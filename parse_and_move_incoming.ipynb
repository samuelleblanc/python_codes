{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info\n",
    "Purpose:\n",
    "\n",
    "    Take incoming folder for sunsat and parse the subfolders and incoming files\n",
    "\n",
    "Input:\n",
    "\n",
    "    None\n",
    "\n",
    "Output:\n",
    "\n",
    "    Moved and catagorized files\n",
    "\n",
    "Keywords:\n",
    "\n",
    "    none\n",
    "\n",
    "Dependencies:\n",
    "\n",
    "    - os\n",
    "    - dateutil\n",
    "    - re\n",
    "    - pathlib2\n",
    "    - datefinder\n",
    "\n",
    "Needed Files:\n",
    "  - None\n",
    "\n",
    "Modification History:\n",
    "\n",
    "    Written: Samuel LeBlanc, Santa Cruz, CA, 2020-11-06\n",
    "    Modified:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the background functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:29.117644Z",
     "start_time": "2020-11-14T02:43:29.105352Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_date_and_string(p):\n",
    "    'p: posix path to extract the date and the string'\n",
    "    fd = [dtemp for dtemp in find_dates(p.stem,source=True)]\n",
    "    if fd:\n",
    "        fdate,f_datestr = fd[0]\n",
    "    else:\n",
    "        f_datestr_re = re.search(\"(\\d{4}?\\d{2}?\\d{2})\",p.stem)          \n",
    "        if f_datestr_re:\n",
    "            f_datestr = f_datestr_re.group()\n",
    "            try:\n",
    "                 fdate = dateutil.parser.parse(f_datestr)\n",
    "            except:\n",
    "                if p.is_dir:\n",
    "                    fdate,f_datestr = get_date_and_string([j for j in p.glob('*')][0])\n",
    "                else:\n",
    "                    fdate,f_datestr = get_date_and_string(p.parent)\n",
    "        else:\n",
    "            if p.suffix in ['.lev10','.lev15','.lev20']: # special for AERONET\n",
    "                f_datestr = re.search(\"(\\d{2}?\\d{2}?\\d{2})\",p.stem).group()\n",
    "                fdate = dateutil.parser.parse(f_datestr,yearfirst=True)\n",
    "    return fdate,f_datestr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:29.535999Z",
     "start_time": "2020-11-14T02:43:29.514072Z"
    }
   },
   "outputs": [],
   "source": [
    "def pull_labels(p,datestr,filters={},dirlabel_in=None):\n",
    "    'p:posis path to extract any labels, datestr: datestr within the filename'\n",
    "    f_str = p.stem\n",
    "    f_strs = f_str.replace(datestr,'').strip('_').split('_')\n",
    "    f_strs_up = [tstr.upper() for tstr in f_strs]\n",
    "    instnames_def = {'4STAR':['4STAR','4STARA','4-STAR','4STAR-A'],\n",
    "                     '4STARB':['4STARB','4STAR2','4STAR-B'],\n",
    "                     '3STAR':['3STAR','3-STAR'],\n",
    "                     '2STAR':['2STAR','2-STAR'],\n",
    "                     'muSSTAR':['MUSSTAR','MUSTAR','MU-STAR','MU-SSTAR'],\n",
    "                     '5STAR':['5STARG','5STAR','5STAR-G','5STARF','5STAR-F'],\n",
    "                     'AATS':['AATS','AATS14','AATS-14'],\n",
    "                     'CAIR':['CAIR','C-AIR']}\n",
    "    if not filters:\n",
    "        instnames = instnames_def\n",
    "    else:\n",
    "        instnames = filters.get('instrument_names',instnames_def)\n",
    "    instname,label,dirlabel = None, None, None\n",
    "    for inm in instnames:\n",
    "        for fstar in instnames[inm]:\n",
    "            if fstar in f_strs_up:\n",
    "                instname = inm\n",
    "                null = f_strs.pop(f_strs_up.index(fstar))\n",
    "                f_strs_up.remove(fstar)  \n",
    "    if p.is_dir():\n",
    "        if dirlabel_in: f_strs.insert(0,dirlabel_in)\n",
    "        dirlabel = '_'.join(f_strs)\n",
    "        dirlabel = dirlabel.strip('_')\n",
    "    else:\n",
    "        label = '_'.join(f_strs)\n",
    "        label = label.strip('_')\n",
    "    \n",
    "    return dirlabel,label,instname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:29.841329Z",
     "start_time": "2020-11-14T02:43:29.832411Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_season(now):\n",
    "    'Function to return a string with the season'\n",
    "    Y = 2000 # dummy leap year to allow input X-02-29 (leap day)\n",
    "    seasons = [('Winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "               ('Spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "               ('Summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "               ('Fall', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "               ('Winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "    \n",
    "    if isinstance(now, datetime):\n",
    "        now = now.date()\n",
    "    now = now.replace(year=Y)\n",
    "    return next(season for season, (start, end) in seasons\n",
    "                if start <= now <= end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:30.174803Z",
     "start_time": "2020-11-14T02:43:30.161301Z"
    }
   },
   "outputs": [],
   "source": [
    "class filetypes:\n",
    "    'Class to identify the filetype, labels, dates, instrumentname, suffixes, input is string indicating full file path'\n",
    "    def __init__(self,f,dirlabel=None,filters={}):\n",
    "        p = Path(f)\n",
    "        self.fdate,self.f_datestr = get_date_and_string(p)\n",
    "        self.dirlabel,self.label,self.instname = pull_labels(p,self.f_datestr,filters=filters,dirlabel_in=dirlabel)\n",
    "        self.p = p\n",
    "        if not self.dirlabel:\n",
    "            self.dirlabel = dirlabel\n",
    "        self.daystr = self.fdate.strftime('%Y%m%d')\n",
    "        \n",
    "    def _print(self):\n",
    "        print self.instname, self.dirlabel, self.label, self.fdate, self.f_datestr, self.p.stem\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        'Method to call only the variables in the class like a dict'\n",
    "        return self.__dict__.get(i)\n",
    "\n",
    "    def keys(self):\n",
    "        'Method to wrap the dict call to the class object'\n",
    "        return self.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:48:48.867437Z",
     "start_time": "2020-11-14T02:48:48.809403Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_newfilepath(f,filters={},debug=False):\n",
    "    'function to build the end file path, input of filetype class f, outputs updated file class f'\n",
    "    # determine the campaign\n",
    "    campaign = 'rooftop'\n",
    "    for campaign_name,date_range in filters['time_filter'].items():\n",
    "        if (f.fdate >= date_range[0]) & (f.fdate <= date_range[1]):\n",
    "            campaign = campaign_name\n",
    "        if f.instname=='4STAR':\n",
    "            for campaign_name,date_range in filters['time_filter_4STAR'].items():\n",
    "                if (f.fdate >= date_range[0]) & (f.fdate <= date_range[1]):\n",
    "                    campaign = campaign_name\n",
    "        elif f.instname=='4STARB':\n",
    "            for campaign_name,date_range in filters['time_filter_4STARB'].items():\n",
    "                if (f.fdate >= date_range[0]) & (f.fdate <= date_range[1]):\n",
    "                    campaign = campaign_name\n",
    "        elif f.instname=='AATS':\n",
    "            for campaign_name,date_range in filters['time_filter_AATS'].items():\n",
    "                if (f.fdate >= date_range[0]) & (f.fdate <= date_range[1]):\n",
    "                    campaign = campaign_name\n",
    "    f.campaign = campaign\n",
    "\n",
    "    if f.campaign=='rooftop':\n",
    "        f.season = get_season(f.fdate)\n",
    "        f.year = f.fdate.year\n",
    "        f.campaign = os.path.join('rooftop','{season}_{year}'.format(**f))\n",
    "    \n",
    "    if debug: print str(f.p)\n",
    "    if debug: print 'Campaign found to be:', campaign\n",
    "    \n",
    "    folders_match_filetype = [ni for ni in filters['directories']\\\n",
    "                              if (f.p.suffix.lower() in filters['directories'][ni]['filetypes'])]\n",
    "    folders_match_label = [j for j in folders_match_filetype if \\\n",
    "                       any([lbl in f.label.lower() for lbl in filters['directories'][j]['label']]) & \\\n",
    "                       (not any([lbl in f.label.lower() for lbl in filters['directories'][j].get('not_label',[])]))]\n",
    "    if debug: print 'folders_match_filetype:',folders_match_filetype\n",
    "    if debug: print 'folders_match_label',folders_match_label\n",
    "    if len(folders_match_label) == 0:\n",
    "        folders_match_label = [j for j in folders_match_filetype if \\\n",
    "                               (not filters['directories'][j]['label'])]\n",
    "        if len(folders_match_label) == 0:\n",
    "            if verbose: print '*** Match move directory not found for file {p.stem}, using base path ***'.format(**f)\n",
    "            folders_match_label = ['']\n",
    "\n",
    "    f.newpath = Path(root_folder).joinpath('{campaign}'.format(**f),folders_match_label[0],\\\n",
    "                                 filters['directories'].get(folders_match_label[0],{}).get('folder_name','').format(**f))    \n",
    "    f.newfile = f.newpath.joinpath(f.p.name)\n",
    "    \n",
    "    if debug: print 'newpath:',str(f.newpath),' newfile:',str(f.newfile)\n",
    "        \n",
    "    #check if destination file already exists:\n",
    "    if f.newfile.exists():\n",
    "        if filecmp.cmp(str(f.newfile),str(f.p),shallow=True):\n",
    "            if filecmp.cmp(str(f.newfile),str(f.p),shallow=False):\n",
    "                # they are the same and don't do anything\n",
    "                if verbose: print '{prefix}Exact same file already exists at: {newfile}, removing incoming file'.format(**f)\n",
    "                if not dry_run: os.remove(str(f.p))\n",
    "                return None\n",
    "        if verbose: print '{prefix}Different file with same name ({p.name}) exists'.format(**f)\n",
    "        f.newpath = f.newpath.joinpath('Uploaded_on_{}'.format(date.today().strftime('%Y%m%d')))\n",
    "        f.newfile = f.newpath.joinpath(f.p.name)\n",
    "        \n",
    "    return folders_match_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:30.920164Z",
     "start_time": "2020-11-14T02:43:30.895039Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_filters_from_json(in_directory):\n",
    "    'function to read in the filters from the json file'\n",
    "    with open(in_directory+'.filters.json') as fjson: \n",
    "        filters = json.load(fjson)\n",
    "\n",
    "    # sanitize input\n",
    "    # set the dates\n",
    "    for nt,lt in filters['time_filter'].items():\n",
    "        lt[0] = datetime(lt[0][0],lt[0][1],lt[0][2])\n",
    "        lt[1] = datetime(lt[1][0],lt[1][1],lt[1][2])\n",
    "    for nt,lt in filters['time_filter_4STAR'].items():\n",
    "        lt[0] = datetime(lt[0][0],lt[0][1],lt[0][2])\n",
    "        lt[1] = datetime(lt[1][0],lt[1][1],lt[1][2])\n",
    "    for nt,lt in filters['time_filter_4STARB'].items():\n",
    "        lt[0] = datetime(lt[0][0],lt[0][1],lt[0][2])\n",
    "        lt[1] = datetime(lt[1][0],lt[1][1],lt[1][2])\n",
    "    for nt,lt in filters['time_filter_AATS'].items():\n",
    "        lt[0] = datetime(lt[0][0],lt[0][1],lt[0][2])\n",
    "        lt[1] = datetime(lt[1][0],lt[1][1],lt[1][2])\n",
    "\n",
    "    # ensure capitalization of the instrument names \n",
    "    for ni,li in filters['instrument_names'].items():\n",
    "        filters['instrument_names'][ni] = [lis.upper() for lis in li]\n",
    "\n",
    "    # ensure lower of the filetypes and labels\n",
    "    for ni in filters['directories']:\n",
    "        filters['directories'][ni]['filetypes'] = [lis.lower() for lis in filters['directories'][ni]['filetypes']]\n",
    "        filters['directories'][ni]['label'] = [lis.lower() for lis in filters['directories'][ni]['label']]\n",
    "        if type(filters['directories'][ni]['folder_name']) is list:\n",
    "            filters['directories'][ni]['folder_name'] = ''\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:31.651080Z",
     "start_time": "2020-11-14T02:43:31.641331Z"
    }
   },
   "outputs": [],
   "source": [
    "def recurse_through_dir(indir,dirlabel=None,verbose=False,filters={}):\n",
    "    fl = os.listdir(indir)\n",
    "    fl_array = []\n",
    "    dirs = {}\n",
    "    for f in fl:\n",
    "        if f.startswith('.'): continue #ignore hidden files\n",
    "        fl_array.append(filetypes(indir+'/'+f,dirlabel=dirlabel,filters=filters))\n",
    "        if verbose: fl_array[-1]._print()\n",
    "        if fl_array[-1].p.is_dir():\n",
    "            dirs[f] = fl_array[-1].dirlabel\n",
    "            fla = recurse_through_dir(indir+'/'+f,dirlabel=dirs[f],verbose=verbose,filters=filters)\n",
    "            fl_array.extend(fla)\n",
    "    return fl_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the command line argument parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:32.749750Z",
     "start_time": "2020-11-14T02:43:32.745214Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:33.140867Z",
     "start_time": "2020-11-14T02:43:33.137349Z"
    }
   },
   "outputs": [],
   "source": [
    "long_description = \"\"\"    Run the incoming file parser and moves the files to the desired sunsat locations\n",
    "    The File locations and folders are defined by the json file: .filters.json\n",
    "    Please update the date ranges within that file for any new field mission, if not then assumes rooftop measurements for the season_year\n",
    "    Can run a call to matlab for any incoming 4STAR raw data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:33.490800Z",
     "start_time": "2020-11-14T02:43:33.472737Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-m', '--run_matlab'], dest='run_matlab', nargs=0, const=True, default=False, type=None, choices=None, help='if set, will run the matlab calls if there is 4STAR/4STARB raw files', metavar=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=long_description)\n",
    "parser.add_argument('-d','--dry_run',help='if set, turn on dry runs, and not move or delete any file/folder',\n",
    "                    action='store_true')\n",
    "parser.add_argument('-q','--quiet',help='if set, quiet the comments',\n",
    "                    action='store_true')\n",
    "parser.add_argument('-i','--in_dir',nargs='?',\n",
    "                    help='Input directory to recurse files, parse, and move',\n",
    "                    default='/data/sunsat/_incoming_gdrive/')\n",
    "parser.add_argument('-r','--root_dir',nargs='?',\n",
    "                    help='full file path of the root directory to save to',\n",
    "                    default='/data/sunsat/')\n",
    "parser.add_argument('-m','--run_matlab',help='if set, will run the matlab calls if there is 4STAR/4STARB raw files',\n",
    "                    action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:34.065365Z",
     "start_time": "2020-11-14T02:43:34.061712Z"
    }
   },
   "outputs": [],
   "source": [
    "in_ = vars(parser.parse_known_args()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the modules and get the defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:36.238998Z",
     "start_time": "2020-11-14T02:43:36.065743Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, zipfile\n",
    "import dateutil.parser\n",
    "import re\n",
    "from pathlib2 import Path\n",
    "from datefinder import find_dates\n",
    "from datetime import date, datetime\n",
    "import json\n",
    "import filecmp\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:36.901197Z",
     "start_time": "2020-11-14T02:43:36.895860Z"
    }
   },
   "outputs": [],
   "source": [
    "in_directory = in_.get('in_dir','/data/sunsat/_incoming_gdrive/')\n",
    "root_folder = in_.get('root_dir','/data/sunsat/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:37.470932Z",
     "start_time": "2020-11-14T02:43:37.465774Z"
    }
   },
   "outputs": [],
   "source": [
    "verbose = not in_.get('quiet',False)\n",
    "dry_run = in_.get('dry_run',True)\n",
    "run_matlab = in_.get('run_matlab',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:38.014299Z",
     "start_time": "2020-11-14T02:43:38.008648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_dir': '/data/sunsat/_incoming_gdrive/', 'root_dir': '/data/sunsat/', 'quiet': False, 'dry_run': False, 'run_matlab': False}\n"
     ]
    }
   ],
   "source": [
    "if verbose: print in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:43:39.586337Z",
     "start_time": "2020-11-14T02:43:39.578053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Go through and unzip any folder\n",
    "prefix = '*DRY RUN*: ' if dry_run else ''\n",
    "for item in os.listdir(in_directory): # loop through items in dir\n",
    "    if item.lower().endswith('.zip'): # check for \".zip\" extension\n",
    "        file_name = Path(in_directory+item) # get full path of files\n",
    "        zip_ref = zipfile.ZipFile(str(file_name)) # create zipfile object\n",
    "        if verbose: print '{prefix}found zip file: {file_name}, extracting here.'.format(prefix=prefix,file_name=file_name)\n",
    "        if not dry_run: zip_ref.extractall(in_directory) # extract file to dir\n",
    "        zip_ref.close() # close file\n",
    "        if not dry_run: os.remove(str(file_name)) # delete zipped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:52:40.088061Z",
     "start_time": "2020-11-14T02:52:40.082107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None starflags__auto_marks_ALL_20201113_1631 2020-10-27 00:00:00 20201027 starflags_20201027_auto_marks_ALL_20201113_1631\n"
     ]
    }
   ],
   "source": [
    "filters = get_filters_from_json(in_directory)\n",
    "fl_arr = recurse_through_dir(in_directory,verbose=verbose,filters=filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T02:52:42.615670Z",
     "start_time": "2020-11-14T02:52:42.601614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/sunsat/_incoming_gdrive/starflags_20201027_auto_marks_ALL_20201113_1631.m\n",
      "Campaign found to be: rooftop\n",
      "folders_match_filetype: [u'data_processed/flagfiles', u'data_processed/starinfo']\n",
      "folders_match_label [u'data_processed/flagfiles']\n",
      "newpath: /data/sunsat/rooftop/Fall_2020/data_processed/flagfiles  newfile: /data/sunsat/rooftop/Fall_2020/data_processed/flagfiles/starflags_20201027_auto_marks_ALL_20201113_1631.m\n",
      "Moving file from /data/sunsat/_incoming_gdrive/starflags_20201027_auto_marks_ALL_20201113_1631.m to new path: /data/sunsat/rooftop/Fall_2020/data_processed/flagfiles/starflags_20201027_auto_marks_ALL_20201113_1631.m\n"
     ]
    }
   ],
   "source": [
    "data_raw_found = False\n",
    "data_raw_files = {}\n",
    "for f in fl_arr:\n",
    "    # determine the end path of the file\n",
    "    if f.p.is_dir(): continue # do nothing for directories\n",
    "    f.prefix = '*DRY RUN*: ' if dry_run else ''\n",
    "    \n",
    "    folders_match_label = get_newfilepath(f,filters=filters,debug=False)\n",
    "    if not folders_match_label: continue\n",
    "        \n",
    "    if 'data_raw' in folders_match_label:\n",
    "        data_raw_found = True\n",
    "\n",
    "    # now move the files\n",
    "    if not f.newpath.exists() & verbose: print '{prefix}+Creating new path: {newpath}'.format(**f) \n",
    "    if not dry_run: f.newpath.mkdir(parents=True,exist_ok=True)\n",
    "    if verbose: print '{prefix}~Moving file from {p}\\n   to new path: {newfile}'.format(**f) \n",
    "    if not dry_run: f.p.rename(f.newfile)\n",
    "    if 'data_raw' in folders_match_label: \n",
    "        data_raw_files['{instname}_{daystr}'.format(**f)] =\\\n",
    "                      data_raw_files.get('{instname}_{daystr}'.format(**f),[])\n",
    "        data_raw_files['{instname}_{daystr}'.format(**f)].append(str(f.newfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T23:30:59.842404Z",
     "start_time": "2020-11-13T23:30:59.833089Z"
    }
   },
   "outputs": [],
   "source": [
    "# clean up folders after move\n",
    "for dirpath, dirnames, filenames in os.walk(in_directory,topdown=False):\n",
    "    if not dirpath in in_directory:\n",
    "        try: \n",
    "            if verbose: print '{pre}-removing :{path}'.format(pre=prefix,path=dirpath)\n",
    "            if not dry_run:\n",
    "                os.rmdir(dirpath) \n",
    "        except: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T23:37:40.013990Z",
     "start_time": "2020-11-13T23:37:39.962534Z"
    }
   },
   "outputs": [],
   "source": [
    "if run_matlab:\n",
    "    prefix = '*DRY RUN*: ' if dry_run else ''\n",
    "    for dr,drs in data_raw_files.items():\n",
    "        # get the position of the new star.mat and starsun.mat files\n",
    "        f = filetypes('{}star.mat'.format(dr),filters=filters)\n",
    "        fml = get_newfilepath(f,filters=filters)\n",
    "        if not dry_run: f.newpath.mkdir(parents=True,exist_ok=True)\n",
    "        fs = filetypes('{}starsun.mat'.format(dr),filters=filters)\n",
    "        fmls = get_newfilepath(fs,filters=filters)\n",
    "        if not dry_run: fs.newpath.mkdir(parents=True,exist_ok=True)\n",
    "            \n",
    "        # make the position of the new quicklook file\n",
    "        instname,daystr = dr.split('_')\n",
    "        fq = filetypes('{daystr}_{instname}_Quicklooks.ppt'.format(instname=instname,daystr=daystr))\n",
    "        fmlq = get_newfilepath(fq,filters=filters)\n",
    "        \n",
    "        # make the position of the new figure files\n",
    "        ff = filetypes('{daystr}_{instname}_plots.fig'.format(instname=instname,daystr=daystr))\n",
    "        fmlf = get_newfilepath(ff,filters=filters)\n",
    "        \n",
    "        # make the position of the aeronet files\n",
    "        fa = filetypes('{daystr}_AERONET_NASA_Ames.lev15'.format(instname=instname,daystr=daystr))\n",
    "        fmla = get_newfilepath(fa,filters=filters)\n",
    "        \n",
    "        # make the position of the gas_summary files\n",
    "        fg = filetypes('{instname}_{daystr}_gas_summary.mat'.format(instname=instname,daystr=daystr))\n",
    "        fmlg = get_newfilepath(fg,filters=filters)\n",
    "        \n",
    "        # make a string of the raw files    \n",
    "        filelist = \"'\"+\"';'\".join(drs)+\"'\"\n",
    "        if not f.instname in ['4STAR','4STARB']: # only for 4STARs for now.\n",
    "            continue\n",
    "        command_setpath = \"setnamedpath('starimg','{fig_path}');setnamedpath('starsun','{aero_path}');setnamedpath('gas_summary','{gas_path}')\".\\\n",
    "                           format(fig_path=str(f.newpath)+'/',aero_path=str(fa.newpath)+'/',gas_path=str(fg.newpath)+'/')\n",
    "        command = \"allstarmat({{{filelist}}},'{starmat}')\".format(filelist=filelist,starmat=str(f.newfile))\n",
    "        command2 = \"starsun('{starmat}','{starsun}')\".format(starmat=f.newfile,starsun=fs.newfile)\n",
    "        command3 = \"Quicklooks_4STAR('{starsun}','{starmat}','{quicklooks}')\".format(starmat=str(f.newfile),\n",
    "                                       starsun=str(fs.newfile),quicklooks=in_directory+str(fq.newfile.name))\n",
    "        if verbose: \n",
    "            print ' '.join(['{}matlab'.format(prefix),'-nodisplay','-r','\"{};{};{};{};exit;\"'.\\\n",
    "                            format(command_setpath,command,command2,command3)])\n",
    "        if not dry_run:\n",
    "            process = subprocess.Popen(['matlab','-nodisplay','-r','\"{};{};{};{};exit;\"'.\\\n",
    "                                        format(command_setpath,command,command2,command3)],\n",
    "                                       shell=True,\n",
    "                                       stdout=subprocess.PIPE, \n",
    "                                       stderr=subprocess.PIPE)\n",
    "            while process.returncode is None:\n",
    "                # handle output by direct access to stdout and stderr\n",
    "                for line in process.stdout:\n",
    "                    if verbose: print line\n",
    "                for liner in process.stderr:\n",
    "                    if verbose: print liner\n",
    "                # set returncode if the process has exited\n",
    "                process.poll()\n",
    "            #stdout, stderr = process.communicate()\n",
    "            #if verbose: print stdout, stderr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
