{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info\n",
    "Purpose:\n",
    "\n",
    "    Take incoming folder for sunsat and parse the subfolders and incoming files\n",
    "\n",
    "Input:\n",
    "\n",
    "    None\n",
    "\n",
    "Output:\n",
    "\n",
    "    Moved and catagorized files\n",
    "\n",
    "Keywords:\n",
    "\n",
    "    none\n",
    "\n",
    "Dependencies:\n",
    "\n",
    "    - os\n",
    "    - dateutil\n",
    "    - re\n",
    "    - pathlib2\n",
    "    - datefinder\n",
    "\n",
    "Needed Files:\n",
    "  - None\n",
    "\n",
    "Modification History:\n",
    "\n",
    "    Written: Samuel LeBlanc, Santa Cruz, CA, 2020-11-06\n",
    "    Modified: Samuel LeBlanc, Santa Cruz, CA, 2020-12-02\n",
    "             - added support for files without a date in the name, using either the directories' date, or the file's date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the background functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:05.806298Z",
     "start_time": "2020-12-03T22:27:05.801920Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:06.373170Z",
     "start_time": "2020-12-03T22:27:06.351477Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_date_and_string(p,dirdate=None):\n",
    "    'p: posix path to extract the date and the string'\n",
    "    fdate = dirdate\n",
    "    fd = [dtemp for dtemp in find_dates(p.stem,source=True)]\n",
    "    if fd:\n",
    "        fdate,f_datestr = fd[0]\n",
    "    else:\n",
    "        f_datestr_re = re.search(\"(\\d{4}?\\d{2}?\\d{2})\",p.stem)          \n",
    "        if f_datestr_re:\n",
    "            f_datestr = f_datestr_re.group()\n",
    "            try:\n",
    "                 fdate = dateutil.parser.parse(f_datestr)\n",
    "            except:\n",
    "                if p.is_dir:\n",
    "                    fdate,f_datestr = get_date_and_string([j for j in p.glob('*')][0])\n",
    "                else:\n",
    "                    fdate,f_datestr = get_date_and_string(p.parent)\n",
    "        else:\n",
    "            if p.suffix in ['.lev10','.lev15','.lev20']: # special for AERONET\n",
    "                f_datestr = re.search(\"(\\d{2}?\\d{2}?\\d{2})\",p.stem).group()\n",
    "                fdate = dateutil.parser.parse(f_datestr,yearfirst=True)\n",
    "    \n",
    "    if not fdate: fdate = datetime.fromtimestamp(p.stat().st_ctime)\n",
    "    if not locals().get('f_datestr'): f_datestr = fdate.strftime('%Y%m%d')\n",
    "        \n",
    "    return fdate,f_datestr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:06.897428Z",
     "start_time": "2020-12-03T22:27:06.869622Z"
    }
   },
   "outputs": [],
   "source": [
    "def pull_labels(p,datestr,filters={},dirlabel_in=None):\n",
    "    'p:posis path to extract any labels, datestr: datestr within the filename'\n",
    "    f_str = p.stem\n",
    "    f_strs = f_str.replace(datestr,'').strip('_').split('_')\n",
    "    f_strs_up = [tstr.upper() for tstr in f_strs]\n",
    "    instnames_def = {'4STAR':['4STAR','4STARA','4-STAR','4STAR-A'],\n",
    "                     '4STARB':['4STARB','4STAR2','4STAR-B'],\n",
    "                     '3STAR':['3STAR','3-STAR'],\n",
    "                     '2STAR':['2STAR','2-STAR'],\n",
    "                     'muSSTAR':['MUSSTAR','MUSTAR','MU-STAR','MU-SSTAR'],\n",
    "                     '5STAR':['5STARG','5STAR','5STAR-G','5STARF','5STAR-F'],\n",
    "                     'AATS':['AATS','AATS14','AATS-14'],\n",
    "                     'CAIR':['CAIR','C-AIR']}\n",
    "    if not filters:\n",
    "        instnames = instnames_def\n",
    "    else:\n",
    "        instnames = filters.get('instrument_names',instnames_def)\n",
    "    instname,label,dirlabel = None, None, None\n",
    "    for inm in instnames:\n",
    "        for fstar in instnames[inm]:\n",
    "            if fstar in f_strs_up:\n",
    "                instname = inm\n",
    "                null = f_strs.pop(f_strs_up.index(fstar))\n",
    "                f_strs_up.remove(fstar)  \n",
    "    if p.is_dir():\n",
    "        if dirlabel_in: f_strs.insert(0,dirlabel_in)\n",
    "        dirlabel = '_'.join(f_strs)\n",
    "        dirlabel = dirlabel.strip('_')\n",
    "    else:\n",
    "        label = '_'.join(f_strs)\n",
    "        label = label.strip('_')\n",
    "    \n",
    "    return dirlabel,label,instname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:07.263053Z",
     "start_time": "2020-12-03T22:27:07.252233Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_season(now):\n",
    "    'Function to return a string with the season'\n",
    "    Y = 2000 # dummy leap year to allow input X-02-29 (leap day)\n",
    "    seasons = [('Winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "               ('Spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "               ('Summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "               ('Fall', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "               ('Winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "    \n",
    "    if isinstance(now, datetime):\n",
    "        now = now.date()\n",
    "    now = now.replace(year=Y)\n",
    "    return next(season for season, (start, end) in seasons\n",
    "                if start <= now <= end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:07.692662Z",
     "start_time": "2020-12-03T22:27:07.670858Z"
    }
   },
   "outputs": [],
   "source": [
    "class filetypes:\n",
    "    'Class to identify the filetype, labels, dates, instrumentname, suffixes, input is string indicating full file path'\n",
    "    def __init__(self,f,dirlabel=None,dirdate=None,filters={}):\n",
    "        p = Path(f)\n",
    "        self.fdate,self.f_datestr = get_date_and_string(p,dirdate=dirdate)\n",
    "        self.dirlabel,self.label,self.instname = pull_labels(p,self.f_datestr,filters=filters,dirlabel_in=dirlabel)\n",
    "        self.p = p\n",
    "        if not self.dirlabel:\n",
    "            self.dirlabel = dirlabel\n",
    "        if not dirdate:\n",
    "            self.dirdate = self.fdate\n",
    "        else:\n",
    "            self.dirdate = dirdate\n",
    "        self.daystr = self.dirdate.strftime('%Y%m%d')\n",
    "        \n",
    "    def _print(self):\n",
    "        print(self.instname, self.dirlabel, self.label, self.fdate, self.f_datestr, self.p.stem)\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        'Method to call only the variables in the class like a dict'\n",
    "        return self.__dict__.get(i)\n",
    "\n",
    "    def keys(self):\n",
    "        'Method to wrap the dict call to the class object'\n",
    "        return self.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:08.175422Z",
     "start_time": "2020-12-03T22:27:08.104385Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_newfilepath(f,filters={},debug=False,fake_file=False,nexact=0):\n",
    "    'function to build the end file path, input of filetype class f, outputs updated file class f'\n",
    "    # determine the campaign\n",
    "    campaign = 'rooftop'\n",
    "    for campaign_name,date_range in filters['time_filter'].items():\n",
    "        if (f.fdate >= date_range[0]) & (f.fdate <= date_range[1]):\n",
    "            campaign = campaign_name\n",
    "        if f.instname=='4STAR':\n",
    "            for campaign_name,date_range in filters['time_filter_4STAR'].items():\n",
    "                if (f.fdate >= date_range[0]) & (f.fdate <= date_range[1]):\n",
    "                    campaign = campaign_name\n",
    "        elif f.instname=='4STARB':\n",
    "            for campaign_name,date_range in filters['time_filter_4STARB'].items():\n",
    "                if (f.fdate >= date_range[0]) & (f.fdate <= date_range[1]):\n",
    "                    campaign = campaign_name\n",
    "        elif f.instname=='AATS':\n",
    "            for campaign_name,date_range in filters['time_filter_AATS'].items():\n",
    "                if (f.fdate >= date_range[0]) & (f.fdate <= date_range[1]):\n",
    "                    campaign = campaign_name\n",
    "    f.campaign = campaign\n",
    "\n",
    "    if f.campaign=='rooftop':\n",
    "        f.season = get_season(f.fdate)\n",
    "        f.year = f.fdate.year\n",
    "        f.campaign = os.path.join('rooftop','{season}_{year}'.format(**f))\n",
    "    \n",
    "    if debug: print(str(f.p))\n",
    "    if debug: print('Campaign found to be:', campaign)\n",
    "    \n",
    "    folders_match_filetype = [ni for ni in filters['directories']\\\n",
    "                              if (f.p.suffix.lower() in filters['directories'][ni]['filetypes'])]\n",
    "    folders_match_label = [j for j in folders_match_filetype if \\\n",
    "                       any([lbl in f.label.lower() for lbl in filters['directories'][j]['label']]) & \\\n",
    "                       (not any([lbl in f.label.lower() for lbl in filters['directories'][j].get('not_label',[])]))]\n",
    "    if debug: print('folders_match_filetype:',folders_match_filetype)\n",
    "    if debug: print('folders_match_label',folders_match_label)\n",
    "    if len(folders_match_label) == 0:\n",
    "        folders_match_label = [j for j in folders_match_filetype if \\\n",
    "                               (not filters['directories'][j]['label'])]\n",
    "        if len(folders_match_label) == 0:\n",
    "            if verbose: print('*** Match move directory not found for file {p.stem}, using base path ***'.format(**f))\n",
    "            folders_match_label = ['']\n",
    "\n",
    "    f.newpath = Path(root_folder).joinpath('{campaign}'.format(**f),folders_match_label[0],\\\n",
    "                                 filters['directories'].get(folders_match_label[0],{}).get('folder_name','').format(**f))   \n",
    "    f.newfile = f.newpath.joinpath(f.p.name)\n",
    "    \n",
    "    if debug: print( 'newpath:',str(f.newpath),' newfile:',str(f.newfile))\n",
    "        \n",
    "    #check if destination file already exists:\n",
    "    if f.newfile.exists() & (not fake_file):\n",
    "        if filecmp.cmp(str(f.newfile),str(f.p),shallow=True):\n",
    "            if filecmp.cmp(str(f.newfile),str(f.p),shallow=False):\n",
    "                # they are the same and don't do anything\n",
    "                if verbose: \n",
    "                    print( '{prefix}Exact same file already exists at: {newfile}, removing incoming file'.format(**f))\n",
    "                if not dry_run: os.remove(str(f.p))\n",
    "                nexact = nexact+1\n",
    "                return None,nexact\n",
    "        if verbose: print( '{prefix}Different file with same name ({p.name}) exists'.format(**f))\n",
    "        f.newpath = f.newpath.joinpath('Uploaded_on_{}'.format(date.today().strftime('%Y%m%d')))\n",
    "        f.newfile = f.newpath.joinpath(f.p.name)\n",
    "        \n",
    "    return folders_match_label,nexact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:08.617426Z",
     "start_time": "2020-12-03T22:27:08.584881Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_filters_from_json(in_directory):\n",
    "    'function to read in the filters from the json file'\n",
    "    with open(in_directory+'.filters.json') as fjson: \n",
    "        filters = json.load(fjson)\n",
    "\n",
    "    # sanitize input\n",
    "    # set the dates\n",
    "    for nt,lt in filters['time_filter'].items():\n",
    "        lt[0] = datetime(lt[0][0],lt[0][1],lt[0][2])\n",
    "        lt[1] = datetime(lt[1][0],lt[1][1],lt[1][2])\n",
    "    for nt,lt in filters['time_filter_4STAR'].items():\n",
    "        lt[0] = datetime(lt[0][0],lt[0][1],lt[0][2])\n",
    "        lt[1] = datetime(lt[1][0],lt[1][1],lt[1][2])\n",
    "    for nt,lt in filters['time_filter_4STARB'].items():\n",
    "        lt[0] = datetime(lt[0][0],lt[0][1],lt[0][2])\n",
    "        lt[1] = datetime(lt[1][0],lt[1][1],lt[1][2])\n",
    "    for nt,lt in filters['time_filter_AATS'].items():\n",
    "        lt[0] = datetime(lt[0][0],lt[0][1],lt[0][2])\n",
    "        lt[1] = datetime(lt[1][0],lt[1][1],lt[1][2])\n",
    "\n",
    "    # ensure capitalization of the instrument names \n",
    "    for ni,li in filters['instrument_names'].items():\n",
    "        filters['instrument_names'][ni] = [lis.upper() for lis in li]\n",
    "\n",
    "    # ensure lower of the filetypes and labels\n",
    "    for ni in filters['directories']:\n",
    "        filters['directories'][ni]['filetypes'] = [lis.lower() for lis in filters['directories'][ni]['filetypes']]\n",
    "        filters['directories'][ni]['label'] = [lis.lower() for lis in filters['directories'][ni]['label']]\n",
    "        if type(filters['directories'][ni]['folder_name']) is list:\n",
    "            filters['directories'][ni]['folder_name'] = ''\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:09.176138Z",
     "start_time": "2020-12-03T22:27:09.165722Z"
    }
   },
   "outputs": [],
   "source": [
    "def recurse_through_dir(indir,dirlabel=None,dirdate=None,verbose=False,filters={}):\n",
    "    fl = os.listdir(indir)\n",
    "    fl_array = []\n",
    "    dirs = {}\n",
    "    for f in fl:\n",
    "        if f.startswith('.'): continue #ignore hidden files\n",
    "        if verbose: print(f+' -> ',end='')\n",
    "        fl_array.append(filetypes(indir+'/'+f,dirlabel=dirlabel,filters=filters,dirdate=dirdate))\n",
    "        if verbose: fl_array[-1]._print()\n",
    "        if fl_array[-1].p.is_dir():\n",
    "            dirs[f] = fl_array[-1].dirlabel\n",
    "            fla = recurse_through_dir(indir+'/'+f,dirlabel=dirs[f],verbose=verbose,\n",
    "                                      filters=filters,dirdate=fl_array[-1].fdate)\n",
    "            fl_array.extend(fla)\n",
    "    return fl_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:09.668913Z",
     "start_time": "2020-12-03T22:27:09.648261Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_temp_mfile(mfilepath,filelist,starmat,starsun,quicklooks,fig_path,aero_path,gas_path,sun_path,incoming_path):\n",
    "    'Print the matlab commands to a temp m file'\n",
    "    \n",
    "    command_setpath = [\"setnamedpath('starimg','{fig_path}');\".format(fig_path=fig_path),\n",
    "                       \"setnamedpath('starsun','{sun_path}');\".format(sun_path=sun_path),\n",
    "                       \"setnamedpath('aeronet','{aero_path}');\".format(aero_path=aero_path),\n",
    "                       \"setnamedpath('gas_summary','{gas_path}');\".format(gas_path=gas_path)]\n",
    "    command = \"allstarmat({{{filelist}}},'{starmat}')\".format(filelist=filelist,starmat=starmat)\n",
    "    command2 = \"starsun('{starmat}','{starsun}')\".format(starmat=starmat,starsun=starsun)\n",
    "    command3 = \"Quicklooks_4STAR('{starsun}','{starmat}','{quicklooks}')\".format(starmat=starmat,\n",
    "                                   starsun=starsun,quicklooks=quicklooks)\n",
    "    \n",
    "    commands = command_setpath\n",
    "    commands.append(command)\n",
    "    commands.append(command2)\n",
    "    commands.append(\"pa = getnamedpath('starmat');\")\n",
    "    commands.append(\"setnamedpath('starmat','{incoming_path}');\".format(incoming_path=incoming_path))\n",
    "    commands.append(command3)\n",
    "    commands.append(\"setnamedpath('starmat',pa);\")\n",
    "    \n",
    "    with open(mfilepath,'w') as f:\n",
    "        f.write('% Temp matlab script created on : '+str(datetime.now())+' \\n')\n",
    "        for cm_line in commands:\n",
    "            f.write(cm_line+' \\n')\n",
    "        f.write('exit;\\n')\n",
    "    return mfilepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:10.318961Z",
     "start_time": "2020-12-03T22:27:10.292688Z"
    }
   },
   "outputs": [],
   "source": [
    "def move_files(fl_arr,filters,verbose=False,dry_run=False):\n",
    "    'Function to go through and move the files, create folders if necessary, and check if there are any new raw data'\n",
    "    data_raw_found = False\n",
    "    data_raw_files = {}\n",
    "    nexact, nmoved, ncreated, ndataraw = 0,0,0,0\n",
    "    for f in fl_arr:\n",
    "        # determine the end path of the file\n",
    "        if f.p.is_dir(): continue # do nothing for directories\n",
    "        f.prefix = '*DRY RUN*: ' if dry_run else ''\n",
    "\n",
    "        folders_match_label,nexact = get_newfilepath(f,filters=filters,debug=False,nexact=nexact)\n",
    "        if not folders_match_label: continue\n",
    "\n",
    "        if 'data_raw' in folders_match_label:\n",
    "            data_raw_found = True\n",
    "\n",
    "        # now move the files\n",
    "        if not f.newpath.exists() & verbose: print( '{prefix}+Creating new path: {newpath}'.format(**f) )\n",
    "        if not dry_run: \n",
    "            if not f.newpath.exists(): ncreated = ncreated+1\n",
    "            f.newpath.mkdir(parents=True,exist_ok=True)\n",
    "        if verbose: print( '{prefix}~Moving file from {p}\\n   to new path: {newfile}'.format(**f) )\n",
    "        if not dry_run: \n",
    "            nmoved = nmoved+1\n",
    "            f.p.rename(f.newfile)\n",
    "        if 'data_raw' in folders_match_label: \n",
    "            data_raw_files['{instname}_{daystr}'.format(**f)] =\\\n",
    "                          data_raw_files.get('{instname}_{daystr}'.format(**f),[])\n",
    "            data_raw_files['{instname}_{daystr}'.format(**f)].append(str(f.newfile))\n",
    "            ndataraw = ndataraw+1\n",
    "    return data_raw_found, data_raw_files, nexact, nmoved, ncreated, ndataraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the command line argument parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:12.224955Z",
     "start_time": "2020-12-03T22:27:12.220130Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:12.761806Z",
     "start_time": "2020-12-03T22:27:12.756941Z"
    }
   },
   "outputs": [],
   "source": [
    "long_description = \"\"\"    Run the incoming file parser and moves the files to the desired sunsat locations\n",
    "    The File locations and folders are defined by the json file: .filters.json\n",
    "    Please update the date ranges within that file for any new field mission, \n",
    "        if not then assumes rooftop measurements for the season_year\n",
    "    Can run a call to matlab for any incoming 4STAR raw data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:13.188278Z",
     "start_time": "2020-12-03T22:27:13.165168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-m', '--run_matlab'], dest='run_matlab', nargs=0, const=True, default=False, type=None, choices=None, help='if set, will run the matlab calls if there is 4STAR/4STARB raw files', metavar=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=long_description)\n",
    "parser.add_argument('-d','--dry_run',help='if set, turn on dry runs, and not move or delete any file/folder',\n",
    "                    action='store_true')\n",
    "parser.add_argument('-q','--quiet',help='if set, quiet the comments',\n",
    "                    action='store_true')\n",
    "parser.add_argument('-i','--in_dir',nargs='?',\n",
    "                    help='Input directory to recurse files, parse, and move',\n",
    "                    default='/data/sunsat/_incoming_gdrive/')\n",
    "parser.add_argument('-r','--root_dir',nargs='?',\n",
    "                    help='full file path of the root directory to save to',\n",
    "                    default='/data/sunsat/')\n",
    "parser.add_argument('-m','--run_matlab',help='if set, will run the matlab calls if there is 4STAR/4STARB raw files',\n",
    "                    action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:13.721676Z",
     "start_time": "2020-12-03T22:27:13.716219Z"
    }
   },
   "outputs": [],
   "source": [
    "in_ = vars(parser.parse_known_args()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the modules and get the defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:16.442676Z",
     "start_time": "2020-12-03T22:27:16.324275Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, zipfile\n",
    "import dateutil.parser\n",
    "import re\n",
    "from pathlib2 import Path\n",
    "from datefinder import find_dates\n",
    "from datetime import date, datetime\n",
    "import json\n",
    "import filecmp\n",
    "import subprocess\n",
    "import threading\n",
    "from aeronet import get_AERONET_file_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:17.733667Z",
     "start_time": "2020-12-03T22:27:17.726179Z"
    }
   },
   "outputs": [],
   "source": [
    "in_directory = in_.get('in_dir','/data/sunsat/_incoming_gdrive/')\n",
    "root_folder = in_.get('root_dir','/data/sunsat/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:18.997273Z",
     "start_time": "2020-12-03T22:27:18.990281Z"
    }
   },
   "outputs": [],
   "source": [
    "verbose = not in_.get('quiet',False)\n",
    "dry_run = in_.get('dry_run',True)\n",
    "run_matlab = in_.get('run_matlab',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:19.483732Z",
     "start_time": "2020-12-03T22:27:19.477221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_dir': '/data/sunsat/_incoming_gdrive/', 'root_dir': '/data/sunsat/', 'quiet': False, 'dry_run': False, 'run_matlab': False}\n"
     ]
    }
   ],
   "source": [
    "if verbose: print( in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:30.369876Z",
     "start_time": "2020-12-03T22:27:30.357281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Go through and unzip any folder\n",
    "prefix = '*DRY RUN*: ' if dry_run else ''\n",
    "for item in os.listdir(in_directory): # loop through items in dir\n",
    "    if item.lower().endswith('.zip'): # check for \".zip\" extension\n",
    "        file_name = Path(in_directory+item) # get full path of files\n",
    "        zip_ref = zipfile.ZipFile(str(file_name)) # create zipfile object\n",
    "        if verbose: \n",
    "            print( '{prefix}found zip file: {file_name}, extracting here.'.format(prefix=prefix,file_name=file_name))\n",
    "        if not dry_run: zip_ref.extractall(in_directory) # extract file to dir\n",
    "        zip_ref.close() # close file\n",
    "        if not dry_run: os.remove(str(file_name)) # delete zipped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:27:54.794978Z",
     "start_time": "2020-12-03T22:27:54.645950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201115_201115_NASA_Ames.lev15 -> None None NASA_Ames 2020-11-15 00:00:00 201115 201115_201115_NASA_Ames\n",
      "20201112_4STARsisters_AmesRoof -> None 4STARsisters_AmesRoof None 2020-11-12 00:00:00 20201112 20201112_4STARsisters_AmesRoof\n",
      "20201112_4STARB -> 4STARB 4STARsisters_AmesRoof None 2020-11-12 00:00:00 20201112 20201112_4STARB\n",
      "4STARB_20201112_003_NIR_SUN.dat -> 4STARB 4STARsisters_AmesRoof 003_NIR_SUN 2020-11-12 00:00:00 20201112 4STARB_20201112_003_NIR_SUN\n",
      "4STARB_20201112_001_VIS_SUN.dat -> 4STARB 4STARsisters_AmesRoof 001_VIS_SUN 2020-11-12 00:00:00 20201112 4STARB_20201112_001_VIS_SUN\n",
      "4STARB_20201112_004_TRACK.dat -> 4STARB 4STARsisters_AmesRoof 004_TRACK 2020-11-12 00:00:00 20201112 4STARB_20201112_004_TRACK\n",
      "4STARB_20201112_003_VIS_SUN.dat -> 4STARB 4STARsisters_AmesRoof 003_VIS_SUN 2020-11-12 00:00:00 20201112 4STARB_20201112_003_VIS_SUN\n",
      "4STARB_20201112_002_TRACK.dat -> 4STARB 4STARsisters_AmesRoof 002_TRACK 2020-11-12 00:00:00 20201112 4STARB_20201112_002_TRACK\n",
      "4STARB_20201112_001_NIR_SUN.dat -> 4STARB 4STARsisters_AmesRoof 001_NIR_SUN 2020-11-12 00:00:00 20201112 4STARB_20201112_001_NIR_SUN\n",
      "20201113_notes.jpg -> None 4STARsisters_AmesRoof notes 2020-11-13 00:00:00 20201113 20201113_notes\n",
      "20201112_4STARA -> 4STAR 4STARsisters_AmesRoof None 2020-11-12 00:00:00 20201112 20201112_4STARA\n",
      "4STAR_20201113_008_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 008_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_008_TRACK\n",
      "4STAR_20201113_013_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 013_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_013_TRACK\n",
      "4STAR_20201113_003_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 003_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_003_TRACK\n",
      "4STAR_20201113_016_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 016_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_016_TRACK\n",
      "4STAR_20201112_001_NIR_SUN.dat -> 4STAR 4STARsisters_AmesRoof 001_NIR_SUN 2020-11-12 00:00:00 20201112 4STAR_20201112_001_NIR_SUN\n",
      "4STAR_20201113_012_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 012_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_012_TRACK\n",
      "4STAR_20201112_002_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 002_TRACK 2020-11-12 00:00:00 20201112 4STAR_20201112_002_TRACK\n",
      "4STAR_20201113_004_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 004_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_004_TRACK\n",
      "4STAR_20201113_007_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 007_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_007_TRACK\n",
      "4STAR_20201112_001_VIS_SUN.dat -> 4STAR 4STARsisters_AmesRoof 001_VIS_SUN 2020-11-12 00:00:00 20201112 4STAR_20201112_001_VIS_SUN\n",
      "4STAR_20201113_009_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 009_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_009_TRACK\n",
      "4STAR_20201113_006_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 006_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_006_TRACK\n",
      "4STAR_20201113_005_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 005_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_005_TRACK\n",
      "4STAR_20201113_002_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 002_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_002_TRACK\n",
      "4STAR_20201113_014_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 014_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_014_TRACK\n",
      "4STAR_20201113_011_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 011_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_011_TRACK\n",
      "4STAR_20201113_010_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 010_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_010_TRACK\n",
      "4STAR_20201113_001_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 001_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_001_TRACK\n",
      "4STAR_20201113_015_TRACK.dat -> 4STAR 4STARsisters_AmesRoof 015_TRACK 2020-11-13 00:00:00 20201113 4STAR_20201113_015_TRACK\n",
      "20201104_4STAR_Quicklooks.pptx -> 4STAR None Quicklooks 2020-11-04 00:00:00 20201104 20201104_4STAR_Quicklooks\n",
      "20201104_4STARB_Quicklooks.pptx -> 4STARB None Quicklooks 2020-11-04 00:00:00 20201104 20201104_4STARB_Quicklooks\n",
      "20201104_4STARboth_AmesRoof_Clear -> None 4STARboth_AmesRoof_Clear None 2020-11-04 00:00:00 20201104 20201104_4STARboth_AmesRoof_Clear\n",
      "20201104_4STARA -> 4STAR 4STARboth_AmesRoof_Clear None 2020-11-04 00:00:00 20201104 20201104_4STARA\n",
      "4STAR_20201105_005_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 005_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_005_TRACK\n",
      "4STAR_20201104_001_NIR_SUN.dat -> 4STAR 4STARboth_AmesRoof_Clear 001_NIR_SUN 2020-11-04 00:00:00 20201104 4STAR_20201104_001_NIR_SUN\n",
      "4STAR_20201105_006_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 006_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_006_TRACK\n",
      "4STAR_20201105_014_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 014_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_014_TRACK\n",
      "4STAR_20201105_003_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 003_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_003_TRACK\n",
      "4STAR_20201105_013_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 013_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_013_TRACK\n",
      "4STAR_20201105_001_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 001_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_001_TRACK\n",
      "4STAR_20201105_009_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 009_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_009_TRACK\n",
      "4STAR_20201105_004_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 004_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_004_TRACK\n",
      "4STAR_20201105_011_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 011_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_011_TRACK\n",
      "4STAR_20201105_010_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 010_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_010_TRACK\n",
      "4STAR_20201104_001_VIS_SUN.dat -> 4STAR 4STARboth_AmesRoof_Clear 001_VIS_SUN 2020-11-04 00:00:00 20201104 4STAR_20201104_001_VIS_SUN\n",
      "4STAR_20201104_002_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 002_TRACK 2020-11-04 00:00:00 20201104 4STAR_20201104_002_TRACK\n",
      "4STAR_20201105_002_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 002_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_002_TRACK\n",
      "4STAR_20201105_008_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 008_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_008_TRACK\n",
      "4STAR_20201105_007_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 007_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_007_TRACK\n",
      "4STAR_20201105_012_TRACK.dat -> 4STAR 4STARboth_AmesRoof_Clear 012_TRACK 2020-11-05 00:00:00 20201105 4STAR_20201105_012_TRACK\n",
      "20201104_4STARB -> 4STARB 4STARboth_AmesRoof_Clear None 2020-11-04 00:00:00 20201104 20201104_4STARB\n",
      "4STARB_20201104_003_VIS_SKYA.dat -> 4STARB 4STARboth_AmesRoof_Clear 003_VIS_SKYA 2020-11-04 00:00:00 20201104 4STARB_20201104_003_VIS_SKYA\n",
      "4STARB_20201104_004_NIR_SKYP.dat -> 4STARB 4STARboth_AmesRoof_Clear 004_NIR_SKYP 2020-11-04 00:00:00 20201104 4STARB_20201104_004_NIR_SKYP\n",
      "4STARB_20201104_003_NIR_SKYA.dat -> 4STARB 4STARboth_AmesRoof_Clear 003_NIR_SKYA 2020-11-04 00:00:00 20201104 4STARB_20201104_003_NIR_SKYA\n",
      "4STARB_20201104_005_NIR_SUN.dat -> 4STARB 4STARboth_AmesRoof_Clear 005_NIR_SUN 2020-11-04 00:00:00 20201104 4STARB_20201104_005_NIR_SUN\n",
      "4STARB_20201104_001_VIS_SUN.dat -> 4STARB 4STARboth_AmesRoof_Clear 001_VIS_SUN 2020-11-04 00:00:00 20201104 4STARB_20201104_001_VIS_SUN\n",
      "4STARB_20201104_002_TRACK.dat -> 4STARB 4STARboth_AmesRoof_Clear 002_TRACK 2020-11-04 00:00:00 20201104 4STARB_20201104_002_TRACK\n",
      "4STARB_20201104_005_VIS_SUN.dat -> 4STARB 4STARboth_AmesRoof_Clear 005_VIS_SUN 2020-11-04 00:00:00 20201104 4STARB_20201104_005_VIS_SUN\n",
      "4STARB_20201104_001_NIR_SUN.dat -> 4STARB 4STARboth_AmesRoof_Clear 001_NIR_SUN 2020-11-04 00:00:00 20201104 4STARB_20201104_001_NIR_SUN\n",
      "4STARB_20201104_004_VIS_SKYP.dat -> 4STARB 4STARboth_AmesRoof_Clear 004_VIS_SKYP 2020-11-04 00:00:00 20201104 4STARB_20201104_004_VIS_SKYP\n",
      "20201112_4STARB_Quicklooks.pptx -> 4STARB None Quicklooks 2020-11-12 00:00:00 20201112 20201112_4STARB_Quicklooks\n"
     ]
    }
   ],
   "source": [
    "filters = get_filters_from_json(in_directory)\n",
    "fl_arr = recurse_through_dir(in_directory,verbose=verbose,filters=filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:28:04.033999Z",
     "start_time": "2020-12-03T22:28:02.982100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~Moving file from /data/sunsat/_incoming_gdrive/201115_201115_NASA_Ames.lev15\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_processed/aeronet/201115_201115_NASA_Ames.lev15\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201112_4STARsisters_AmesRoof/4STARB_20201112_003_NIR_SUN.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201112_4STARsisters_AmesRoof/4STARB_20201112_001_VIS_SUN.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201112_4STARsisters_AmesRoof/4STARB_20201112_004_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201112_4STARsisters_AmesRoof/4STARB_20201112_003_VIS_SUN.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201112_4STARsisters_AmesRoof/4STARB_20201112_002_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201112_4STARsisters_AmesRoof/4STARB_20201112_001_NIR_SUN.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/notes/20201112_4STARsisters_AmesRoof/20201113_notes.jpg, removing incoming file\n",
      "+Creating new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_008_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_008_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_013_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_013_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_003_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_003_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_016_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_016_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201112_001_NIR_SUN.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201112_001_NIR_SUN.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_012_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_012_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201112_002_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201112_002_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_004_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_004_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_007_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_007_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201112_001_VIS_SUN.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201112_001_VIS_SUN.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_009_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_009_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_006_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_006_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_005_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_005_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_002_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_002_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_014_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_014_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_011_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_011_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_010_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_010_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_001_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_001_TRACK.dat\n",
      "~Moving file from /data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA/4STAR_20201113_015_TRACK.dat\n",
      "   to new path: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201112_4STARsisters_AmesRoof/4STAR_20201113_015_TRACK.dat\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/quicklooks/20201104_4STAR_Quicklooks.pptx, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/quicklooks/20201104_4STARB_Quicklooks.pptx, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_005_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201104_001_NIR_SUN.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_006_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_014_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_003_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_013_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_001_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_009_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_004_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_011_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_010_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201104_001_VIS_SUN.dat, removing incoming file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201104_002_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_002_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_008_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_007_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STAR_20201104_4STARboth_AmesRoof_Clear/4STAR_20201105_012_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201104_4STARboth_AmesRoof_Clear/4STARB_20201104_003_VIS_SKYA.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201104_4STARboth_AmesRoof_Clear/4STARB_20201104_004_NIR_SKYP.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201104_4STARboth_AmesRoof_Clear/4STARB_20201104_003_NIR_SKYA.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201104_4STARboth_AmesRoof_Clear/4STARB_20201104_005_NIR_SUN.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201104_4STARboth_AmesRoof_Clear/4STARB_20201104_001_VIS_SUN.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201104_4STARboth_AmesRoof_Clear/4STARB_20201104_002_TRACK.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201104_4STARboth_AmesRoof_Clear/4STARB_20201104_005_VIS_SUN.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201104_4STARboth_AmesRoof_Clear/4STARB_20201104_001_NIR_SUN.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/data_raw/4STARB_20201104_4STARboth_AmesRoof_Clear/4STARB_20201104_004_VIS_SKYP.dat, removing incoming file\n",
      "Exact same file already exists at: /data/sunsat/rooftop/Fall_2020/quicklooks/20201112_4STARB_Quicklooks.pptx, removing incoming file\n"
     ]
    }
   ],
   "source": [
    "data_raw_found, data_raw_files, nexact, nmoved, ncreated, ndataraw =\\\n",
    "                move_files(fl_arr,filters,verbose=verbose,dry_run=dry_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:42:23.980565Z",
     "start_time": "2020-12-03T22:42:23.283401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded AERONET file: /data/sunsat/rooftop/Fall_2020/data_processed/aeronet/201112_201112_NASA_Ames.lev15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aeronet.py:198: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 198 of the file aeronet.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(html)\n"
     ]
    }
   ],
   "source": [
    "# check if there are raw data files, and if so, get the aeronet\n",
    "if data_raw_found:\n",
    "    daystrss = []\n",
    "    for k in data_raw_files.keys():\n",
    "        instname,daystr0 = k.split('_')\n",
    "        fa_tmp = filetypes('{daystr}_AERONET_NASA_Ames.lev15'.format(instname=instname,daystr=daystr0))\n",
    "        fmla_tmp = get_newfilepath(fa_tmp,filters=filters,fake_file=True)\n",
    "        if not daystr in daystrss:\n",
    "            daystrss.append(daystr0)\n",
    "            if fa_tmp.campaign.find('rooftop') >= 0:\n",
    "                aeronet_file = get_AERONET_file_v2(date=fa_tmp.fdate,site='NASA_Ames',path=str(fa_tmp.newpath))\n",
    "                if verbose: print('Downloaded AERONET file: {}'.format(aeronet_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T22:43:40.344512Z",
     "start_time": "2020-12-03T22:43:40.332707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-removing :/data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARB\n",
      "-removing :/data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof/20201112_4STARA\n",
      "-removing :/data/sunsat/_incoming_gdrive/20201112_4STARsisters_AmesRoof\n",
      "-removing :/data/sunsat/_incoming_gdrive/20201104_4STARboth_AmesRoof_Clear/20201104_4STARA\n",
      "-removing :/data/sunsat/_incoming_gdrive/20201104_4STARboth_AmesRoof_Clear/20201104_4STARB\n",
      "-removing :/data/sunsat/_incoming_gdrive/20201104_4STARboth_AmesRoof_Clear\n"
     ]
    }
   ],
   "source": [
    "# clean up folders after move\n",
    "for dirpath, dirnames, filenames in os.walk(in_directory,topdown=False):\n",
    "    if not dirpath in in_directory:\n",
    "        try: \n",
    "            if verbose: print( '{pre}-removing :{path}'.format(pre=prefix,path=dirpath))\n",
    "            if not dry_run:\n",
    "                os.rmdir(dirpath) \n",
    "        except: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T23:10:29.477770Z",
     "start_time": "2020-12-03T23:10:29.399295Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*DRY RUN*: matlab -nodisplay -batch temp\n"
     ]
    }
   ],
   "source": [
    "nmats = 0\n",
    "if run_matlab:\n",
    "    prefix = '*DRY RUN*: ' if dry_run else ''\n",
    "    for dr,drs in data_raw_files.items():\n",
    "        # get the position of the new star.mat and starsun.mat files\n",
    "        f = filetypes('{}star.mat'.format(dr),filters=filters)\n",
    "        fml = get_newfilepath(f,filters=filters,fake_file=True)\n",
    "        if not dry_run: f.newpath.mkdir(parents=True,exist_ok=True)\n",
    "        fs = filetypes('{}starsun.mat'.format(dr),filters=filters)\n",
    "        fmls = get_newfilepath(fs,filters=filters,fake_file=True)\n",
    "        if not dry_run: fs.newpath.mkdir(parents=True,exist_ok=True)\n",
    "            \n",
    "        # make the position of the new quicklook file\n",
    "        instname,daystr = dr.split('_')\n",
    "        fq = filetypes('{daystr}_{instname}_Quicklooks.pptx'.format(instname=instname,daystr=daystr))\n",
    "        fmlq = get_newfilepath(fq,filters=filters,fake_file=True)\n",
    "        if not dry_run: fq.newpath.mkdir(parents=True,exist_ok=True)\n",
    "        \n",
    "        # make the position of the new figure files\n",
    "        ff = filetypes('{daystr}_{instname}_plots.png'.format(instname=instname,daystr=daystr))\n",
    "        fmlf = get_newfilepath(ff,filters=filters,fake_file=True)\n",
    "        if not dry_run: ff.newpath.parent.mkdir(parents=True,exist_ok=True)\n",
    "        \n",
    "        # make the position of the aeronet files\n",
    "        fa = filetypes('{daystr}_AERONET_NASA_Ames.lev15'.format(instname=instname,daystr=daystr))\n",
    "        fmla = get_newfilepath(fa,filters=filters,fake_file=True)\n",
    "        if not dry_run: fa.newpath.mkdir(parents=True,exist_ok=True)\n",
    "        \n",
    "        # make the position of the gas_summary files\n",
    "        fg = filetypes('{instname}_{daystr}_gas_summary.mat'.format(instname=instname,daystr=daystr))\n",
    "        fmlg = get_newfilepath(fg,filters=filters,fake_file=True)\n",
    "        if not dry_run: fg.newpath.mkdir(parents=True,exist_ok=True)\n",
    "        \n",
    "        # make a string of the raw files    \n",
    "        filelist = \"'\"+\"';'\".join(drs)+\"'\"\n",
    "        if not f.instname in ['4STAR','4STARB']: # only for 4STARs for now.\n",
    "            continue\n",
    "            \n",
    "        mfile = make_temp_mfile(in_directory+'temp.m',filelist=filelist,starmat=str(f.newfile),\\\n",
    "                                starsun=str(fs.newfile),quicklooks=in_directory+str(fq.newfile.name),\\\n",
    "                                fig_path=str(ff.newpath.parent)+'/', aero_path=str(fa.newpath)+'/',\\\n",
    "                                gas_path=str(fg.newpath)+'/', sun_path=str(fs.newpath)+'/',incoming_path=in_directory)\n",
    "\n",
    "        if verbose: \n",
    "            print( ' '.join(['{}matlab'.format(prefix),'-nodisplay','-batch',\"{}\".format(Path(mfile).stem)]))\n",
    "        if not dry_run:\n",
    "            pmfile = Path(mfile)\n",
    "            os.chdir(str(pmfile.parent))\n",
    "            process = subprocess.Popen(['matlab','-nodisplay','-batch',\"{}\".format(pmfile.stem)],\n",
    "                                       shell=False, stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "\n",
    "            while True:\n",
    "                # handle output by direct access to stdout and stderr\n",
    "                output = process.stdout.readline()\n",
    "                if process.poll() is not None:\n",
    "                    break\n",
    "                if output:\n",
    "                    if verbose: print(output.strip())\n",
    "            rc = process.poll()\n",
    "            if verbose: print(rc)\n",
    "            nmats = nmats + 1\n",
    "                \n",
    "            if rc==0:\n",
    "                os.remove(mfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T18:24:19.683110Z",
     "start_time": "2020-12-03T18:24:19.674344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thu Dec  3 10:24:19 2020'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datetime.now().strftime(\"%c\")+' :Python moved {nmoved} files, Created {ncreated} folders, found {ndataraw} files, and generated {nmats} starmats/suns'\\\n",
    "      .format(nmoved=nmoved,ncreated=ncreated,ndataraw=ndataraw,nmats=nmats))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
