{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Name:  \n",
    "\n",
    "    DARE_AAC_spread\n",
    "\n",
    "Purpose:  \n",
    "\n",
    "    For MeloÃ«'s study for global DARE, using calipso, MODIS, and other measurements of Aerosol above clouds\n",
    "    Prep and read the radiative transfer files to run the \n",
    "  \n",
    "Input:\n",
    "\n",
    "    none\n",
    "\n",
    "Output:\n",
    "   \n",
    "    plots\n",
    "  \n",
    "Keywords:\n",
    "\n",
    "    none\n",
    "  \n",
    "Dependencies:\n",
    "\n",
    "    - numpy\n",
    "    - scipy : for saving and reading\n",
    "    - Run_libradtran\n",
    "\n",
    "  \n",
    "Needed Files:\n",
    "\n",
    "  - matlab input files: Input_to_DARF_mmm.mat\n",
    "  - spread of the data information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the required modules and file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T01:27:11.072009Z",
     "start_time": "2018-01-31T01:27:10.742554Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import Run_libradtran as RL\n",
    "import load_utils as lm\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "import signal\n",
    "from copy import copy,deepcopy\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T01:42:19.895733Z",
     "start_time": "2018-01-31T01:42:19.893304Z"
    }
   },
   "outputs": [],
   "source": [
    "std_label = 'v4_spread'\n",
    "verbose = False\n",
    "imax = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T01:42:23.904825Z",
     "start_time": "2018-01-31T01:42:23.901216Z"
    }
   },
   "outputs": [],
   "source": [
    "fp = '/u/sleblan2/meloe_AAC/' + std_label + '/'\n",
    "fp_alb = '/nobackup/sleblan2/AAC_DARF/surface_albedo/'\n",
    "fp_out = '/nobackup/sleblan2/AAC_DARF/input/' + std_label + '/'\n",
    "fp_pmom = '/nobackup/sleblan2/AAC_DARF/rtm/'\n",
    "fp_uvspec = '/u/sleblan2/libradtran/libRadtran-2.0-beta/bin/uvspec'\n",
    "wvl_thm = '/nobackup/sleblan2/AAC_DARF/rtm/wvl.thm.dat'\n",
    "vv = 'v3_20170616_CALIOP_AAC_AODxfAAC_With_Without_Sa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if reading or writing and input arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T01:27:13.348188Z",
     "start_time": "2018-01-31T01:27:13.332609Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-doread] [-dowrite] [-i INDEX] [-tmp]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/sleblanc/.local/share/jupyter/runtime/kernel-afe65769-e38e-40a1-8c3c-a33b9f67be56.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "long_description = \"\"\"    Prepare or read the AAC DARE calculations, with the spread for all values.\n",
    "      - defaults to prepare AAC files \"\"\"\n",
    "parser = argparse.ArgumentParser(description=long_description)\n",
    "parser.add_argument('-r','--doread',help='if set, will only read the output, not produce them',\n",
    "                    action='store_true',default=False)\n",
    "parser.add_argument('-w','--dowrite',help='if set, will write the input and list files for fuliou',\n",
    "                    action='store_true',default=False)\n",
    "parser.add_argument('-s','--shortread',help='if set, will only read the available files outputted in the fp_output file pat',\n",
    "                    action='store_true',default=False)\n",
    "parser.add_argument('-i','--index',help='index (from 0 to 36) to split up the work on each node/ COD',type =int)\n",
    "#parser.add_argument('-i','--index',help='Sets the index of the pixel file to use (19374,22135). Default is 0',type=int)\n",
    "#parser.add_argument('-t','--tmp_folder',help='Set to use the temporary folder',action='store_true',default=False)\n",
    "parser.add_argument('-t','--tmp_folder',nargs='?',help='The path to the temp directory to use')\n",
    "parser.add_argument('-v','--verbose',help='If set, outputs comments about the progress',action='store_true',default=False)\n",
    "parser.add_argument('-j','--splitindex',\n",
    "                    help='add extra level of index splitting, on addition to -i, split up the work on each node /COD and per 10/ext',action='store_true',default=False)\n",
    "parser.add_argument('-m','--match',help='if set, matches the index value to all other ext, ssa, asy, for use in debugging',action='store_true',default=False)\n",
    "in_ = vars(parser.parse_args())\n",
    "doread = in_.get('doread',False)\n",
    "dowrite = in_.get('dowrite',False)\n",
    "i = in_.get('index',0)\n",
    "shortread = in_.get('shortread',False)\n",
    "verbose = in_.get('verbose',False)\n",
    "j_index = in_.get('splitindex',False)\n",
    "match = in_.get('match',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_.get('tmp_folder'):\n",
    "    tmp_folder = in_.get('tmp_folder')\n",
    "    tmp = True\n",
    "else:\n",
    "    tmp = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T01:42:27.600338Z",
     "start_time": "2018-01-31T01:42:27.597281Z"
    }
   },
   "outputs": [],
   "source": [
    "if i>0:\n",
    "    if j_index:\n",
    "        std_label = std_label+'_{:02.0f}_e{:02.0f}'.format(i%imax,i/imax)\n",
    "    else:\n",
    "        std_label = std_label+'_{:02.0f}'.format(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T01:42:28.072770Z",
     "start_time": "2018-01-31T01:42:28.070358Z"
    }
   },
   "outputs": [],
   "source": [
    "if tmp:\n",
    "    fp_out = tmp_folder+'/AAC_DARF/input/' + std_label + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T01:42:28.464356Z",
     "start_time": "2018-01-31T01:42:28.461125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v4_spread_03'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if verbose: \n",
    "    print 'Running on folders: {}'.format(fp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the input files and create the subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-22T17:46:41.902840Z",
     "start_time": "2018-01-22T17:46:41.900371Z"
    }
   },
   "outputs": [],
   "source": [
    "mmm = 'JJA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-22T17:51:56.881806Z",
     "start_time": "2018-01-22T17:51:56.877879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in JJA months, getting mat file: /mnt/c/Users/sleblanc/Research/Calipso/meloe/v3_without/Input_to_DARF_JJA_v3_20170616_CALIOP_AAC_AODxfAAC_With_Without_Sa.mat\n"
     ]
    }
   ],
   "source": [
    "fpm = fp+'Input_to_DARF_{mmm}_{vv}.mat'.format(mmm=mmm,vv=vv)\n",
    "if verbose:\n",
    "    print 'in %s months, getting mat file: %s' % (mmm,fpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-22T17:51:57.722306Z",
     "start_time": "2018-01-22T17:51:57.653625Z"
    }
   },
   "outputs": [],
   "source": [
    "input_mmm = sio.loadmat(fpm,mat_dtype=True)['data_input_darf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-22T18:23:05.250865Z",
     "start_time": "2018-01-22T18:23:05.245403Z"
    }
   },
   "outputs": [],
   "source": [
    "geo = {'zout':[0,3,100],'year':2007,'day':15,'minute':0,'second':0}\n",
    "geo['month'] = 7\n",
    "doy = 225\n",
    "aero = {'z_arr':[3.0,4.0]}\n",
    "cloud = {'ztop':3.0,'zbot':2.0,'phase':'wc','write_moments_file':True}\n",
    "source = {'integrate_values':True,'dat_path':'/u/sleblan2/libradtran/libRadtran-2.0-beta/data/','run_fuliou':True}\n",
    "albedo = {'create_albedo_file':False}\n",
    "albedo['sea_surface_albedo'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-22T17:52:01.163038Z",
     "start_time": "2018-01-22T17:52:01.160270Z"
    }
   },
   "outputs": [],
   "source": [
    "geo['lat'],geo['lon'] = -7.0,-10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-22T18:21:22.074282Z",
     "start_time": "2018-01-22T18:21:22.070715Z"
    }
   },
   "outputs": [],
   "source": [
    "ia1,ia2,io1,io2 = 16,25,35,39\n",
    "ilat = np.arange(18,26)\n",
    "ilon = np.arange(37,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T19:44:29.006413Z",
     "start_time": "2018-01-23T19:44:29.000304Z"
    }
   },
   "outputs": [],
   "source": [
    "cod = input_mmm['MODIS_COD_mean'][0,0][ia1:ia2,io1:io2].flatten(order='F')\n",
    "ext = np.append(np.abs(input_mmm['MOC_ext_mean'][0,0][ia1:ia2,io1:io2,:]).reshape([36,30],order='F'),np.zeros([1,30]),axis=0)\n",
    "ssa = input_mmm['MOC_ssa_mean'][0,0][ia1:ia2,io1:io2,:].reshape([36,30],order='F')\n",
    "asy = input_mmm['MOC_asym_mean'][0,0][ia1:ia2,io1:io2,:].reshape([36,30],order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-22T19:06:02.843830Z",
     "start_time": "2018-01-22T19:06:02.840071Z"
    }
   },
   "outputs": [],
   "source": [
    "cloud['ref'] = np.nanmean(input_mmm['MODIS_effrad_mean'][0,0][ia1:ia2,io1:io2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmom_solar = RL.make_pmom_inputs(fp_rtm=fp_pmom,source='solar',deltascale=False)\n",
    "pmom_thermal = RL.make_pmom_inputs(fp_rtm=fp_pmom,source='thermal')\n",
    "max_nmom=20\n",
    "pmom_solar['max_nmoms'] = max_nmom\n",
    "pmom_thermal['max_nmoms'] = max_nmom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the writing out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_fp_output = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_out2 = fp_out+mmm+std_label+'/'\n",
    "if not os.path.exists(fp_out2):\n",
    "    os.makedirs(fp_out2)\n",
    "if change_fp_output:\n",
    "    fp_output = fp_out2.replace('input','output')\n",
    "    if not os.path.exists(fp_output):\n",
    "        os.makedirs(fp_output)\n",
    "fp_base_file = fp_out2+'base.inp'\n",
    "make_base = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dowrite: \n",
    "    ff = 'AAC_list_file_{m}_{v}{lbl}.sh'.format(m=mmm,v=vv,lbl=std_label)\n",
    "    file_list = file(fp_pmom+ff,'w')\n",
    "    if verbose: \n",
    "        print 'Starting list file: '\n",
    "    print fp_pmom+ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T22:31:33.049955Z",
     "start_time": "2018-01-23T22:31:33.046043Z"
    }
   },
   "outputs": [],
   "source": [
    "aero['wvl_arr'] = input_mmm['MOC_wavelengths'][0,0][0,:]*1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if i>0:\n",
    "    if j_index:\n",
    "        codd = [cod[i%imax]]\n",
    "        iee = np.arange((i/imax)*4,(i/imax+1)*4)\n",
    "        if (i/imax+1)*4 > 33:\n",
    "             iee = np.arange((i/imax)*4,37)\n",
    "    else:\n",
    "        codd = [cod[i]]\n",
    "        iee = np.arange(0,37)\n",
    "else:\n",
    "    codd = cod\n",
    "    iee = np.arange(0,37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if match:\n",
    "    iee = [i]\n",
    "\n",
    "if verbose:\n",
    "    print 'Running through the permutations'\n",
    "b = []\n",
    "first_time = True\n",
    "for icod,c in enumerate(codd):\n",
    "    if i>0: icod = i\n",
    "    dd = {}\n",
    "    # set the cloud values\n",
    "    cloud['tau'] = c\n",
    "    try: cloud['tau'][cloud['tau']<0.0] = 0.0\n",
    "    except: pass\n",
    "    try: cloud['ref'][cloud['ref']<2.0] = 2.0\n",
    "    except: pass\n",
    "    \n",
    "    cloud_file_name_sol = fp_out2+'AAC_input_cod%02i_%s_sol.inp_cloud' % (icod,mmm)\n",
    "    cloud_file_name_thm = fp_out2+'AAC_input_cod%02i_%s_thm.inp_cloud' % (icod,mmm)\n",
    "    \n",
    "    dd['cld_f_sol'] = copy(cloud_file_name_sol)\n",
    "    dd['cld_f_thm'] = copy(cloud_file_name_thm)\n",
    "\n",
    "    if dowrite:\n",
    "        RL.write_cloud_file_moments(cloud_file_name_sol,cloud['tau'],cloud['ref'],cloud['zbot'],cloud['ztop'],\n",
    "                                    verbose=verbose,moms_dict=pmom_solar,wvl_range=[250,5600])\n",
    "        RL.write_cloud_file_moments(cloud_file_name_thm,cloud['tau'],cloud['ref'],cloud['zbot'],cloud['ztop'],\n",
    "                                    verbose=verbose,moms_dict=pmom_thermal,wvl_range=[4000,50000-1])\n",
    "    dd['cod'],dd['ref'],dd['zbot'],dd['ztop'] = copy(cloud['tau']),copy(cloud['ref']),copy(cloud['zbot']),copy(cloud['ztop'])\n",
    "    \n",
    "    if aero['wvl_arr'].max()<100000.0:\n",
    "        aero['wvl_arr'] = np.append(aero['wvl_arr'],100000.0)\n",
    "    \n",
    "    for iext,e in enumerate(ext):\n",
    "        if not iext in iee:\n",
    "            continue\n",
    "        # set the aerosol values\n",
    "        aero['ext'] = e\n",
    "        aero['ext'][aero['ext']<0.0] = 0.0\n",
    "        if np.isnan(aero['ext']).all():\n",
    "            if verbose:\n",
    "                print 'skipping cod:%i, ext:%i' % (icod,iext)\n",
    "            continue\n",
    "        if not len(aero['ext'])==len(aero['wvl_arr']):\n",
    "            aero['ext'] = np.append(aero['ext'],e[-1])\n",
    "        for issa,s in enumerate(ssa):\n",
    "            if match:\n",
    "                if not issa in iee:\n",
    "                    continue\n",
    "            aero['ssa'] = s\n",
    "            try: aero['ssa'][aero['ssa']<0.0] = 0.0\n",
    "            except: pass\n",
    "            try: aero['ssa'][aero['ssa']>1.0] = 1.0\n",
    "            except: pass\n",
    "            if not len(aero['ssa'])==len(aero['wvl_arr']):\n",
    "                aero['ssa'] = np.append(aero['ssa'],s[-1])\n",
    "            for iasy,a in enumerate(asy):\n",
    "                if match:\n",
    "                    if not iasy in iee:\n",
    "                        continue\n",
    "                aero['asy'] = a\n",
    "\n",
    "                #sanitize inputs after adding subtracting standard deviations\n",
    "                try: aero['asy'][aero['asy']<0.0] = 0.0\n",
    "                except: pass\n",
    "                try: aero['asy'][aero['asy']>1.0] = 1.0\n",
    "                except: pass\n",
    "                if not len(aero['asy'])==len(aero['wvl_arr']):\n",
    "                    aero['asy'] = np.append(aero['asy'],a[-1])\n",
    "                \n",
    "                aero['file_name'] = fp_out2+'AAC_input_cod%02i_ext%02i_ssa%02i_asy%02i_%s_sol.inp_aero' % (icod,iext,issa,iasy,mmm)\n",
    "                dd['aero'] = deepcopy(aero)\n",
    "                \n",
    "                fsol = []\n",
    "                fthm = []\n",
    "                \n",
    "                fsol_o = []\n",
    "                fthm_o = []\n",
    "                \n",
    "                for HH in xrange(24):\n",
    "                    geo['hour'] = HH\n",
    "                    #build the solar input file\n",
    "                    source['source'] = 'solar'\n",
    "                    source['wvl_range'] = [250,5600]\n",
    "                    source['wvl_filename'] = None\n",
    "                    file_out_sol = fp_out2+'AAC_input_cod%02i_ext%02i_ssa%02i_asy%02i_%s_HH%02i_sol.inp' % (icod,iext,issa,iasy,mmm,HH)\n",
    "                    fsol.append(file_out_sol)\n",
    "                    fsol_o.append(fp_output+'AAC_input_cod%02i_ext%02i_ssa%02i_asy%02i_%s_HH%02i_sol.out' % (icod,iext,issa,iasy,mmm,HH))\n",
    "                    \n",
    "                    #build the thermal input file\n",
    "                    source['source'] = 'thermal'\n",
    "                    source['wvl_range'] = [4000,50000-1]\n",
    "                    source['wvl_filename'] = None\n",
    "                    file_out_thm = fp_out2+'AAC_input_cod%02i_ext%02i_ssa%02i_asy%02i_%s_HH%02i_thm.inp' % (icod,iext,issa,iasy,mmm,HH)\n",
    "                    fthm.append(file_out_thm)\n",
    "                    fthm_o.append(fp_output+'AAC_input_cod%02i_ext%02i_ssa%02i_asy%02i_%s_HH%02i_thm.out' % (icod,iext,issa,iasy,mmm,HH))\n",
    "                    \n",
    "                    if dowrite:\n",
    "                        file_list.write(fp_uvspec+' < \"'+file_out_sol+'\" > \"'+fp_output\n",
    "                                    +'AAC_input_cod%02i_ext%02i_ssa%02i_asy%02i_%s_HH%02i_sol.out\"\\n' % (icod,iext,issa,iasy,mmm,HH))\n",
    "                        file_list.write(fp_uvspec+' < \"'+file_out_thm+'\" > \"'+fp_output\n",
    "                                    +'AAC_input_cod%02i_ext%02i_ssa%02i_asy%02i_%s_HH%02i_thm.out\"\\n' % (icod,iext,issa,iasy,mmm,HH))\n",
    "                        if first_time:\n",
    "                            cloud['link_to_mom_file'],cloud['file_name'] = True,cloud_file_name_sol\n",
    "                            RL.write_input_aac(file_out_sol,geo=geo,aero=aero,cloud=cloud,source=source,albedo=albedo,verbose=False,\n",
    "                                               make_base=True,fp_base_file=fp_base_file,set_quiet=True,solver='rodents')\n",
    "                            first_time = False\n",
    "        \n",
    "\n",
    "                #print mmm,icod,iext,issa,iasy\n",
    "                dd['geo'],dd['source'],dd['albedo'],dd['fp_base_file'] = deepcopy(geo),deepcopy(source),deepcopy(albedo),fp_base_file\n",
    "                dd['fsol'],dd['fthm'],dd['fsol_o'],dd['fthm_o'] = fsol[:],fthm[:],fsol_o[:],fthm_o[:]\n",
    "                dd['icod'],dd['iext'],dd['issa'],dd['iasy'],dd['mmm'] = copy(icod),copy(iext),copy(issa),copy(iasy),copy(mmm)\n",
    "                b.append(deepcopy(dd))\n",
    "if dowrite: file_list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    pbar = tqdm(total=len(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for use in this program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init():\n",
    "    # ignore the SIGINI in sub process, just print a log\n",
    "    def sig_int(signal_num, frame):\n",
    "        if verbose: \n",
    "            print 'signal: %s' % signal_num\n",
    "        raise IOError\n",
    "    signal.signal(signal.SIGINT, sig_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_input_aac_24h(d):\n",
    "    'function to print out the 24hour files (sol and thm) from an input dict'\n",
    "    cloud = {'tau':d['cod'],'ref':d['ref'],'zbot':d['zbot'],'ztop':d['ztop'],\n",
    "             'link_to_mom_file':True,'phase':'wc','write_moments_file':True}\n",
    "    geo = d['geo']\n",
    "    source = d['source']\n",
    "    albedo = d['albedo']\n",
    "    fp_base_file = d['fp_base_file']\n",
    "    aero = d['aero']\n",
    "    aero['link_to_mom_file'] = False\n",
    "    \n",
    "    #print 'fname: {fsol[0]}, iext: {iext}, issa: {issa}, iasy: {iasy}'.format(**d)\n",
    "    \n",
    "    for HH in xrange(24):\n",
    "        geo['hour'] = HH\n",
    "        #build the solar input file\n",
    "        source['source'] = 'solar'\n",
    "        source['wvl_range'] = [250,5600]\n",
    "        source['wvl_filename'] = None\n",
    "        file_out_sol = d['fsol'][HH]\n",
    "        cloud['file_name'] = d['cld_f_sol']\n",
    "        RL.write_input_aac(file_out_sol,geo=geo,aero=aero,cloud=cloud,source=source,albedo=albedo,verbose=False,\n",
    "                           make_base=False,fp_base_file=fp_base_file,set_quiet=True,solver='rodents')\n",
    "        \n",
    "        #build the thermal input file\n",
    "        source['source'] = 'thermal'\n",
    "        source['wvl_range'] = [4000,50000-1]\n",
    "        source['wvl_filename'] = None\n",
    "        file_out_thm = d['fthm'][HH]\n",
    "        cloud['file_name'] = d['cld_f_thm']\n",
    "        \n",
    "        RL.write_input_aac(file_out_thm,geo=geo,aero=aero,cloud=cloud,source=source,albedo=albedo,verbose=False,\n",
    "                           make_base=False,fp_base_file=fp_base_file,set_quiet=True,solver='rodents')\n",
    "\n",
    "        if not aero['link_to_mom_file']:\n",
    "            aero['link_to_mom_file'] = True\n",
    "        if verbose:\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_aac_24h(d):\n",
    "    'function to read out the 24hour files (sol and thm) from an input dict'\n",
    "\n",
    "    zout=[0,3,100]\n",
    "    nz = len(zout)\n",
    "    output = {'zout':zout,'ext':d['aero']['ext'],'asy':d['aero']['asy'],'ssa':d['aero']['ssa']}\n",
    "    output['SW_irr_dn_utc'] = np.zeros((nz,24))\n",
    "    output['SW_irr_up_utc'] = np.zeros((nz,24))\n",
    "    output['LW_irr_dn_utc'] = np.zeros((nz,24))\n",
    "    output['LW_irr_up_utc'] = np.zeros((nz,24))  \n",
    "    \n",
    "    for HH in xrange(24):\n",
    "        geo['hour'] = HH\n",
    "        file_out_sol = d['fsol_o'][HH]\n",
    "        file_out_thm = d['fthm_o'][HH]\n",
    "        try:\n",
    "            sol = RL.read_libradtran(file_out_sol,zout=zout)\n",
    "            thm = RL.read_libradtran(file_out_thm,zout=zout)\n",
    "        except IOError:\n",
    "            print 'File not found skip: cod%02i_ext%02i_ssa%02i_asy%02i_%s_HH%02i' %(d['icod'],d['iext'],d['issa'],d['iasy'],d['mmm'],HH)\n",
    "            if HH==0:\n",
    "                print file_out_sol\n",
    "            continue\n",
    "        except ValueError:\n",
    "            print 'Problem with file: cod%02i_ext%02i_ssa%02i_asy%02i_%s_HH%02i' %(d['icod'],d['iext'],d['issa'],d['iasy'],d['mmm'],HH)\n",
    "            output['SW_irr_dn_utc'][:,HH] = np.nan\n",
    "            output['SW_irr_up_utc'][:,HH] = np.nan\n",
    "            output['LW_irr_dn_utc'][:,HH] = np.nan\n",
    "            output['LW_irr_up_utc'][:,HH] = np.nan\n",
    "            continue\n",
    "        output['SW_irr_dn_utc'][:,HH] = sol['direct_down']+sol['diffuse_down']\n",
    "        output['SW_irr_up_utc'][:,HH] = sol['diffuse_up']\n",
    "\n",
    "        output['LW_irr_dn_utc'][:,HH] = thm['direct_down']+thm['diffuse_down']\n",
    "        output['LW_irr_up_utc'][:,HH] = thm['diffuse_up']\n",
    "\n",
    "    output['SW_irr_dn_avg'] = np.mean(output['SW_irr_dn_utc'],axis=1)\n",
    "    output['SW_irr_up_avg'] = np.mean(output['SW_irr_up_utc'],axis=1)\n",
    "    output['LW_irr_dn_avg'] = np.mean(output['LW_irr_dn_utc'],axis=1)\n",
    "    output['LW_irr_up_avg'] = np.mean(output['LW_irr_up_utc'],axis=1)\n",
    "    if verbose:\n",
    "        pbar.update(1)\n",
    "\n",
    "    return output        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core of the reading/writing routines, calling pool of workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dowrite:\n",
    "    if verbose:\n",
    "        print 'Now preparing the pool of workers and making them print the files'\n",
    "    p = Pool(cpu_count(),worker_init)\n",
    "    results = p.map(print_input_aac_24h,b)\n",
    "    p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doread:\n",
    "    il = len(b)\n",
    "    if shortread:\n",
    "        ll = os.listdir(fp_output)\n",
    "        il = len(ll)\n",
    "        if verbose:\n",
    "            print 'Only reading over {} files'.format(il)\n",
    "    \n",
    "    if verbose:\n",
    "        print 'Now preparing the pool of workers and making them read all the files'\n",
    "    p = Pool(cpu_count(),worker_init)\n",
    "    results = p.map(read_input_aac_24h,b[0:il])\n",
    "    p.close()\n",
    "    \n",
    "    nm_list = {'SW_irr_dn_avg':'SW_irr_dn_avg','SW_irr_up_avg':'SW_irr_up_avg',\n",
    "               'LW_irr_dn_avg':'LW_irr_dn_avg','LW_irr_up_avg':'LW_irr_up_avg',\n",
    "               'ssa':'ssa','asy':'asy','ext':'ext'}\n",
    "    saves = {}\n",
    "    for a in nm_list.keys():\n",
    "        saves[a] = np.array([results[n][nm_list[a]] for n in xrange(il)])\n",
    "\n",
    "    saves['geo'] = geo\n",
    "    saves['source'] = source\n",
    "    saves['source']['wvl_filename'] = []\n",
    "    saves['albedo'] = albedo\n",
    "    saves['cloud'] = cloud\n",
    "    \n",
    "    fp_save = fp+'AAC_spread_{m}_{v}_{i}.mat'.format(m=mmm,v=vv,i=i)\n",
    "    try:\n",
    "        if j_index:\n",
    "            fp_save = fp+'AAC_spread_{m}_{v}_{i}_e{j}.mat'.format(m=mmm,v=vv,i=i%imax,j=i/imax)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if verbose:\n",
    "        print 'Saving read file: '+fp_save\n",
    "    sio.savemat(fp_save,saves)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
