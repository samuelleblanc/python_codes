{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info\n",
    "Purpose:\n",
    "\n",
    "    collection of utilities for handling some common numerical analysis\n",
    "\n",
    "Input:\n",
    "\n",
    "    see particular functions\n",
    "\n",
    "Output:\n",
    "\n",
    "    see functions\n",
    "\n",
    "Dependencies:\n",
    "\n",
    "    - load_utils.py\n",
    "    - matplotlib\n",
    "    - numpy\n",
    "    - Sp_parameters\n",
    "    - write_utils\n",
    "    - path_utils\n",
    "    - hdf5storage\n",
    "    - scipy\n",
    "\n",
    "Needed Files:\n",
    "  - file.rc : for consistent creation of look of matplotlib figures\n",
    "  - ...\n",
    "\n",
    "Modification History:\n",
    "\n",
    "    Written: Samuel LeBlanc, Santa Cruz, CA, 2021-02-02\n",
    "    Modified:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__():\n",
    "    \"\"\"\n",
    "       Collection of codes to do common tasks in numerical analysis of various data\n",
    "           \n",
    "        details are in the info of each module\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import scipy.stats as st\n",
    "    from scipy import interpolate\n",
    "    import map_utils as mu\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_std(x,n):\n",
    "    'Function to do a running standard deviation on array (x) with window size (n)'\n",
    "    q = x**2\n",
    "    q = np.convolve(q, np.ones((n, )), mode=\"same\")\n",
    "    s = np.convolve(x, np.ones((n, )), mode=\"same\")\n",
    "    o = (q-s**2/n)/float(n-1)\n",
    "    return o "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments(index,vals_dict,nsep=150,set_nan=True):\n",
    "    'Function to seperate continuous segments (within a distance of nsep) based on a prior index'\n",
    "    disc_flacaod_long = np.where(np.diff(index,1)>nsep)[0]\n",
    "    \n",
    "    discontinuity_istart_long =  index[np.append(0,disc_flacaod_long[:-1]+1)]\n",
    "    discontinuity_iend_long =  index[disc_flacaod_long]\n",
    "    \n",
    "    kv = vals_dict.keys()\n",
    "    d = {k:[] for k in kv}\n",
    "    for i,start in enumerate(discontinuity_istart_long): # loop through discontinuities \n",
    "        if discontinuity_iend_long[i]-start < 2: continue\n",
    "        for k in kv: # loop through keys\n",
    "            try:\n",
    "                d[k].append(vals_dict[k][start:discontinuity_iend_long[i]])\n",
    "            except:\n",
    "                print start, discontinuity_iend_long[i]\n",
    "                continue\n",
    "                #d[k].append([np.nan])\n",
    "    \n",
    "    for k in kv:\n",
    "        d[k] = np.array(d[k])\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segments_by_time(index,doys,vals_dict,tsep=5.0/24.0/60.0/60.0,set_nan=True):\n",
    "    'Function to seperate continuous segments (within a distance in doys of tsep) based on a prior index (default for 5 seconds in doy)'\n",
    "    disc_flacaod_long = np.where(np.diff(doys[index],1)>tsep)[0]\n",
    "    \n",
    "    discontinuity_istart_long =  index[np.append(0,disc_flacaod_long[:-1]+1)]\n",
    "    discontinuity_iend_long =  index[disc_flacaod_long]\n",
    "    \n",
    "    kv = vals_dict.keys()\n",
    "    d = {k:[] for k in kv}\n",
    "    for i,start in enumerate(discontinuity_istart_long): # loop through discontinuities \n",
    "        if discontinuity_iend_long[i]-start < 2: continue\n",
    "        for k in kv: # loop through keys\n",
    "            try:\n",
    "                d[k].append(vals_dict[k][start:discontinuity_iend_long[i]])\n",
    "            except:\n",
    "                print start, discontinuity_iend_long[i]\n",
    "                continue\n",
    "                #d[k].append([np.nan])\n",
    "    \n",
    "    for k in kv:\n",
    "        d[k] = np.array(d[k])\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(seg_dict):\n",
    "    'Function that calculates the cumulative distance and instantaneous change between each point for a set of segments'\n",
    "    seg_dict['dist'],seg_dict['cumdist'] = [],[]\n",
    "    for i,l in enumerate(seg_dict['lat']):\n",
    "        try:\n",
    "            ckm,km = [],[]\n",
    "            pos1 = [seg_dict['lat'][i][0],seg_dict['lon'][i][0]] \n",
    "            for j,a in enumerate(seg_dict['lat'][i]):\n",
    "                d = mu.spherical_dist(pos1,[seg_dict['lat'][i][j],seg_dict['lon'][i][j]])\n",
    "                ckm.append(d)\n",
    "                km.append(d)\n",
    "        except:\n",
    "            cckm,dkm = [np.nan],[np.nan]\n",
    "\n",
    "        iu = np.where(np.isfinite(ckm))[0]\n",
    "        try:\n",
    "            fckm = interpolate.interp1d(seg_dict['utc'][i][iu],np.array(ckm)[iu])\n",
    "            fkm = interpolate.interp1d(seg_dict['utc'][i][iu],np.array(km)[iu])\n",
    "            cckm = fckm(seg_dict['utc'][i])\n",
    "            dkm = fkm(seg_dict['utc'][i])\n",
    "            seg_dict['cumdist'].append(np.array(cckm))\n",
    "            seg_dict['dist'].append(np.array(np.diff(dkm)))\n",
    "        except:\n",
    "            seg_dict['cumdist'].append(np.array(np.nan))\n",
    "            seg_dict['dist'].append(np.array(np.nan))\n",
    "\n",
    "    return seg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx_autocor(plus_dist,minus_dist,min_num=100):\n",
    "    'Function to calculate the autocorrelation from 2 populations of the same distribution - plus and minus'\n",
    "    # minus_dist = corr_all[j][0][ik][val]\n",
    "    # plus_dist = corr_all[j][1][ik][val]\n",
    "    mmk = np.nanmean(minus_dist)\n",
    "    mpk = np.nanmean(plus_dist)\n",
    "    smk = np.nanstd(minus_dist)\n",
    "    spk = np.nanstd(plus_dist)\n",
    "    top = [(v-mpk)*(plus_dist[iv]-mmk) for iv,v in enumerate(minus_dist)]\n",
    "    #print val,ik,j,mmk,mpk,smk,spk,np.nansum(top)\n",
    "    autocorr = np.nansum(top)/((len(minus_dist)-1)*spk*smk)\n",
    "    autocorr_len = len(minus_dist)\n",
    "    if autocorr_len<min_num:\n",
    "        autocorr = np.nan\n",
    "    return autocorr, autocorr_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_autocor(plus_dist,minus_dist,min_num=100,subsamp_ratio=0.5):\n",
    "    'fx_autocor, but called with random subsampling at a ratio defined by subsamp_ratio [0-1]'\n",
    "    irand = np.random.randint(len(plus_dist),size=int(subsamp_ratio*len(plus_dist)))\n",
    "    return fx_autocor(plus_dist[irand],minus_dist[irand],min_num=min_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr(x, t=1):\n",
    "    return np.corrcoef(np.array([x[:-t], x[t:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr2(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[result.size // 2:]/result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr5(x):\n",
    "    '''numpy.correlate, non partial'''\n",
    "    n = len(x)\n",
    "    lags = range(n)\n",
    "    #mean=x.mean()\n",
    "    var=np.nanvar(x)\n",
    "    xp=x-np.nanmean(x)\n",
    "    corr=np.correlate(xp,xp,'full')[n-1:]/var/n\n",
    "\n",
    "    return corr[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_dist(d,dist=0.12,verbose=False):\n",
    "    'function to insterpolate the AOD from the dict to an even grid spacing accroding to distance (default 0.12 km)'\n",
    "    d['cdist_n'],d['aod_n'] = [],[]\n",
    "    for i,cd in enumerate(d['cumdist']):\n",
    "        if verbose:\n",
    "            print i, cd.min(),cd.max(), np.nanmin(cd),np.nanmax(cd)\n",
    "            if not np.isfinite(cd.min()): print cd\n",
    "        d['cdist_n'].append(np.arange(cd.min(),cd.max(),dist))\n",
    "        try:\n",
    "            fcd = interpolate.interp1d(cd,d['aod0500'][i])\n",
    "            d['aod_n'].append(fcd(d['cdist_n'][i]))\n",
    "        except TypeError:\n",
    "            d['aod_n'].append(np.array(np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bined_alt(x,alt,days,fl,n=70,rg=None):\n",
    "    'Function to create binned data for a set range, usually for altitude'\n",
    "    binned_ang,binned_alt,binned_num,binned_ndays = [],[],[],[]\n",
    "    if rg:\n",
    "        dz = (rg[1]-rg[0])/n\n",
    "    else:\n",
    "        dz = np.nanmax(alt[fl])/n\n",
    "        rg = [0.0,np.nanmax(alt[fl])]\n",
    "    print np.nanmax(alt[fl]),dz\n",
    "    for i in xrange(n):\n",
    "        flaa = (alt[fl]>=(i*dz)+rg[0]) & (alt[fl]<((i+1.0)*dz)+rg[0])\n",
    "        binned_ang.append(x[fl][flaa])\n",
    "        binned_alt.append(np.mean([(i*dz)+rg[0],((i+1.0)*dz)+rg[0]]))\n",
    "        binned_num.append(len(x[fl][flaa]))\n",
    "        binned_ndays.append(len(np.unique(days[fl][flaa])))\n",
    "    return binned_ang,binned_alt,binned_num,binned_ndays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_dist_fmf(d,dist=0.12):\n",
    "    'function to insterpolate the AOD from the dict to an even grid spacing accroding to distance (default 0.12 km)'\n",
    "    d['cdist_n'],d['aod_nf'],d['aod_nc'],d['eta_n'] = [],[],[],[]\n",
    "    for i,cd in enumerate(d['cumdist']):        \n",
    "        d['cdist_n'].append(np.arange(cd.min(),cd.max(),dist))\n",
    "        if np.sum(np.isfinite(d['aodf'][i]))/float(len(d['aodf'][i])) < 0.75: # check if at least 75% of the segment is valid\n",
    "            af = np.array(np.nan)\n",
    "            ac = np.array(np.nan)\n",
    "            et = np.array(np.nan)\n",
    "        else:\n",
    "            try:\n",
    "                fcdf = interpolate.interp1d(cd,d['aodf'][i])\n",
    "                af = fcdf(d['cdist_n'][i])\n",
    "                fcdc = interpolate.interp1d(cd,d['aodc'][i])\n",
    "                ac = fcdc(d['cdist_n'][i])\n",
    "                fcde = interpolate.interp1d(cd,d['eta'][i])\n",
    "                et = fcde(d['cdist_n'][i])\n",
    "            except TypeError:\n",
    "                af = np.array(np.nan)\n",
    "                ac = np.array(np.nan)\n",
    "                et = np.array(np.nan)\n",
    "        d['aod_nf'].append(af)\n",
    "        d['aod_nc'].append(ac)\n",
    "        d['eta_n'].append(et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binned(x,alt,fl,bn,flb):\n",
    "    'Function to create binned data for a set range, usually for altitude'\n",
    "    \n",
    "    binned_ang,binned_alt,binned_num = [],[],[]\n",
    "    for i,b in enumerate(bn[:-1]):\n",
    "        flaa = (alt[flb]>=b) & (alt[flb]<bn[i+1])\n",
    "        binned_ang.append(x[:,flb][flaa])\n",
    "        binned_alt.append(np.mean([b,bn[i+1]]))\n",
    "        binned_num.append(len(x[fl][:,flaa]))\n",
    "    return binned_ang,binned_alt,binned_num,binned_ndays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_2d(lat,lon,x,fl=[],bins=26,rg=[[-25,-8],[0,16]],days=[],verbose=True):\n",
    "    \"Combined Statistics function to get the mean, median, number, ndays, and std from a 2d dataset\"    \n",
    "    stat = {}\n",
    "    if not len(fl)>0: fl = np.isfinite(x)\n",
    "        \n",
    "    stat['mean'],stat['xm'],stat['ym'],stat['bin'] = \\\n",
    "          st.binned_statistic_2d(lat[fl],lon[fl],x[fl],bins=bins,range=rg,statistic='mean')\n",
    "    stat['mean'] = np.ma.masked_array(stat['mean'],np.isnan(stat['mean']))\n",
    "    \n",
    "    stat['median'],stat['xe'],stat['ye'],stat['bine'] = \\\n",
    "          st.binned_statistic_2d(lat[fl],lon[fl],x[fl],bins=bins,range=rg,statistic='median')\n",
    "    stat['median'] = np.ma.masked_array(stat['median'],np.isnan(stat['median']))\n",
    "\n",
    "    stat['std'],stat['xs'],stat['ys'],stat['bins'] = \\\n",
    "          st.binned_statistic_2d(lat[fl],lon[fl],x[fl],bins=bins,range=rg,statistic=np.nanstd)\n",
    "    stat['std'] = np.ma.masked_array(stat['std'],np.isnan(stat['std']))\n",
    "    \n",
    "    stat['cnt'],stat['xn'],stat['yn'],stat['binn'] = \\\n",
    "          st.binned_statistic_2d(lat[fl],lon[fl],x[fl],bins=bins,range=rg,statistic='count')\n",
    "    stat['cnt'] = np.ma.masked_array(stat['cnt'],np.isnan(stat['cnt']))\n",
    "\n",
    "    if len(days)>0:\n",
    "        uniq_cnt = lambda x: len(np.unique(x))\n",
    "        stat['dcnt'],stat['xd'],stat['yd'],stat['bind'] = \\\n",
    "          st.binned_statistic_2d(lat[fl],lon[fl],days[fl],bins=bins,range=rg,statistic=uniq_cnt)\n",
    "        stat['dcnt'] = np.ma.masked_array(stat['dcnt'],np.isnan(stat['dcnt']))\n",
    "    else:\n",
    "        stat['dcnt'] = stat['cnt']*0.0\n",
    "    \n",
    "    if verbose:\n",
    "        print 'Mean values: mean={}, median={}, std={}, num={}, day={}'.format(\\\n",
    "                    np.nanmean(stat['mean']),np.nanmean(stat['median']),np.nanmean(stat['std']),\n",
    "                    np.nanmean(stat['cnt']),np.nanmean(stat['dcnt']))\n",
    "        print 'Median values: mean={}, median={}, std={}, num={}, day={}'.format(\\\n",
    "                    np.nanmedian(stat['mean']),np.nanmedian(stat['median']),np.nanmedian(stat['std']),\n",
    "                    np.nanmedian(stat['cnt']),np.nanmedian(stat['dcnt']))\n",
    "        print 'STD values: mean={}, median={}, std={}, num={}, day={}'.format(\\\n",
    "                    np.nanstd(stat['mean']),np.nanstd(stat['median']),np.nanstd(stat['std']),\n",
    "                    np.nanstd(stat['cnt']),np.nanstd(stat['dcnt']))\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
