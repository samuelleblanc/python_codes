{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {}
   },
   "source": [
    "Name:  \n",
    "\n",
    "    Run_libradtran\n",
    "\n",
    "Purpose:  \n",
    "\n",
    "    Python modules that combine the different modules used for writing and reading libradtran files. \n",
    "    Used with libradtran 2.0\n",
    "    Same outputs as IDL procedures 'write_inp_mix.pro' but for libradtran 2.0\n",
    "\n",
    "Calling Sequence:\n",
    "\n",
    "    import Run_libradtran as RL\n",
    "  \n",
    "Input:\n",
    "\n",
    "    none at command line\n",
    "    see methods of module\n",
    "\n",
    "Output:\n",
    "   \n",
    "    input files for libradtran 2.0 (uvspec) \n",
    "  \n",
    "Keywords:\n",
    "\n",
    "    none\n",
    "  \n",
    "Dependencies:\n",
    "\n",
    "    - numpy\n",
    "    - scipy : for saving and reading\n",
    "    - math\n",
    "    - pdb\n",
    "    - datetime\n",
    "    - load_utils\n",
    "  \n",
    "Needed Files:\n",
    "\n",
    "  - ...\n",
    "  \n",
    "  \n",
    "Modification History:\n",
    "\n",
    "    Wrtten: Samuel LeBlanc, NASA Ames, from Santa Cruz, 2015-06-26\n",
    "    Modified: Samuel LeBlanc, NASA Ames, 2015-10-06\n",
    "            - added function to write out the write_aac dictionaries to a version file\n",
    "    Modified: Samuel LeBlanc, Santa Cruz, 2020-05-11, Under stay at home for COVID-19\n",
    "            - added fifo writing option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_wrapper_file_print(output_file,string_list,append=False,fifo=False):\n",
    "    'Wrapper to make separate process for writing file when using fifo'\n",
    "    if fifo:\n",
    "        from multiprocessing import Process\n",
    "        p1 = Process(target=print_to_file,args=(output_file,string_list,append,fifo))\n",
    "        p1.start()\n",
    "    else:\n",
    "        print_to_file(output_file,string_list,append=append,fifo=fifo)\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_to_file(output_file, string_list,append=False,fifo=False):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    \n",
    "        Program to print to file from an output string. \n",
    "        Generalized for all ascii file printing needs.\n",
    "        \n",
    "    Input:\n",
    "    \n",
    "        output_file: full path to file to be written\n",
    "        string_list: List of strings to be output (each on its own line)\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "        output file (ascii)\n",
    "        \n",
    "    Keywords:\n",
    "    \n",
    "        append: (default False), if True, appends to the end of the file    \n",
    "        fifo: (default False), if True makes a fifo file\n",
    "        \n",
    "    Dependencies:\n",
    "    \n",
    "        - N/A\n",
    "    \n",
    "    Required files:\n",
    "    \n",
    "        - None\n",
    "        \n",
    "    Example:\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Modification History:\n",
    "\n",
    "    Written (v1.0): Samuel LeBlanc, 2020-05-11, Santa Cruz, CA, in COVID-19 Stay at home order\n",
    "        \n",
    "    \"\"\"\n",
    "    import os\n",
    "       \n",
    "    if fifo: \n",
    "        if not os.path.exists(output_file):\n",
    "            os.mkfifo(output_file)\n",
    "            \n",
    "    try:\n",
    "        if append and not fifo:\n",
    "            p = open(output_file,'a')\n",
    "        else:\n",
    "            p = open(output_file,'w')\n",
    "    except Exception,e:\n",
    "        print 'Problem with accessing file, return Exception: ',e\n",
    "        return\n",
    "\n",
    "    if fifo:\n",
    "        p.flush()\n",
    "    \n",
    "    for ll in string_list:\n",
    "        p.write('{}\\n'.format(ll.replace('\\n','')))\n",
    "    \n",
    "    p.close()\n",
    "    if fifo: \n",
    "        os.unlink(p)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def write_cloud_file(output_file,tau,ref,zbot,ztop,verbose=False,append_directly_below=False,fifo=False,use_old=False):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "\n",
    "        Program to write out the cloud file profile\n",
    "        for either ic_file or wc_file in 1D settings\n",
    "        outputs 3 columns: \n",
    "            # z [km]    IWC/LWC [g/m^3]    Reff [um]\n",
    "            \n",
    "        ** translates tau and ref to lwc/iwc with the equation LWP = 2/3*tau*ref and LWC=LWP/z_extent*0.001\n",
    "        ** Writes out file based on layer properties, not level properties. \n",
    "           (given value of ref and tau are for a cloud from zbot to ztop)\n",
    "    \n",
    "    Input: \n",
    "  \n",
    "        output_file: full path to file to be written\n",
    "        tau: value of cloud optical thickness\n",
    "        ref: value of effective radius in microns\n",
    "        ztop: location in km of cloud top\n",
    "        zbot: location in km of cloud bottom\n",
    "    \n",
    "    Output:\n",
    "\n",
    "        output_file\n",
    "                \n",
    "    \n",
    "    Keywords: \n",
    "\n",
    "        verbose: (default False) if true prints out info about file writing \n",
    "        append_directly_below: (default False) if true then opens a already existing file\n",
    "                               and only writes out the last line as an append\n",
    "        fifo: (default False) if true, then writes to a fifo file, and starts a seperate thread to only write this file, \n",
    "              then immediatly close\n",
    "        use_old: (default False) if True, then uses previous method of file writing.\n",
    "    \n",
    "    Dependencies:\n",
    "\n",
    "        numpy\n",
    "    \n",
    "    Required files:\n",
    "   \n",
    "        none\n",
    "    \n",
    "    Example:\n",
    "\n",
    "        ...\n",
    "        \n",
    "    Modification History:\n",
    "    \n",
    "        Written (v1.0): Samuel LeBlanc, 2015-06-26, NASA Ames, from Santa Cruz, CA\n",
    "        Modified (v1.1): Samuel LeBlanc, DC8 flying above Korea, 2016-05-02\n",
    "        Modified (v1.2): Samuel LeBlanc, Santa Cruz in COVID-19 stay at home, 2020-05-11\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    if (zbot >= ztop):\n",
    "        raise ValueError('*** Error ztop must be larger than zbot ***')\n",
    "    if (ztop < 1.0):\n",
    "        print('ztop is smaller than one, check units, ztop should be in km')\n",
    "        if verbose:\n",
    "            print('..file preperations continuing')\n",
    "    if tau:\n",
    "        if np.isnan(tau):\n",
    "            raise ValueError('*** Error tau is NaN ***')\n",
    "    if ref:\n",
    "        if np.isnan(ref):\n",
    "            raise ValueError('*** Error ref is NaN ***')\n",
    "    lwp = 2.0/3.0*tau*ref\n",
    "    lwc = lwp/(ztop-zbot)*0.001\n",
    "    if verbose:\n",
    "        print('..Cloud water content is: %f' % lwc)\n",
    "    \n",
    "    if use_old:\n",
    "        if not append_directly_below:\n",
    "            try:\n",
    "                output = file(output_file,'w')\n",
    "            except Exception,e:\n",
    "                print 'Problem with accessing file, return Exception: ',e\n",
    "                return\n",
    "            if verbose:\n",
    "                print('..printing to file: %s' % output_file)\n",
    "            output.write('# z [km]    IWC/LWC [g/m^3]    Reff [um] \\n')\n",
    "            output.write('%4.4f\\t%4.5f\\t%3.2f\\n' % (ztop,0,0))\n",
    "            output.write('%4.4f\\t%4.5f\\t%3.2f\\n' % (zbot,lwc,ref))\n",
    "        else:\n",
    "            try:\n",
    "                output = file(output_file,'a')\n",
    "            except Exception,e:\n",
    "                print 'Problem with accessing file, return Exception: ',e\n",
    "                return\n",
    "            output.write('%4.4f\\t%4.5f\\t%3.2f\\n' % (zbot,lwc,ref))\n",
    "        output.close() \n",
    "    else:\n",
    "        out_string = []\n",
    "        if not append_directly_below:\n",
    "            out_string.append('# z [km]    IWC/LWC [g/m^3]    Reff [um] \\n')\n",
    "            out_string.append('%4.4f\\t%4.5f\\t%3.2f\\n' % (ztop,0,0))\n",
    "            out_string.append('%4.4f\\t%4.5f\\t%3.2f\\n' % (zbot,lwc,ref))\n",
    "        else:\n",
    "            out_string.append('%4.4f\\t%4.5f\\t%3.2f\\n' % (zbot,lwc,ref))\n",
    "        process_wrapper_file_print(output_file,out_string,append=append_directly_below,fifo=fifo)\n",
    "    if verbose:\n",
    "        print('..File finished write_cloud_file, closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def write_aerosol_file_explicit(output_file,z_arr,ext,ssa,asy,wvl_arr,verbose=False,expand_hg=False,\n",
    "                                fifo=False,use_old=False):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "\n",
    "        Writes the file with profile of aerosol files\n",
    "        writes one file per layer of aerosol properties, which are wavelength dependent\n",
    "        outputs 2 columns of layer properties: \n",
    "            # z [km]     file_path\n",
    "            \n",
    "        ** Translates asymmetry parameter into scattering phase function defined by Henyey-Greenstein\n",
    "    \n",
    "    Input: \n",
    "  \n",
    "        output_file: full path to file to be written\n",
    "        ext: value of aerosol extinction coefficient at each altitude and wavelength [alt,wvl]\n",
    "            To define the top most layer, ext must be zero at that altitude\n",
    "        ssa: value of aerosol single scattering albedo at each altitude and wavelength [alt,wvl]\n",
    "        asy: value of aerosol asymmetry parameter at each altitude and wavelength [alt,wvl]\n",
    "        z_arr: value of altitudes to use with ext,ssa,asy\n",
    "        wvl_arr: array of wavelengths in nm\n",
    "    \n",
    "    Output:\n",
    "\n",
    "        output_file\n",
    "                \n",
    "    \n",
    "    Keywords: \n",
    "\n",
    "        verbose: (default False) if true prints out info about file writing \n",
    "        expand_hg: (default False) if true expands the Henyey Greenstein legendre moments from the assymetry parameter\n",
    "        fifo: (default False) if true, then writes to a fifo file, and starts a seperate thread to only write this file, \n",
    "              then immediatly close\n",
    "        use_old: (default False) if True, then uses previous method of file writing.\n",
    "    \n",
    "    Dependencies:\n",
    "\n",
    "        numpy\n",
    "        Run_libradtran (this file)\n",
    "    \n",
    "    Required files:\n",
    "   \n",
    "        none\n",
    "    \n",
    "    Example:\n",
    "\n",
    "        ...\n",
    "        \n",
    "    Modification History:\n",
    "    \n",
    "        Written (v1.0): Samuel LeBlanc, 2015-06-26, NASA Ames, from Santa Cruz, CA\n",
    "        Modified (v1.1):Samuel LeBlanc, 2020-05-11, Santa Cruz, CA, under COVID-19 stay-at-home\n",
    "                        - added fifo writing handling\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from Run_libradtran import write_aerosol_file_explicit_wvl\n",
    "    two_z = False\n",
    "    if not len(z_arr)==np.shape(ext)[0]:\n",
    "        if len(z_arr)==2:\n",
    "            #sepcial case for only two points on the z array\n",
    "            two_z = True\n",
    "        else:\n",
    "            raise LookupError('*** Error z_arr not same size as ext ***')\n",
    "    if two_z:\n",
    "        if not len(wvl_arr)==len(ext):\n",
    "            raise LookupError('*** Error wvl_arr not same size as ext ***')\n",
    "    else:\n",
    "        if not len(wvl_arr)==np.shape(ext)[1]:\n",
    "            raise LookupError('*** Error wvl_arr not same size as ext ***')\n",
    "    \n",
    "    if use_old:\n",
    "        try:\n",
    "            output = file(output_file,'w')\n",
    "        except Exception,e:\n",
    "            print 'Problem with accessing file, return Exception: ',e\n",
    "            return\n",
    "        if verbose:\n",
    "            print('..printing to file: %s' % output_file)\n",
    "\n",
    "        output.write('# z [km] \\t file_path\\n')\n",
    "        izs = np.argsort(z_arr)[::-1]\n",
    "        zs = np.sort(z_arr)[::-1]\n",
    "        if verbose:\n",
    "            print('..printing %i lines onto profile file' % len(zs))\n",
    "        for iz,z in enumerate(zs):\n",
    "            file_iz = output_file+'_z%03i' % iz\n",
    "            if two_z:\n",
    "                if iz>0:\n",
    "                    write_aerosol_file_explicit_wvl(file_iz,wvl_arr,ext,ssa,asy,verbose=verbose,expand_hg=expand_hg,\n",
    "                                                    fifo=fifo,use_old=use_old)\n",
    "                    output.write('%4.4f\\t%s\\n' % (z,file_iz))\n",
    "                else:\n",
    "                    output.write('%4.4f\\t%s\\n' % (z,'NULL'))\n",
    "            else:\n",
    "                if any(ext[izs[iz],:]):\n",
    "                    write_aerosol_file_explicit_wvl(file_iz,wvl_arr,ext[izs[iz],:],ssa[izs[iz],:],asy[izs[iz],:],\n",
    "                                                    verbose=verbose,expand_hg=expand_hg,fifo=fifo,use_old=use_old)\n",
    "                    output.write('%4.4f\\t%s\\n' % (z,file_iz))\n",
    "                else:\n",
    "                    output.write('%4.4f\\t%s\\n' % (z,'NULL'))\n",
    "        output.close() \n",
    "    else:\n",
    "        out_string = []\n",
    "        out_string.append('# z [km] \\t file_path\\n')\n",
    "        izs = np.argsort(z_arr)[::-1]\n",
    "        zs = np.sort(z_arr)[::-1]\n",
    "        for iz,z in enumerate(zs):\n",
    "            file_iz = output_file+'_z%03i' % iz\n",
    "            if two_z:\n",
    "                if iz>0:\n",
    "                    write_aerosol_file_explicit_wvl(file_iz,wvl_arr,ext,ssa,asy,verbose=verbose,expand_hg=expand_hg,\n",
    "                                                    fifo=fifo,use_old=use_old)\n",
    "                    out_string.append('%4.4f\\t%s\\n' % (z,file_iz))\n",
    "                else:\n",
    "                    out_string.append('%4.4f\\t%s\\n' % (z,'NULL'))\n",
    "            else:\n",
    "                if any(ext[izs[iz],:]):\n",
    "                    write_aerosol_file_explicit_wvl(file_iz,wvl_arr,ext[izs[iz],:],ssa[izs[iz],:],asy[izs[iz],:],\n",
    "                                                    verbose=verbose,expand_hg=expand_hg)\n",
    "                    out_string.append('%4.4f\\t%s\\n' % (z,file_iz))\n",
    "                else:\n",
    "                    out_string.append('%4.4f\\t%s\\n' % (z,'NULL'))\n",
    "        process_wrapper_file_print(output_file,out_string,append=False,fifo=fifo)\n",
    "        \n",
    "    if verbose:\n",
    "        print('..File finished write_aerosol_file_explicit, closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def write_aerosol_file_explicit_wvl(output_file,wvl_arr,ext,ssa,asy,verbose=False,expand_hg=False,\n",
    "                                    fifo=False,use_old=False):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "\n",
    "        Writes the file with aerosol properties per wavelength\n",
    "        outputs many columns of layer properties: \n",
    "            # wvl[nm]    ext[km^-1]   ssa[unitless]  legendre_moments\n",
    "            \n",
    "            where for Henyey-Greenstein the legendre moments consist of:\n",
    "                1   asymmetry_parameter, ..., asymmetry_parameter^n\n",
    "        \n",
    "        ** Translates asymmetry parameter into scattering phase function defined by Henyey-Greenstein\n",
    "    \n",
    "    Input: \n",
    "  \n",
    "        output_file: full path to file to be written\n",
    "        ext: value of aerosol extinction coefficient at each wavelength [wvl]\n",
    "        ssa: value of aerosol single scattering albedo at each wavelength [wvl]\n",
    "        asy: value of aerosol asymmetry parameter at each wavelength [wvl]\n",
    "        wvl_arr: array of wavelengths in nm\n",
    "    \n",
    "    Output:\n",
    "\n",
    "        output_file\n",
    "                \n",
    "    \n",
    "    Keywords: \n",
    "\n",
    "        verbose: (default False) if true prints out info about file writing \n",
    "        expand_hg: (default False) if true, then epands the Henyey-Greenstein phase function, not just printing the asymmetry p\n",
    "        fifo: (default False) if true, then writes to a fifo file, and starts a seperate thread to only write this file, \n",
    "              then immediatly close\n",
    "        use_old: (default False) if True, then uses previous method of file writing.\n",
    "        \n",
    "    Dependencies:\n",
    "\n",
    "        numpy\n",
    "        Run_libradtran (this file)\n",
    "    \n",
    "    Required files:\n",
    "   \n",
    "        none\n",
    "    \n",
    "    Example:\n",
    "\n",
    "        ...\n",
    "        \n",
    "    Modification History:\n",
    "    \n",
    "        Written (v1.0): Samuel LeBlanc, 2015-06-26, NASA Ames, from Santa Cruz, CA\n",
    "        Modified (v1.1):Samuel LeBlanc, 2020-05-11, Santa Cruz, CA, under COVID-19 stay-at-home\n",
    "                         - added fifo writing handling\n",
    "    \"\"\"\n",
    "    if not len(wvl_arr)==len(ext):\n",
    "        raise LookupError(\"ext and wvl_arr don't have the same size\")\n",
    "    if not len(wvl_arr)==len(ssa):\n",
    "        raise LookupError(\"ssa and wvl_arr don't have the same size\")  \n",
    "    if not len(wvl_arr)==len(asy):\n",
    "        raise LookupError(\"asy and wvl_arr don't have the same size\")  \n",
    "    \n",
    "    if use_old:\n",
    "        try:\n",
    "            output = file(output_file,'w')\n",
    "        except Exception,e:\n",
    "            print 'Problem with accessing file, return Exception: ',e\n",
    "            return\n",
    "        if verbose:\n",
    "            print('..printing to explicit aerosol wavelength defined file: %s' % output_file)\n",
    "        output.write('# wvl[nm]    ext[km^-1]   ssa[unitless]  legendre_moments\\n')\n",
    "        for iw,wvl in enumerate(wvl_arr):\n",
    "            if expand_hg:\n",
    "                asys = [asy[iw]**n for n in range(100)]\n",
    "                st = '%f\\t%f\\t%1.6f\\t' % (wvl,ext[iw],ssa[iw])\n",
    "                stt = st+'\\t'.join(map(str,asys))+'\\n'\n",
    "                output.write(stt)\n",
    "            else:\n",
    "                output.write('%f\\t%f\\t%1.6f\\t%1.6f\\t%1.6f\\n' % (wvl,ext[iw],ssa[iw],1.0,asy[iw]))\n",
    "        output.close()\n",
    "    else:\n",
    "        out_string = []\n",
    "        out_string.append('# wvl[nm]    ext[km^-1]   ssa[unitless]  legendre_moments\\n')\n",
    "        for iw,wvl in enumerate(wvl_arr):\n",
    "            if expand_hg:\n",
    "                asys = [asy[iw]**n for n in range(100)]\n",
    "                st = '%f\\t%f\\t%1.6f\\t' % (wvl,ext[iw],ssa[iw])\n",
    "                stt = st+'\\t'.join(map(str,asys))+'\\n'\n",
    "                out_string.append(stt)\n",
    "            else:\n",
    "                out_string.append('%f\\t%f\\t%1.6f\\t%1.6f\\t%1.6f\\n' % (wvl,ext[iw],ssa[iw],1.0,asy[iw]))\n",
    "        process_wrapper_file_print(output_file,out_string,append=False,fifo=fifo)\n",
    "        \n",
    "    if verbose:\n",
    "        print('..File finished write_aerosol_file_explicit_wvl, closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def write_cloud_file_moments(output_file,tau,ref,zbot,ztop,moms_dict=None,\n",
    "                             verbose=False,append_directly_below=False,wvl_range=None,fifo=False,use_old=False):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "\n",
    "        Writes the file with profile of cloud moment files\n",
    "        writes one file per layer of cloud properties, which are wavelength dependent\n",
    "        outputs 2 columns of layer properties: \n",
    "            # z [km]     file_path\n",
    "\n",
    "    Input: \n",
    "  \n",
    "        output_file: full path to file to be written\n",
    "        tau: value of cloud optical thickness\n",
    "        ref: value of cloud particles effective radius [microns]\n",
    "        zbot: bottom of cloud layer [km]\n",
    "        ztop: top of cloud layer [km]\n",
    "        moms_dict: dictionary from saved legendre moments. \n",
    "                    Includes: ntheta, pmom, rho, nmom, ssa, nim, nre, ext, wvl, phase, theta, ref\n",
    "        wvl_range: sets the range of wavelength for the cloud properties to be saved. If not set, prints all values in moms_dict\n",
    "    \n",
    "    Output:\n",
    "\n",
    "        output_file              \n",
    "    \n",
    "    Keywords: \n",
    "\n",
    "        verbose: (default False) if true prints out info about file writing \n",
    "        append_directly_below: (default False) if true appends a new line to an existing file with cloud properties directly \n",
    "                               below the last line of the already existing file\n",
    "        fifo: (default False) if true, then writes to a fifo file, and starts a seperate thread to only write this file, \n",
    "              then immediatly close\n",
    "        use_old: (default False) if True, then uses previous method of file writing.\n",
    "    \n",
    "    Dependencies:\n",
    "\n",
    "        numpy\n",
    "        Run_libradtran (this file)\n",
    "    \n",
    "    Required files:\n",
    "   \n",
    "        none\n",
    "    \n",
    "    Example:\n",
    "\n",
    "        ...\n",
    "        \n",
    "    Modification History:\n",
    "    \n",
    "        Written (v1.0): Samuel LeBlanc, 2015-06-29, NASA Ames, from Santa Cruz, CA\n",
    "        Modified (v1.1): Samuel LeBlanc, DC8 flying above Korea, 2016-05-02\n",
    "                        - added the append_directly_below keyword\n",
    "        Modified (v1.2): Samuel LeBlanc, Santa Cruz, CA, 2017-02-17\n",
    "                        - added the wvl_range keyword\n",
    "        Modified (v1.3): Samuel LeBlanc, 2020-05-11, Santa Cruz, CA, under COVID-19 stay-at-home\n",
    "                         - added fifo writing handling\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from Run_libradtran import write_cloud_file_moments_wvl, get_cloud_ext_ssa_moms\n",
    "        \n",
    "    if (zbot >= ztop):\n",
    "        raise ValueError('*** Error ztop must be larger than zbot ***')\n",
    "    if (ztop < 1.0):\n",
    "        print('ztop is smaller than one, check units, ztop should be in km')\n",
    "        if verbose:\n",
    "            print('..file preperations continuing')\n",
    "            \n",
    "    lwp = 2.0/3.0*tau*ref\n",
    "    lwc = lwp/(ztop-zbot)*0.001\n",
    "    ext,ssa,wvl,moments,nmom = get_cloud_ext_ssa_moms(ref,lwc,moms_dict=moms_dict,verbose=False)\n",
    "    \n",
    "    if use_old:\n",
    "        if not append_directly_below:\n",
    "            try:\n",
    "                output = file(output_file,'w')\n",
    "            except Exception,e:\n",
    "                print 'Problem with accessing file, return Exception: ',e\n",
    "                return\n",
    "            if verbose:\n",
    "                print('..printing to file: %s' % output_file)\n",
    "\n",
    "            output.write('# z [km] \\t file_path\\n')\n",
    "            output.write('%4.4f\\t%s\\n' % (ztop,'NULL'))\n",
    "            file_cloud = output_file+'_zbot'\n",
    "            output.write('%4.4f\\t%s\\n' % (zbot,file_cloud))\n",
    "        else:\n",
    "            try:\n",
    "                output = file(output_file,'a')\n",
    "            except Exception,e:\n",
    "                print 'Problem with accessing file, return Exception: ',e\n",
    "                return\n",
    "            if verbose:\n",
    "                print('..printing to file: %s' % output_file)\n",
    "\n",
    "            file_cloud = output_file+'_zbelow'\n",
    "            output.write('%4.4f\\t%s\\n' % (zbot,file_cloud))\n",
    "\n",
    "        write_cloud_file_moments_wvl(file_cloud,wvl,ext,ssa,moments,nmom,verbose=verbose,wvl_range=wvl_range,use_old=use_old)\n",
    "\n",
    "        output.close()\n",
    "    else:\n",
    "        out_string = []\n",
    "        out_string.append('# z [km] \\t file_path\\n')\n",
    "        out_string.append('%4.4f\\t%s\\n' % (ztop,'NULL'))\n",
    "        file_cloud = output_file+'_zbot'\n",
    "        out_string.append('%4.4f\\t%s\\n' % (zbot,file_cloud))\n",
    "        process_wrapper_file_print(output_file,out_string,append=False,fifo=fifo)\n",
    "        \n",
    "        write_cloud_file_moments_wvl(file_cloud,wvl,ext,ssa,moments,nmom,verbose=verbose,wvl_range=wvl_range,\n",
    "                                     use_old=use_old,fifo=fifo)\n",
    "        \n",
    "            \n",
    "    if verbose:\n",
    "        print('..File finished write_cloud_file_moments, closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def write_cloud_file_moments_wvl(output_file,wvl,ext,ssa,moments,nmom,verbose=False,wvl_range=None,\n",
    "                                 fifo=False,use_old=False):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "\n",
    "        Writes the file with cloud properties per wavelength\n",
    "        outputs many columns of layer properties: \n",
    "            # wvl[nm]    ext[km^-1]   ssa[unitless]  legendre_moments\n",
    "    \n",
    "    Input: \n",
    "  \n",
    "        output_file: full path to file to be written\n",
    "        ext: value of aerosol extinction coefficient at each wavelength [wvl]\n",
    "        ssa: value of aerosol single scattering albedo at each wavelength [wvl]\n",
    "        moments: array of moments at each wavelength [wvl]\n",
    "        nmom: number of moments to be written out. \n",
    "        wvl: array of wavelengths in nm referring to the properties\n",
    "        wvl_range: only print the values within this wavelength range\n",
    "    \n",
    "    Output:\n",
    "\n",
    "        output_file\n",
    "                \n",
    "    Keywords: \n",
    "\n",
    "        verbose: (default False) if true prints out info about file writing \n",
    "        fifo: (default False) if true, then writes to a fifo file, and starts a seperate thread to only write this file, \n",
    "              then immediatly close\n",
    "        use_old: (default False) if True, then uses previous method of file writing.\n",
    "    \n",
    "    Dependencies:\n",
    "\n",
    "        numpy\n",
    "        Run_libradtran (this file)\n",
    "    \n",
    "    Required files:\n",
    "   \n",
    "        none\n",
    "    \n",
    "    Example:\n",
    "\n",
    "        ...\n",
    "        \n",
    "    Modification History:\n",
    "    \n",
    "        Written (v1.0): Samuel LeBlanc, 2015-06-29, NASA Ames, from Santa Cruz, CA\n",
    "        Modified (v1.1): Samuel LeBlanc, 2020-05-11, Santa Cruz, CA, under COVID-19 stay-at-home\n",
    "                 - added fifo writing handling\n",
    "    \"\"\"\n",
    "    if not len(wvl)==len(ext):\n",
    "        raise LookupError(\"ext and wvl_arr don't have the same size\")\n",
    "    if not len(wvl)==len(ssa):\n",
    "        raise LookupError(\"ssa and wvl_arr don't have the same size\")  \n",
    "        \n",
    "    if not wvl_range:\n",
    "        wvl_range = [min(wvl),max(wvl)]\n",
    "    if verbose: print '... wvl_range:',wvl_range[0],wvl_range[1]\n",
    "        \n",
    "    if use_old:\n",
    "        try:\n",
    "            output = file(output_file,'w')\n",
    "        except Exception,e:\n",
    "            print 'Problem with accessing file, return Exception: ',e\n",
    "            return\n",
    "        if verbose:\n",
    "            print('..printing to cloud moments properties wavelength defined file: %s' % output_file)\n",
    "        output.write('# wvl[nm]    ext[km^-1]   ssa[unitless]  legendre_moments\\n')\n",
    "        for iw,wv in enumerate(wvl):\n",
    "            if (wv<wvl_range[0]-10.0 or wv>wvl_range[1]+10.0) and wvl_range[1]<10000.0:\n",
    "                continue\n",
    "            try:\n",
    "                if len(moments.shape)>1:\n",
    "                    output.write('%f\\t%f\\t%1.6f\\t%s \\n' % \n",
    "                                 (wv,ext[iw],ssa[iw],\" \".join([str(x/(2.0*i+1.0)) for i,x in enumerate(moments[iw,0:int(nmom[iw])])])))\n",
    "                else:\n",
    "                    st = '%f\\t%f\\t%1.6f\\t%s \\n' %\\\n",
    "                                 (wv,ext[iw],ssa[iw],\n",
    "                                  \" \".join(['{:1.5g}'.format(x/(2.0*i+1.0)) for i,x in enumerate(moments[iw][0,0:int(nmom[iw])])]))\n",
    "                    if len(st)>1000000:\n",
    "                        st = '%f\\t%f\\t%1.6f\\t%s \\n' %\\\n",
    "                                 (wv,ext[iw],ssa[iw],\n",
    "                                  \" \".join(['{:1.4g}'.format(x/(2.0*i+1.0)) for i,x in enumerate(moments[iw][0,0:int(nmom[iw])])]))\n",
    "                        an = len(moments[iw][0,0:int(nmom[iw])])-1\n",
    "                        print 'trying to reduce size', len(st), an\n",
    "                        while len(st)>1000000:\n",
    "                            df = int((len(st)-1000000)/10)\n",
    "                            an = an-df-10\n",
    "                            st = '%f\\t%f\\t%1.6f\\t%s \\n' %\\\n",
    "                                 (wv,ext[iw],ssa[iw],\n",
    "                                  \" \".join(['{:1.4g}'.format(x/(2.0*i+1.0)) for i,x in enumerate(moments[iw][0,0:an])]))\n",
    "                            print 'in size reduction', len(st),an\n",
    "                    output.write(st)\n",
    "                    #output.write('%f\\t%f\\t%1.6f\\t%s \\n' % \n",
    "                    #             (wv,ext[iw],ssa[iw],\n",
    "                    #\" \".join(['{:1.4g}'.format(x/(2.0*i+1.0)) for i,x in enumerate(moments[iw][0,0:nmom[iw]])])))\n",
    "            except:\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "        output.close()\n",
    "    else:\n",
    "        out_string = []\n",
    "        out_string.append('# wvl[nm]    ext[km^-1]   ssa[unitless]  legendre_moments\\n')\n",
    "        for iw,wv in enumerate(wvl):\n",
    "            if (wv<wvl_range[0]-10.0 or wv>wvl_range[1]+10.0) and wvl_range[1]<10000.0:\n",
    "                continue\n",
    "            if len(moments.shape)>1:\n",
    "                out_string.append('%f\\t%f\\t%1.6f\\t%s \\n' % \n",
    "                             (wv,ext[iw],ssa[iw],\" \".join([str(x/(2.0*i+1.0)) for i,x in enumerate(moments[iw,0:int(nmom[iw])])])))\n",
    "            else:\n",
    "                st = '%f\\t%f\\t%1.6f\\t%s \\n' %\\\n",
    "                             (wv,ext[iw],ssa[iw],\n",
    "                              \" \".join(['{:1.5g}'.format(x/(2.0*i+1.0)) for i,x in enumerate(moments[iw][0,0:int(nmom[iw])])]))\n",
    "                if len(st)>1000000:\n",
    "                    st = '%f\\t%f\\t%1.6f\\t%s \\n' %\\\n",
    "                             (wv,ext[iw],ssa[iw],\n",
    "                              \" \".join(['{:1.4g}'.format(x/(2.0*i+1.0)) for i,x in enumerate(moments[iw][0,0:int(nmom[iw])])]))\n",
    "                    an = len(moments[iw][0,0:int(nmom[iw])])-1\n",
    "                    print 'trying to reduce size', len(st), an\n",
    "                    while len(st)>1000000:\n",
    "                        df = int((len(st)-1000000)/10)\n",
    "                        an = an-df-10\n",
    "                        st = '%f\\t%f\\t%1.6f\\t%s \\n' %\\\n",
    "                             (wv,ext[iw],ssa[iw],\n",
    "                              \" \".join(['{:1.4g}'.format(x/(2.0*i+1.0)) for i,x in enumerate(moments[iw][0,0:an])]))\n",
    "                        print 'in size reduction', len(st),an\n",
    "                out_string.append(st)\n",
    "        \n",
    "        process_wrapper_file_print(output_file,out_string,append=False,fifo=fifo)\n",
    "        \n",
    "    if verbose:\n",
    "        print('..File write_cloud_file_moments_wvl finished, closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def write_albedo_file(output_file,wvl=[],alb=[],verbose=False,fifo=False,use_old=False):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "\n",
    "        Writes the file with surface albedo per wavelength\n",
    "        outputs 2 column: \n",
    "            # wvl[nm]    albedo[unitless]\n",
    "            \n",
    "    Input: \n",
    "  \n",
    "        output_file: full path to file to be written\n",
    "        wvl: wavelength array in nm\n",
    "        alb: value of albedo at each wavelength, unitless\n",
    "        \n",
    "    Output:\n",
    "\n",
    "        output_file of albedo values \n",
    "                    \n",
    "    Keywords: \n",
    "\n",
    "        verbose: (default False) if true prints out info about file writing \n",
    "        fifo: (default False) if true, then writes to a fifo file, and starts a seperate thread to only write this file, \n",
    "              then immediatly close\n",
    "        use_old: (default False) if True, then uses previous method of file writing.\n",
    "    \n",
    "    Dependencies:\n",
    "\n",
    "        none\n",
    "    \n",
    "    Required files:\n",
    "   \n",
    "        none\n",
    "    \n",
    "    Example:\n",
    "\n",
    "        ...\n",
    "        \n",
    "    Modification History:\n",
    "    \n",
    "        Written (v1.0): Samuel LeBlanc, 2015-06-26, NASA Ames, from Santa Cruz, CA\n",
    "        Modified (v1.1): Samuel LeBlanc, 2020-05-11, Santa Cruz, CA, under COVID-19 stay-at-home\n",
    "                 - added fifo writing handling\n",
    "    \"\"\"\n",
    "    if not len(wvl)==len(alb):\n",
    "        raise LookupError(\"wvl and alb don't have the same size\")\n",
    "    \n",
    "    if use_old:\n",
    "        try:\n",
    "            output = file(output_file,'w')\n",
    "        except Exception,e:\n",
    "            print 'Problem with accessing file, return Exception: ',e\n",
    "            return\n",
    "        if verbose:\n",
    "            print('..printing to albedo wavelength defined file: %s' % output_file)\n",
    "        output.write('# wvl[nm]    alb[unitless] \\n')\n",
    "        for iw,w in enumerate(wvl):\n",
    "            if not w>100.0:\n",
    "                print '** Possible error with wavelenght, values below 100 nm, check units **'\n",
    "            output.write('%f\\t%f\\n' % (w,alb[iw]))\n",
    "        output.close()\n",
    "    else:\n",
    "        out_string = []\n",
    "        out_string.append('# wvl[nm]    alb[unitless] \\n')\n",
    "        for iw,w in enumerate(wvl):\n",
    "            if not w>100.0:\n",
    "                print '** Possible error with wavelenght, values below 100 nm, check units **'\n",
    "            out_string.append('%f\\t%f\\n' % (w,alb[iw]))\n",
    "        process_wrapper_file_print(output_file,out_string,append=False,fifo=fifo)\n",
    "        \n",
    "    if verbose:\n",
    "        print('..File write_albedo_file finished, closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def get_cloud_ext_ssa_moms(ref,lwc,moms_dict=None,verbose=False):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "\n",
    "        Extracts the moments, extinction, ssa \n",
    "        \n",
    "    Input: \n",
    "  \n",
    "        ref: effective radius of cloud particles [microns]\n",
    "        lwc: liquid/ice water content in cloud [g/m^3]\n",
    "        moms_dict: dictionary from saved legendre moments. \n",
    "                    Includes: ntheta, pmom, rho, nmom, ssa, nim, nre, ext, wvl, phase, theta, ref\n",
    "        \n",
    "    Output:\n",
    "\n",
    "        ext,ssa,wvl,moments,nmom\n",
    "        ext: extinction coefficient of cloud per wavelength [km^-1]\n",
    "        ssa: single scattering albedo of cloud per wavelength [unitless]\n",
    "        wvl: wavelength array of returned properties [nm]\n",
    "        moments: array of legendre moments at each wavelength\n",
    "        nmom: number of legendre moments\n",
    "                \n",
    "    Keywords: \n",
    "\n",
    "        verbose: (default False) if true prints out info about file writing \n",
    "    \n",
    "    Dependencies:\n",
    "\n",
    "        numpy\n",
    "        sys\n",
    "        scipy.io (for loading idl files)\n",
    "    \n",
    "    Required files:\n",
    "   \n",
    "        none\n",
    "    \n",
    "    Example:\n",
    "\n",
    "        ext,ssa,wvl,moments,nmom = get_cloud_ext_ssa_moms(ref,lwc,moms_dict=moms_dict,verbose=True)\n",
    "        \n",
    "    Modification History:\n",
    "    \n",
    "        Written (v1.0): Samuel LeBlanc, 2015-06-30, NASA Ames, from Santa Cruz, CA\n",
    "        Modified: Samuel LeBlanc, 2017-02-17, Santa Cruz, CA\n",
    "                  Changed the output commands to easily pass the ice pmoms as well as the wc\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    if verbose:\n",
    "        print '..Getting the moments and extinction coefficients from the moms_dict of cloud properties'\n",
    "    \n",
    "    if not moms_dict:\n",
    "        import sys\n",
    "        if sys.platform=='win32':\n",
    "            fdict = 'C:/Users/sleblan2/Research/4STAR/rtm_dat/mie_hi.out'\n",
    "        else:\n",
    "            fdict = '/u/sleblan2/4STAR/rtm_dat/mie_hi.out'\n",
    "        print 'No moments dict defined, loading defaults: '+fdict\n",
    "        import scipy.io as sio\n",
    "        moms_dict = sio.idl.read(fdict)\n",
    "    ir = np.argmin(abs(moms_dict['ref']-ref))\n",
    "    ext = moms_dict['ext'][ir,:]*lwc\n",
    "    wvl = moms_dict['wvl']\n",
    "    if wvl[0]<1:\n",
    "        wvl = wvl*1000.0\n",
    "    nm = moms_dict.get('max_nmoms',-1)\n",
    "    if moms_dict.get('max_nmoms',False):\n",
    "        nmom = moms_dict['nmom'][ir,:]*0+nm\n",
    "    else:\n",
    "        nmom = moms_dict['nmom'][ir,:]\n",
    "\n",
    "    return ext,moms_dict['ssa'][ir,:],wvl,moms_dict['pmom'][ir,:],nmom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def write_input_aac(output_file,geo={},aero={},cloud={},source={},albedo={},\n",
    "                    verbose=False,make_base=False,fp_base_file=None,set_quiet=True,max_nmom=None,solver='disort',\n",
    "                    fifo=False,use_old=False,return_string=False):\n",
    "    \"\"\"\n",
    "    Name:\n",
    "\n",
    "        write_input_aac\n",
    "    \n",
    "    Purpose:\n",
    "\n",
    "        Writes the libradtran input file with defined defaults, see below\n",
    "        outputs libradtran input files in ascii format\n",
    "        \n",
    "        ** There is a multitude of other default parameters. \n",
    "        ** These should be changed for any other type of input files to be written\n",
    "    \n",
    "    Input: \n",
    "  \n",
    "        output_file: full path to file to be written\n",
    "        geo: dictionary with geometry details\n",
    "            sza: solar zenith angle (libradtran default is 0)\n",
    "            lat: latitude\n",
    "            lon: longitude\n",
    "            doy: day of year  # for calculating sun earth distance\n",
    "            year: year (YYYY format) # used if you want uvspec to calculate the sza\n",
    "            month: month (MM format)\n",
    "            day: day of the month (DD format)\n",
    "            hour: hour of the day, 24h format, UTC\n",
    "            minute: minutes of the hour\n",
    "            second: seconds of the minute\n",
    "            zout: at what altitude should be outputted, in km, default is 0 and 100\n",
    "        aero: dictionary with aerosol properties\n",
    "            ext: value of aerosol extinction coefficient at each altitude and wavelength [alt,wvl]\n",
    "                 To define the top most layer, ext must be zero at that altitude\n",
    "            ssa: value of aerosol single scattering albedo at each altitude and wavelength [alt,wvl]\n",
    "            asy: value of aerosol asymmetry parameter at each altitude and wavelength [alt,wvl]\n",
    "            z_arr: value of altitudes to use with ext,ssa,asy\n",
    "            wvl_arr: array of wavelengths in nm\n",
    "            link_to_mom_file: if True then no moments file is written out, but it is referenced via\n",
    "                              file_name saved to aero dict\n",
    "            file_name: file name and paths of explicit file for aerosol defined. \n",
    "                       By default it is created in this program if it is not set, \n",
    "                       if link_to_mom_file is set, this must be defined\n",
    "            disort_phase: (default False) if true then writes then phase function instead of the moments.\n",
    "            expand_hg: (default False) if true expands the henyey greenstein phase function into legendre moments.\n",
    "        cloud: dictionary with cloud properties\n",
    "            tau: value of cloud optical thickness\n",
    "            ref: value of effective radius in microns\n",
    "            ztop: location in km of cloud top\n",
    "            zbot: location in km of cloud bottom\n",
    "            phase: either 'ic' for ice cloud or 'wc' for water cloud\n",
    "            write_moments_file: (default False) if True, writes out moments into an ascii file instead \n",
    "                                of reading directly from the netcdf file. \n",
    "                                Requires the moments to be put in the cloud dict and the nmom.\n",
    "            moms_dict: is the moment dict structure returned from the mie_hi.out idl.readsav. or now the mie_hi_delta.mat\n",
    "                       To be used when building the moments file\n",
    "            link_to_mom_file: if True then no moments file is written out, but referenced via file_name saved to cloud dict\n",
    "            file_name: file name and paths of moments file for cloud defined. \n",
    "                       By default it is created in this program if not set, if link_to_mom_file is set, this must be defined\n",
    "            cloud_below: (default False) if set, creates a liquid cloud with constant properties (tau=10,ref=10 microns), \n",
    "                         of thickness 1 km, directly below the zbot value. Used for in cloud calculations\n",
    "        source: dictionary with source properties\n",
    "            wvl_range: range of wavelengths to model (default [202,500])\n",
    "            source: can either be thermal or solar\n",
    "            dat_path: data path to be used. Defaults to pleaides values (/u/sleblan2/libradtran/libRadtran-2.0-beta/data/)\n",
    "            integrate_values: if True (default), then the resulting output parameters are integrated over wavelength range\n",
    "                              if set to False, returns per_nm irradiance values\n",
    "            wvl_filename: filename and path of wavelength file (second column has wavelengh in nm to be used)\n",
    "            run_fuliou: if set to True, then runs fu liou instead of sbdart (default is False)\n",
    "            slit_file: (defaults to None) Full file path of slit file to use for calculating the radiative transfer.\n",
    "            atm_file: (defaults to None) Full file path of the atmosphere file to use, \n",
    "                      if not set, libradtran calculates from position and time on Earth\n",
    "            zenith: (defaults to False) if True, prepares the input file for returning zenith radiances\n",
    "                    adds a zenith viewing angle (umu=-1), azimuth viewing angle (phi=130) and solar azimuth angle (phi0=130)\n",
    "        albedo: dictionary with albedo properties\n",
    "            create_albedo_file: (default False) if true then albedo file is created with properties defined by alb_wvl and alb \n",
    "            albedo_file: path of albedo file to use if already created \n",
    "            albedo: value of albedo. Only used if create_albedo_file is false and albedo_file is empty \n",
    "                    (defaults to 0.29 - Earth's average)\n",
    "            alb: wavelength dependent value of albedo for use when create_albedo_file is set to True\n",
    "            alb_wvl: wavelength grid of albedo for use when create_albedo_file is set to True\n",
    "            sea_surface_albedo: (default False) If True, sets the sea surface to be parameterized by cox and munk, \n",
    "                                requires wind_speed to be set.\n",
    "            wind_speed: [m/s] (default to 10 m/s) Only used if sea_surface_albedo is set to True. \n",
    "                        wind speed over water for parameterization of cox_and_munk\n",
    "        make_base: boolean to set if the base file is to be written out\n",
    "                   if False, no base file is saved.\n",
    "                   Base file contains quiet flag, data path, source, rad transfer solver, \n",
    "                     output process, wavelength source file, \n",
    "        fp_base_file: full file path for base file. \n",
    "                      If set to a file path and make_base to False, then include path is printed to input file. \n",
    "        set_quiet: if True then quiet is set in the input file, if False, quiet is not set. (default True)\n",
    "        max_nmom: set the maximum number of moments to write out (default None)\n",
    "    \n",
    "    Output:\n",
    "\n",
    "        output_file\n",
    "    \n",
    "    Keywords: \n",
    "\n",
    "        verbose: (default False) if true prints out info about file writing \n",
    "        fifo: (default False) if true, then writes to a fifo file, and starts a seperate thread to only write this file, \n",
    "              then immediatly close\n",
    "        use_old: (default False) if True, then uses previous method of file writing.\n",
    "        return_False: (default False) if True, then returns a string list instead of an input file\n",
    "    \n",
    "    Dependencies:\n",
    "\n",
    "        numpy\n",
    "        Run_libradtran (this file)\n",
    "    \n",
    "    Required files:\n",
    "   \n",
    "        none\n",
    "    \n",
    "    Example:\n",
    "        \n",
    "        Example taken from lut creation for NAAMES, \n",
    "            uses St John's Newfoundland location, on Nov. 19th for low clouds (from 0.5km to 1.5km) over ocean\n",
    "            returns zenith radiances and irradiance at 0.2,3.0 and 100 km\n",
    "            uses internal cloud properties\n",
    "            for vis spectral range, with slit function\n",
    "            no aerosol\n",
    "            cloud tau=2.0, ref=5.0, sza=40.0\n",
    "        \n",
    "        >>> geo = {'lat':47.6212167,'lon':52.74245,'doy':322,'zout':[0.2,3.0,100.0]}\n",
    "        >>> aero = {} # none\n",
    "        >>> cloud = {'ztop':1.5,'zbot':0.5,'write_moments_file':False}\n",
    "        >>> source = {'wvl_range':[400.0,981.0],'source':'solar','integrate_values':False,'run_fuliou':False,\n",
    "                      'dat_path':'/u/sleblan2/libradtran/libRadtran-2.0-beta/data/'}\n",
    "        >>> albedo = {'create_albedo_file':False,'sea_surface_albedo':True,'wind_speed':14.0}\n",
    "        >>> cloud['phase'] = 'wc'\n",
    "        >>> geo['sza'] = 40.0\n",
    "        >>> cloud['tau'] = 2.0\n",
    "        >>> cloud['ref'] = 5.0\n",
    "        \n",
    "        >>> RL.write_input_aac('/u/sleblan2/NAAMES/runs/NAAMES_v1.dat',geo=geo,aero=aero,cloud=cloud,\n",
    "                               source=source,albedo=albedo,\n",
    "                               verbose=False,make_base=False,set_quiet=True)\n",
    "        \n",
    "    Modification History:\n",
    "    \n",
    "        Written (v1.0): Samuel LeBlanc, 2015-06-26, NASA Ames, from Santa Cruz, CA\n",
    "        Modified: Samuel LeBlanc, 2015-06-29, NASA Ames, from Santa Cruz, CA\n",
    "                - added writing of moments for cloud properties file\n",
    "        Modified: Samuel LeBlanc, 2015-07-01, NASA Ames, Happy Canada Day!\n",
    "                - added sea-surface albedo parameterization\n",
    "        Modified: Samuel LeBlanc, 2015-07-08, Santa Cruz, CA\n",
    "                - added base file writing\n",
    "                - added wvl_filename which is to be writen out\n",
    "        Modified: Samuel LeBlanc, 2015-07-09, NASA Ames, CA\n",
    "                - possibility of using the fuliou codes instead of sbdart\n",
    "                - added link_to_mom_file to cloud and aero dict\n",
    "                - added file_name in cloud and aero dict\n",
    "        Modified: Samuel LeBlanc, 2015-10-06, NASA Ames, CA\n",
    "                - modified comments\n",
    "                - added slit_file to source options\n",
    "                - added atm_file to source options\n",
    "                - added zenith radiance keyword\n",
    "        Modified: Samuel LeBlanc, on the DC8 flying above Korea, 2016-05-02\n",
    "                - added the cloud_below keyword to the cloud options.\n",
    "        Modified: Samuel LeBlanc, NASA Ames, CA, 2016-09-22\n",
    "                - added expansion of henyey greenstein legendre moments for aerosol explict files\n",
    "        Modified: Samuel LeBlanc, Santa Cruz, CA, 2017-12-06\n",
    "                - modified use of mie_hi.out for mie_hi_delta.mat with new delta-scaling legendre functions\n",
    "        Modified: Samuel LeBlanc, 2020-05-11, Santa Cruz, CA, under COVID-19 stay-at-home\n",
    "                 - added fifo writing handling, and string file return\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from Run_libradtran import write_aerosol_file_explicit,write_cloud_file,write_albedo_file,merge_dicts\n",
    "    from Run_libradtran import write_cloud_file_moments\n",
    "    \n",
    "    if use_old:\n",
    "        if return_string: print '** return_string option not enabled with use_old **'\n",
    "        try:\n",
    "            output = file(output_file,'w')\n",
    "        except Exception,e:\n",
    "            print 'Problem with accessing file, return Exception: ',e\n",
    "            return\n",
    "        if verbose: print 'Opening input file %s' % output_file\n",
    "\n",
    "    if make_base:\n",
    "        if fp_base_file:\n",
    "            if use_old: base = file(fp_base_file,'w')\n",
    "            include_base = True\n",
    "        else:\n",
    "            print 'Problem: No fp_base_file set, please set before running'\n",
    "            return\n",
    "    else:\n",
    "        if fp_base_file:\n",
    "            include_base = True\n",
    "        else:\n",
    "            include_base = False    \n",
    "                \n",
    "    if verbose: print '..setting the dicts to defaults'\n",
    "    source = merge_dicts({'dat_path':'/u/sleblan2/libradtran/libRadtran-2.0-beta/data/',\n",
    "                          'source':'solar',\n",
    "                          'wvl_range':[250.0,500.0],\n",
    "                          'integrate_values':True,\n",
    "                          'run_fuliou':False,\n",
    "                          'zenith':False},source)\n",
    "    albedo = merge_dicts({'create_albedo_file':False,'sea_surface_albedo':False,'wind_speed':10,\n",
    "                          'albedo':0.29},albedo)\n",
    "    geo = merge_dicts({'zout':[0,100]},geo)\n",
    "    cloud = merge_dicts({'write_moments_file':False,'cloud_below':False},cloud)\n",
    "\n",
    "    if source.get('source')=='solar':\n",
    "        source['source'] = 'solar '+source['dat_path']+'solar_flux/kurudz_1.0nm.dat per_nm'\n",
    "\n",
    "    if verbose: print '..write out general default values'\n",
    "    if use_old:\n",
    "        if make_base:\n",
    "            if source['run_fuliou']:\n",
    "                base.write('mol_abs_param fu\\n')\n",
    "            else:\n",
    "                base.write('mol_abs_param sbdart\\n')\n",
    "            base.write('rte_solver {}\\n'.format(solver))\n",
    "            if set_quiet:\n",
    "                base.write('quiet\\n')\n",
    "        else:\n",
    "            if set_quiet:\n",
    "                output.write('quiet\\n')\n",
    "            if source['run_fuliou']:\n",
    "                output.write('mol_abs_param fu\\n')\n",
    "            else:\n",
    "                output.write('mol_abs_param sbdart\\n')\n",
    "            output.write('rte_solver {}\\n'.format(solver))\n",
    "\n",
    "        if include_base:\n",
    "            output.write('include %s\\n' % fp_base_file)\n",
    "\n",
    "        if verbose: print '..write out source dict values'\n",
    "        if make_base:\n",
    "            if source['integrate_values']:\n",
    "                if source['run_fuliou']:\n",
    "                    base.write('output_process sum\\n')\n",
    "                else:\n",
    "                    base.write('output_process integrate\\n')\n",
    "            else:\n",
    "                base.write('output_process per_nm\\n')\n",
    "            base.write('data_files_path %s\\n' % source['dat_path'])\n",
    "        elif not include_base:\n",
    "            if source['integrate_values']:\n",
    "                if source['run_fuliou']:\n",
    "                    output.write('output_process sum\\n')\n",
    "                else:\n",
    "                    output.write('output_process integrate\\n')\n",
    "            else:\n",
    "                output.write('output_process per_nm\\n')\n",
    "            output.write('data_files_path %s\\n' % source['dat_path'])\n",
    "        output.write('source %s \\n' % source['source'])\n",
    "\n",
    "        if source.get('wvl_filename'):\n",
    "            output.write('wavelength %s\\n' % source['wvl_filename'])\n",
    "        else:\n",
    "            if source['wvl_range'][0]>source['wvl_range'][1]:\n",
    "                if verbose:\n",
    "                    print 'wvl_range was set inverse, inversing'\n",
    "                source['wvl_range'] = list(reversed(source['wvl_range'])) \n",
    "            if source['wvl_range'][0]<250:\n",
    "                if verbose:\n",
    "                    print 'wvl_range starting too low, setting to 250 nm'\n",
    "                source['wvl_range'][0] = 250.0\n",
    "            output.write('wavelength %f %f\\n' % (source['wvl_range'][0],source['wvl_range'][1]))\n",
    "\n",
    "        if source.get('slit_file'):\n",
    "            output.write('slit_function_file %s\\n'%source['slit_file'])\n",
    "\n",
    "        if source.get('atm_file'):\n",
    "            output.write('atmosphere_file %s\\n'%source['atm_file'])\n",
    "\n",
    "        if source['zenith']:\n",
    "            output.write('umu -1.0\\n')\n",
    "            output.write('phi 130.0\\n')\n",
    "            output.write('phi0 130.0\\n')\n",
    "\n",
    "\n",
    "\n",
    "        if verbose: print '..write out the albedo values'\n",
    "        if albedo['create_albedo_file']:\n",
    "            albedo['albedo_file'] = output_file+'_alb'\n",
    "            write_albedo_file(albedo['albedo_file'],albedo['alb_wvl'],albedo['alb'],use_old=use_old)\n",
    "            output.write('albedo_file %s\\n' % albedo['albedo_file'])\n",
    "        elif albedo.get('albedo_file'):\n",
    "            output.write('albedo_file %s\\n' % albedo['albedo_file'])\n",
    "        elif albedo.get('sea_surface_albedo'):\n",
    "            output.write('brdf_cam u10 %i\\n' % albedo['wind_speed'])\n",
    "        else:\n",
    "            output.write('albedo %f\\n' % albedo['albedo'])\n",
    "\n",
    "        if verbose: print '..write out the geo values'\n",
    "        output.write('zout %s \\n' % \" \".join([str(x) for x in geo['zout']]))\n",
    "        if geo.get('lat'):\n",
    "            output.write(\"latitude %s %f\\n\" % ('S' if geo['lat']<0 else 'N',abs(geo['lat'])))\n",
    "            output.write(\"longitude %s %f\\n\" % ('W' if geo['lon']<0 else 'E',abs(geo['lon'])))\n",
    "        if geo.get('sza'):\n",
    "            output.write('sza %f\\n' % geo['sza'])\n",
    "        if geo.get('doy'):\n",
    "            output.write('day_of_year %i\\n' % geo['doy'])\n",
    "        if geo.get('year'):\n",
    "            output.write('time %04i %02i %02i %02i %02i %02i\\n' \n",
    "                         %(geo['year'],geo['month'],geo['day'],geo['hour'],geo['minute'],geo['second']))\n",
    "\n",
    "        if 'ext' in aero:\n",
    "            if verbose: print '..write out the aerosol parameters'\n",
    "            if aero.get('disort_phase'):\n",
    "                dd = 'phase'\n",
    "            else:\n",
    "                dd = 'moments'\n",
    "            aero['expand_hg'] = aero.get('expand_hg',False)\n",
    "            if make_base:\n",
    "                base.write('aerosol_default\\n')\n",
    "                base.write('disort_intcor {}\\n'.format(dd)) #set to use moments for explicit aerosol file\n",
    "            elif not include_base:    \n",
    "                output.write('aerosol_default\\n')\n",
    "                output.write('disort_intcor {}\\n'.format(dd)) #set to use moments for explicit aerosol file\n",
    "            if not aero.get('link_to_mom_file'):\n",
    "                if not aero.get('file_name'):\n",
    "                    aero['file_name'] = output_file+'_aero'\n",
    "                write_aerosol_file_explicit(aero['file_name'],aero['z_arr'],aero['ext'],aero['ssa'],\n",
    "                                            aero['asy'],aero['wvl_arr'],verbose=verbose,\n",
    "                                            expand_hg=aero['expand_hg'],use_old=use_old)\n",
    "            output.write('aerosol_file explicit %s\\n' % aero['file_name'])\n",
    "\n",
    "        if 'tau' in cloud:\n",
    "            if verbose: print '..write out the cloud properties'\n",
    "            if not cloud.get('link_to_mom_file'):\n",
    "                if not cloud.get('file_name'):\n",
    "                    cloud['file_name'] = output_file+'_cloud'\n",
    "            if cloud['phase']=='ic':\n",
    "                if verbose: print '..Ice cloud'\n",
    "                output.write('ic_file %s %s\\n' % ('moments' if cloud['write_moments_file'] else '1D',cloud['file_name']))\n",
    "                output.write('ic_properties baum_v36 interpolate\\n')\n",
    "            elif cloud['phase']=='wc':\n",
    "                if verbose: print '..Liquid water cloud'\n",
    "                output.write('wc_file %s %s\\n' % ('moments' if cloud['write_moments_file'] else '1D',cloud['file_name']))\n",
    "                output.write('wc_properties mie %s\\n' %('interpolate' if not source['run_fuliou'] else ' '))\n",
    "            else:\n",
    "                raise ValueError('phase value in cloud dict not recognised')\n",
    "            if cloud['write_moments_file']:\n",
    "                if not 'ext' in aero:\n",
    "                    output.write('disort_intcor moments\\n') \n",
    "                if not cloud.get('link_to_mom_file'):\n",
    "                    write_cloud_file_moments(cloud['file_name'],cloud['tau'],cloud['ref'],cloud['zbot'],cloud['ztop'],\n",
    "                                             verbose=verbose,moms_dict=cloud.get('moms_dict'),wvl_range=source['wvl_range'],\n",
    "                                             use_old=use_old)\n",
    "                if cloud['cloud_below']:\n",
    "                    if not cloud.get('link_to_mom_file'):\n",
    "                        write_cloud_file_moments(cloud['file_name'],10,10,cloud['zbot']-1.0,cloud['zbot'],\n",
    "                                                 verbose=verbose,moms_dict=cloud.get('moms_dict'),\n",
    "                                                 append_directly_below=True,wvl_range=source['wvl_range'],use_old=use_old)\n",
    "\n",
    "            else:\n",
    "                if not cloud.get('link_to_mom_file'):\n",
    "                    write_cloud_file(cloud['file_name'],cloud['tau'],cloud['ref'],cloud['zbot'],cloud['ztop'],\n",
    "                                     verbose=verbose,use_old=use_old)\n",
    "                if cloud['cloud_below']:\n",
    "                    if not cloud.get('link_to_mom_file'):\n",
    "                        write_cloud_file(cloud['file_name'],10,10,cloud['zbot']-1.0,cloud['zbot'],\n",
    "                                         verbose=verbose,append_directly_below=True,use_old=use_old)\n",
    "        output.close()\n",
    "        if make_base:\n",
    "            base.close()\n",
    "    else:\n",
    "        out_string = []\n",
    "        base_string = []\n",
    "        if set_quiet: base_string.append('quiet\\n')\n",
    "        base_string.append('rte_solver {}\\n'.format(solver))\n",
    "        if source['run_fuliou']:\n",
    "            base_string.append('mol_abs_param fu\\n')\n",
    "        else:\n",
    "            base_string.append('mol_abs_param sbdart\\n')\n",
    "        \n",
    "        if include_base: out_string.append('include %s\\n' % fp_base_file)\n",
    "        \n",
    "        if verbose: print '..write out source dict values'\n",
    "        if source['integrate_values']:\n",
    "            if source['run_fuliou']:\n",
    "                base_string.append('output_process sum\\n')\n",
    "            else:\n",
    "                base_string.append('output_process integrate\\n')\n",
    "        else:\n",
    "            base_string.append('output_process per_nm\\n')\n",
    "        base_string.append('data_files_path %s\\n' % source['dat_path'])\n",
    "        base_string.append('source %s \\n' % source['source'])\n",
    "        if source.get('wvl_filename'):\n",
    "            base_string.append('wavelength %s\\n' % source['wvl_filename'])\n",
    "        else:\n",
    "            if source['wvl_range'][0]>source['wvl_range'][1]:\n",
    "                if verbose:\n",
    "                    print 'wvl_range was set inverse, inversing'\n",
    "                source['wvl_range'] = list(reversed(source['wvl_range'])) \n",
    "            if source['wvl_range'][0]<250:\n",
    "                if verbose:\n",
    "                    print 'wvl_range starting too low, setting to 250 nm'\n",
    "                source['wvl_range'][0] = 250.0\n",
    "            base_string.append('wavelength %f %f\\n' % (source['wvl_range'][0],source['wvl_range'][1]))\n",
    "\n",
    "        if source.get('slit_file'): base_string.append('slit_function_file %s\\n'%source['slit_file'])\n",
    "        if source.get('atm_file'): base_string.append('atmosphere_file %s\\n'%source['atm_file'])\n",
    "        if source['zenith']:\n",
    "            base_string.append('umu -1.0\\n')\n",
    "            base_string.append('phi 130.0\\n')\n",
    "            base_string.append('phi0 130.0\\n')\n",
    "        \n",
    "        if verbose: print '..write out the albedo values'\n",
    "        if albedo['create_albedo_file']:\n",
    "            albedo['albedo_file'] = output_file+'_alb'\n",
    "            write_albedo_file(albedo['albedo_file'],albedo['alb_wvl'],albedo['alb'],use_old=use_old,fifo=fifo)\n",
    "            out_string.append('albedo_file %s\\n' % albedo['albedo_file'])\n",
    "        elif albedo.get('albedo_file'):\n",
    "            out_string.append('albedo_file %s\\n' % albedo['albedo_file'])\n",
    "        elif albedo.get('sea_surface_albedo'):\n",
    "            out_string.append('brdf_cam u10 %i\\n' % albedo['wind_speed'])\n",
    "        else:\n",
    "            out_string.append('albedo %f\\n' % albedo['albedo'])\n",
    "        \n",
    "        if verbose: print '..write out the geo values'\n",
    "        out_string.append('zout %s \\n' % \" \".join([str(x) for x in geo['zout']]))\n",
    "        if geo.get('lat'):\n",
    "            out_string.append(\"latitude %s %f\\n\" % ('S' if geo['lat']<0 else 'N',abs(geo['lat'])))\n",
    "            out_string.append(\"longitude %s %f\\n\" % ('W' if geo['lon']<0 else 'E',abs(geo['lon'])))\n",
    "        if geo.get('sza'): out_string.append('sza %f\\n' % geo['sza'])\n",
    "        if geo.get('doy'): out_string.append('day_of_year %i\\n' % geo['doy'])\n",
    "        if geo.get('year'):\n",
    "            out_string.append('time %04i %02i %02i %02i %02i %02i\\n' \n",
    "                         %(geo['year'],geo['month'],geo['day'],geo['hour'],geo['minute'],geo['second']))\n",
    "        \n",
    "        if 'ext' in aero:\n",
    "            if verbose: print '..write out the aerosol parameters'\n",
    "            if aero.get('disort_phase'):\n",
    "                dd = 'phase'\n",
    "            else:\n",
    "                dd = 'moments'\n",
    "            aero['expand_hg'] = aero.get('expand_hg',False)\n",
    "            base_string.append('aerosol_default\\n')\n",
    "            base_string.append('disort_intcor {}\\n'.format(dd)) #set to use moments for explicit aerosol file\n",
    "            if not aero.get('link_to_mom_file'):\n",
    "                if not aero.get('file_name'):\n",
    "                    aero['file_name'] = output_file+'_aero'\n",
    "                write_aerosol_file_explicit(aero['file_name'],aero['z_arr'],aero['ext'],aero['ssa'],\n",
    "                                            aero['asy'],aero['wvl_arr'],verbose=verbose,\n",
    "                                            expand_hg=aero['expand_hg'],use_old=use_old,fifo=fifo)\n",
    "            out_string.append('aerosol_file explicit %s\\n' % aero['file_name'])\n",
    "            \n",
    "        if 'tau' in cloud:\n",
    "            if verbose: print '..write out the cloud properties'\n",
    "            if not cloud.get('link_to_mom_file'):\n",
    "                if not cloud.get('file_name'):\n",
    "                    cloud['file_name'] = output_file+'_cloud'\n",
    "            if cloud['phase']=='ic':\n",
    "                if verbose: print '..Ice cloud'\n",
    "                out_string.append('ic_file %s %s\\n' % ('moments' if cloud['write_moments_file'] else '1D',cloud['file_name']))\n",
    "                out_string.append('ic_properties baum_v36 interpolate\\n')\n",
    "            elif cloud['phase']=='wc':\n",
    "                if verbose: print '..Liquid water cloud'\n",
    "                out_string.append('wc_file %s %s\\n' % ('moments' if cloud['write_moments_file'] else '1D',cloud['file_name']))\n",
    "                out_string.append('wc_properties mie %s\\n' %('interpolate' if not source['run_fuliou'] else ' '))\n",
    "            else:\n",
    "                raise ValueError('phase value in cloud dict not recognised')\n",
    "            if cloud['write_moments_file']:\n",
    "                if not 'ext' in aero:\n",
    "                    out_string.append('disort_intcor moments\\n') \n",
    "                if not cloud.get('link_to_mom_file'):\n",
    "                    write_cloud_file_moments(cloud['file_name'],cloud['tau'],cloud['ref'],cloud['zbot'],cloud['ztop'],\n",
    "                                             verbose=verbose,moms_dict=cloud.get('moms_dict'),wvl_range=source['wvl_range'],\n",
    "                                             use_old=use_old,fifo=fifo)\n",
    "                if cloud['cloud_below']:\n",
    "                    if not cloud.get('link_to_mom_file'):\n",
    "                        write_cloud_file_moments(cloud['file_name'],10,10,cloud['zbot']-1.0,cloud['zbot'],\n",
    "                                                 verbose=verbose,moms_dict=cloud.get('moms_dict'),\n",
    "                                                 append_directly_below=True,wvl_range=source['wvl_range'],\n",
    "                                                 use_old=use_old,fifo=fifo)\n",
    "\n",
    "            else:\n",
    "                if not cloud.get('link_to_mom_file'):\n",
    "                    write_cloud_file(cloud['file_name'],cloud['tau'],cloud['ref'],cloud['zbot'],cloud['ztop'],\n",
    "                                     verbose=verbose,use_old=use_old,fifo=fifo)\n",
    "                if cloud['cloud_below']:\n",
    "                    if not cloud.get('link_to_mom_file'):\n",
    "                        write_cloud_file(cloud['file_name'],10,10,cloud['zbot']-1.0,cloud['zbot'],\n",
    "                                         verbose=verbose,append_directly_below=True,use_old=use_old,fifo=fifo)\n",
    "        \n",
    "        if make_base:\n",
    "            if return_string: print '** Cant have both make_base and return_string enabled... Making files and not returning string'\n",
    "            process_wrapper_file_print(fp_base_file,base_string,append=False,fifo=fifo)\n",
    "            process_wrapper_file_print(output_file,out_string,append=False,fifo=fifo)\n",
    "        elif return_string:\n",
    "            return base_string.extend(out_string)\n",
    "        else:\n",
    "            base_string.extend(out_string)\n",
    "            process_wrapper_file_print(output_file,base_string,append=False,fifo=fifo)\n",
    "                \n",
    "    if verbose: print 'Finished printing main input file: Closing file'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def merge_dicts(*dict_args):\n",
    "    \"\"\"\n",
    "    Given any number of dicts, shallow copy and merge into a new dict,\n",
    "    precedence goes to key value pairs in latter dicts.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for dictionary in dict_args:\n",
    "        result.update(dictionary)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def make_pmom_inputs(fp_rtm='C:/Users/sleblan2/Research/4STAR/rtm_dat/',\n",
    "                     source='solar',cloudtype='wc',deltascale=True,new=True):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    \n",
    "        Create the moments used as input for the write_input_aac function\n",
    "        \n",
    "    Input:\n",
    "    \n",
    "        fp_rtm: path to the files to load\n",
    "        source: either solar or thermal (default is solar)\n",
    "        cloudtype: either 'wc' for water cloud or 'ic' for ice cloud \n",
    "        deltascale: (default True) if true, uses the mie_hi_delta.mat instead of mie_hi.out\n",
    "        new: (default True) if true, uses the run2020112_SL calculations - restricted to 20 microns, 350 nm to 1700 nm\n",
    "    \n",
    "    Dependencies:\n",
    "\n",
    "        numpy\n",
    "        scipy\n",
    "    \n",
    "    Required files:\n",
    "   \n",
    "        mie_hi.out or mie_hi_delta.mat\n",
    "        wc.sol.long.mie.cdf\n",
    "        wc.sol.short.mie.cdf        \n",
    "        ic.pmom.ghm.baum.mat\n",
    "    \n",
    "    Modification History:\n",
    "    \n",
    "        Written (v1.0): Samuel LeBlanc, 2015-06-30, NASA Ames, from Santa Cruz, CA\n",
    "        Modified: Samuel LeBlanc, 2015-07-02, Santa Cruz, CA\n",
    "                    - added source keyword\n",
    "                    - added new file for loading of thermal mie properties\n",
    "        Modified: Samuel LeBlanc, 2015-07-07, NASA Ames, CA\n",
    "                    - added the allpmom netcdf file from Claudia Emde for Solar \n",
    "        Modified: Samuel LeBlanc, 2015-07-08, Santa Cruz, CA\n",
    "                    - fixed bugs with Claudia Emde's full pmom netcdf files. Added longer wavelengths to be saved.\n",
    "        Modified: Samuel LeBlanc, 2017-02-15, Santa Cruz, CA\n",
    "                    - added ic file from calculations of pmom from Create_ic_phase.py file\n",
    "        Modified: Samuel LeBlanc, 2017-12-06, Santa Cruz, CA\n",
    "                    - added new mie_hi_delta.mat function, for using delta scaled legendre polynomials\n",
    "        Modified: Samuel LeBlanc, 2020-11-17, Santa Cruz, CA\n",
    "                    - added new mie calculations from 20201112\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import scipy.io as sio\n",
    "    \n",
    "    if cloudtype=='wc':\n",
    "        if source=='solar':\n",
    "            mie_long = sio.netcdf_file(fp_rtm+'wc.sol.long.mie.cdf','r')\n",
    "            if deltascale:\n",
    "                if new:\n",
    "                    mie = sio.loadmat(fp_rtm+'mie_run2020112_SL.mat')\n",
    "                    rho = np.array([1.0])\n",
    "                    pmom = {'wvl':mie['wavelen'].flatten(),\n",
    "                            'ref':mie['reff'],\n",
    "                            'ntheta':np.swapaxes(mie['ntheta'][:,:,0],0,1),\n",
    "                            'rho':np.swapaxes(mie['rho'],0,1),\n",
    "                            'nmom':np.swapaxes(mie['nmom'][:,:,0],0,1),\n",
    "                            'ssa':np.swapaxes(mie['ssa'],0,1),\n",
    "                            'ext':np.swapaxes(mie['ext'],0,1),\n",
    "                            'nim':mie['refim'].flatten(),\n",
    "                            'nre':mie['refre'].flatten(),\n",
    "                            'pmom':np.swapaxes(mie['pmom'],0,1),\n",
    "                            'phase':np.swapaxes(mie['phase'][:,:,0,:],0,1),\n",
    "                            'theta':np.swapaxes(mie['theta'][:,:,0,:],0,1)}\n",
    "                    pmom['file_name'] = [fp_rtm+'mie_run2020112_SL.mat']\n",
    "                else:\n",
    "                    mie = sio.loadmat(fp_rtm+'mie_hi_delta.mat')\n",
    "                    rho = np.array([1.0])\n",
    "                    pmom = {'wvl':np.append(mie['wvl'],mie_long.variables['wavelen'].data[1:]),\n",
    "                            'ref':mie['ref'],\n",
    "                            'ntheta':np.concatenate((mie['ntheta'],np.swapaxes(mie_long.variables['ntheta'].data[1:,:,0],0,1)),axis=1),\n",
    "                            'rho':mie['rho'],\n",
    "                            'nmom':np.concatenate((mie['nmom_delta'],np.swapaxes(mie_long.variables['nmom'].data[1:,:,0],0,1)),axis=1),\n",
    "                            'ssa':np.concatenate((mie['ssa'],np.swapaxes(mie_long.variables['ssa'].data[1:,:],0,1)),axis=1),\n",
    "                            'ext':np.concatenate((mie['ext'],np.swapaxes(mie_long.variables['ext'].data[1:,:],0,1)),axis=1),\n",
    "                            'nim':np.append(mie['nim'],mie_long.variables['refim'].data[1:]),\n",
    "                            'nre':np.append(mie['nre'],mie_long.variables['refre'].data[1:]),\n",
    "                            'pmom':np.concatenate((np.concatenate((mie['pmom_delta'],np.zeros((30,754,351))),axis=2),\n",
    "                                                   np.swapaxes(mie_long.variables['pmom'].data[1:,:,0,:652],0,1)),axis=1),\n",
    "                            'phase':np.concatenate((mie['phase'],np.swapaxes(mie_long.variables['phase'].data[1:,:,0,:398],0,1)),axis=1),\n",
    "                            'theta':np.concatenate((mie['theta'],np.swapaxes(mie_long.variables['theta'].data[1:,:,0,:398],0,1)),axis=1)}\n",
    "                    pmom['file_name'] = [fp_rtm+'mie_hi_delta.mat',fp_rtm+'wc.sol.long.mie.cdf']\n",
    "            else:\n",
    "                mie = sio.netcdf_file(fp_rtm+'wc_allpmom.sol.mie.cdf','r')\n",
    "                try:\n",
    "                    rho = np.swapaxes(mie.variables['rho'].data,0,1)\n",
    "                except ValueError:\n",
    "                    rho = mie.variables['rho'].data\n",
    "                mie_short = {'wvl':mie.variables['wavelen'].data,\n",
    "                             'ref':mie.variables['reff'].data,\n",
    "                             'ntheta':np.swapaxes(mie.variables['ntheta'].data[:,:,0],0,1),\n",
    "                             'rho':rho,\n",
    "                             'nmom':np.swapaxes(mie.variables['nmom'].data,0,1),\n",
    "                             'ssa':np.swapaxes(mie.variables['ssa'].data,0,1),\n",
    "                             'ext':np.swapaxes(mie.variables['ext'].data,0,1),\n",
    "                             'nim':mie.variables['refim'].data,\n",
    "                             'nre':mie.variables['refre'].data,\n",
    "                             'pmom':np.swapaxes(mie.variables['pmom'].data[:,:,0,:],0,1),\n",
    "                             'phase':np.swapaxes(mie.variables['phase'].data[:,:,0,:],0,1),\n",
    "                             'theta': np.swapaxes(mie.variables['theta'].data[:,:,0,:],0,1)}\n",
    "                pmom = {'wvl':np.append(mie_short['wvl'],mie_long.variables['wavelen'].data[7:]),\n",
    "                        'ref':mie_short['ref'],\n",
    "                        'ntheta':np.concatenate((mie_short['ntheta'],np.swapaxes(mie_long.variables['ntheta'].data[7:,:-5,0],0,1)),axis=1),\n",
    "                        'rho':mie_short['rho'],\n",
    "                        'nmom':np.concatenate((mie_short['nmom'],np.swapaxes(mie_long.variables['nmom'].data[7:,:-5,0],0,1)),axis=1),\n",
    "                        'ssa':np.concatenate((mie_short['ssa'],np.swapaxes(mie_long.variables['ssa'].data[7:,:-5],0,1)),axis=1),\n",
    "                        'ext':np.concatenate((mie_short['ext'],np.swapaxes(mie_long.variables['ext'].data[7:,:-5],0,1)),axis=1),\n",
    "                        'nim':np.append(mie_short['nim'],mie_long.variables['refim'].data[7:]),\n",
    "                        'nre':np.append(mie_short['nre'],mie_long.variables['refre'].data[7:]),\n",
    "                        'pmom':np.concatenate((mie_short['pmom'],np.concatenate((np.swapaxes(mie_long.variables['pmom'].data[7:,:-5,0,:],0,1),\n",
    "                                                                                 np.zeros((25,72,2500))),axis=2)),axis=1),\n",
    "                        'phase':np.concatenate((mie_short['phase'],np.swapaxes(mie_long.variables['phase'].data[7:,:-5,0,:],0,1)),axis=1),\n",
    "                        'theta':np.concatenate((mie_short['theta'],np.swapaxes(mie_long.variables['theta'].data[7:,:-5,0,:],0,1)),axis=1)}\n",
    "                pmom['file_name'] = [fp_rtm+'wc_allpmom.sol.mie.cdf',fp_rtm+'wc.sol.long.mie.cdf']\n",
    "        elif source=='solar_sub':\n",
    "            if deltascale:\n",
    "                mie = sio.loadmat(fp_rtm+'mie_hi_delta.mat')\n",
    "                mie['pmom'] = mie['pmom_delta']\n",
    "                mie['nmom'] = mie['nmom_delta']\n",
    "            else:\n",
    "                mie = sio.idl.readsav(fp_rtm+'mie_hi.out')\n",
    "            mie_long = sio.netcdf_file(fp_rtm+'wc.sol.long.mie.cdf','r')\n",
    "            pmom = mie\n",
    "            pmom['wvl'] = np.append(mie['wvl'],mie_long.variables['wavelen'].data)\n",
    "            pmom['ntheta'] = np.concatenate((mie['ntheta'],np.swapaxes(mie_long.variables['ntheta'].data[:,:,0],0,1)),axis=1)\n",
    "            pmom['rho'] = np.concatenate((mie['rho'],np.swapaxes(mie_long.variables['rho'].data,0,1)),axis=1)\n",
    "            pmom['nmom'] = np.concatenate((mie['nmom'],np.swapaxes(mie_long.variables['nmom'].data[:,:,0],0,1)),axis=1)\n",
    "            pmom['ssa'] = np.concatenate((mie['ssa'],np.swapaxes(mie_long.variables['ssa'].data,0,1)),axis=1)\n",
    "            pmom['ext'] = np.concatenate((mie['ext'],np.swapaxes(mie_long.variables['ext'].data,0,1)),axis=1)\n",
    "            pmom['nim'] = np.append(mie['nim'],mie_long.variables['refim'].data)\n",
    "            pmom['nre'] = np.append(mie['nre'],mie_long.variables['refre'].data)\n",
    "            pmom['pmom'] = np.concatenate((mie['pmom'],np.concatenate((np.swapaxes(mie_long.variables['pmom'].data[:,:,0,:],0,1),\n",
    "                                                                       np.zeros((30,79,750))),axis=2)),axis=1)\n",
    "            pmom['phase'] = np.concatenate((np.concatenate((mie['phase'],np.zeros((30,754,602))),axis=2),\n",
    "                                            np.swapaxes(mie_long.variables['phase'].data[:,:,0,:],0,1)),axis=1)\n",
    "            pmom['theta'] = np.concatenate((np.concatenate((mie['theta'],np.zeros((30,754,602))),axis=2),\n",
    "                                            np.swapaxes(mie_long.variables['theta'].data[:,:,0,:],0,1)),axis=1).shape \n",
    "            pmom['file_name'] = [fp_rtm+'mie_hi.out',fp_rtm+'wc.sol.long.mie.cdf']\n",
    "        elif source=='thermal':\n",
    "            mie_trm = sio.netcdf_file(fp_rtm+'wc_trm_longmie.cdf','r')\n",
    "            pmom = {'wvl':mie_trm.variables['wavelen'].data*1000.0, \n",
    "                    'ref':mie_trm.variables['reff'].data,\n",
    "                    'ntheta':np.swapaxes(mie_trm.variables['ntheta'].data[:,:,0],0,1),\n",
    "                    'rho':np.swapaxes(mie_trm.variables['rho'].data,0,1),\n",
    "                    'nmom':np.swapaxes(mie_trm.variables['nmom'].data[:,:,0],0,1),\n",
    "                    'ssa':np.swapaxes(mie_trm.variables['ssa'].data,0,1),\n",
    "                    'ext':np.swapaxes(mie_trm.variables['ext'].data,0,1),\n",
    "                    'nim':mie_trm.variables['refim'].data,\n",
    "                    'nre':mie_trm.variables['refre'].data,\n",
    "                    'pmom':np.swapaxes(mie_trm.variables['pmom'].data[:,:,0,:],0,1),\n",
    "                    'phase':np.swapaxes(mie_trm.variables['phase'].data[:,:,0,:],0,1),\n",
    "                    'theta':np.swapaxes(mie_trm.variables['theta'].data[:,:,0,:],0,1)}\n",
    "            pmom['file_name'] = [fp_rtm+'wc_trm_longmie.cdf']\n",
    "        else:\n",
    "            print 'Not a correct option for source: select either solar, solar_sub, or thermal'\n",
    "            return None\n",
    "    elif cloudtype =='ic':\n",
    "        ic = sio.loadmat(fp_rtm+'ic.pmom.ghm.baum.mat')\n",
    "        pmom = {'wvl':ic['pmom_wvl'][0,:],\n",
    "                'ref':ic['ref'][0,:],\n",
    "                'rho':ic['rho'][0,:],\n",
    "                'ssa':np.swapaxes(ic['ssa'][ic['pmom_iwvl'][0,:],:],0,1),\n",
    "                'ext':np.swapaxes(ic['ext'][ic['pmom_iwvl'][0,:],:],0,1),\n",
    "                'pmom':ic['pmom']}#,\n",
    "                #'phase':ic['phase'],\n",
    "                #'theta':ic['theta']}\n",
    "        pmom['nmom'] = np.zeros_like(pmom['pmom'])-1\n",
    "        pmom['file_name'] = [fp_rtm+'ic.pmom.ghm.baum.mat']\n",
    "    else:\n",
    "        print 'Not a correct cloudtype value: either wc or ic'\n",
    "        return None\n",
    "    return pmom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def build_aac_input(fp,fp_alb,fp_out,fp_pmom=None,fp_uvspec='/u/sleblan2/libradtran/libRadtran-2.0-beta/bin/uvspec',fp_output=None,\n",
    "                    wvl_file_sol=None,wvl_file_thm=None,aero_clear=False,version='v1',stdfac_dict={},max_nmom=None,list_only=False,\n",
    "                    start_lat=None,start_lon=None,mmmlist=['DJF','MAM','JJA','SON'],deltascale=True,zaero=[3.0,4.0],zcld=[2.0,3.0]):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    \n",
    "        Program to build the inputs of libradtran for Meloë's AAC study\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "        fp: path of directory to matlab input files\n",
    "        fp_alb: full path to where (without the filename) of the MODIS albedo\n",
    "        fp_out: full path to where the input files will be saved\n",
    "        fp_pmom: full path (without the filename) to pmom files\n",
    "        fp_uvspec: full path to the uvspec program, defaults to : /u/sleblan2/libradtran/libRadtran-2.0-beta/bin/uvspec\n",
    "        fp_output: path to output of uvspec, if none, the fp_out is used, with the last assumed directory \n",
    "                    /input/ to be changed to /output/\n",
    "        wvl_file_sol: full path to solar wavelength file (wavelengths in nm in second column)\n",
    "        wvl_file_thm: full path of thermal wavelength file (wavelengths in nm in second column)\n",
    "        aero_clear: if set to True, then aerosol extinction is set to zero in all cases. (defaults to False) \n",
    "        version: (defaults to v1) version number of the files for tracking\n",
    "        stdfac_dict: Dict that contains the multiplicative factors to the standard deviation stored in the keys:\n",
    "                     'ext','ssa','asym', 'COD','ref'\n",
    "        max_nmom: Maximum number of phase function moments to write out. (defaults to none)\n",
    "        list_only: (default False) When True, only write out the list file (for debugging)\n",
    "        start_lat: (default None) if set to an integer, uses the index to start the latitutde loops creating the files (for debugging)\n",
    "        start_lon: (default None) if set to an integer, uses the index to start the longitutde loops creating the files (for debugging)\n",
    "        mmmlist: (default ['DJF','MAM','JJA','SON']) the list of months to go through\n",
    "        deltascale: (default to True) use the new delta scaled cloud moments if set to True\n",
    "        \n",
    "    Dependencies:\n",
    "    \n",
    "        numpy\n",
    "        scipy\n",
    "        load_utils\n",
    "        Run_libradtran \n",
    "        os\n",
    "        \n",
    "    Required files:\n",
    "    \n",
    "        Input_to_DARF_mmm.mat : input files from Meloë\n",
    "        surface albedo files from MODIS (MCD43GF_geo_shortwave_doy_2007.hdf)\n",
    "        pmom files in netcdf (thermal and solar)\n",
    "        \n",
    "    Example:\n",
    "    \n",
    "        ...\n",
    "        \n",
    "    Modification History:\n",
    "    \n",
    "        Written: Samuel LeBlanc, 2015-07-01, Happy Canada Day!, Santa Cruz, CA\n",
    "        Modified: Samuel LeBlanc, 2015-07-07, NASA Ames\n",
    "                - Modified the calling paths to include fp_pmom\n",
    "                - Added comments\n",
    "                - Changed out of Prepare_input_aac to Run_libradtran\n",
    "        Modified: Samuel LeBlanc, 2015-07-08, Santa Cruz, CA\n",
    "                - added creator of list file (for running on cluster), creating list file in the path described by fp_out\n",
    "                - added fp_uvspec \n",
    "                - added fp_output for list file creation of uvspec output\n",
    "                - changed to use the base_file method\n",
    "                - changed to use wavelength_files\n",
    "        Modified: Samuel LeBlanc, 2015-07-09, NASA Ames, CA\n",
    "                - using one set of cloud files per lat lon combinations, not for every hour\n",
    "                - added aero_clear keyword to define clear value\n",
    "        Modified: Samuel LeBlanc, 2015-07-10, Santa Cruz, CA\n",
    "                - changed to have seperate path and list file for each mmm\n",
    "        MOdified: Samuel LeBlanc, 2017-03-06, Santa Cruz, CA\n",
    "                - added the version keyword for version tracking\n",
    "        Modofied: Samuel LeBlanc, 2019-02-14, NASA Ames, CA\n",
    "                - added zaero and zcld keywords in the function call to modify the aerosol and cloud heights.\n",
    "        \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import scipy.io as sio\n",
    "    import Run_libradtran as RL\n",
    "    import load_utils as lm\n",
    "    import os\n",
    "    if fp_pmom:\n",
    "        pmom_solar = RL.make_pmom_inputs(fp_rtm=fp_pmom,source='solar',deltascale=deltascale)\n",
    "        pmom_thermal = RL.make_pmom_inputs(fp_rtm=fp_pmom,source='thermal')\n",
    "    else:\n",
    "        pmom_solar = RL.make_pmom_inputs(source='solar',deltascale=deltascale)\n",
    "        pmom_thermal = RL.make_pmom_inputs(source='thermal')\n",
    "    if max_nmom:\n",
    "        pmom_solar['max_nmoms'] = max_nmom\n",
    "        pmom_thermal['max_nmoms'] = max_nmom\n",
    "    else:\n",
    "        pmom_solar['max_nmoms'],pmom_thermal['max_nmoms'] = False,False\n",
    "        \n",
    "    geo = {'zout':[0,3,100],'year':2007,'day':15,'minute':0,'second':0}\n",
    "    aero = {'z_arr':zaero}\n",
    "    cloud = {'ztop':zcld[1],'zbot':zcld[0],'phase':'wc','write_moments_file':True}\n",
    "    source = {'integrate_values':True,'dat_path':'/u/sleblan2/libradtran/libRadtran-2.0-beta/data/','run_fuliou':True}\n",
    "    albedo = {'create_albedo_file':False}\n",
    "    if not fp_output:\n",
    "        change_fp_output = True\n",
    "    else:\n",
    "        change_fp_output = False\n",
    "    \n",
    "    stdfac_dict = RL.merge_dicts({'ext':0.0,'ssa':0.0,'asym':0.0,\n",
    "                                  'COD':0.0,'ref':0.0},stdfac_dict)\n",
    "    std_label = ''\n",
    "    if aero_clear:\n",
    "        std_label = '_clear'\n",
    "    for k in stdfac_dict.keys():\n",
    "        if stdfac_dict[k] != 0.0:\n",
    "            if stdfac_dict[k]>0.0: \n",
    "                n='p' \n",
    "            else: n='m'\n",
    "            std_label = std_label+'_'+k+nstdfac_dict\n",
    "    \n",
    "    for mmm in mmmlist: #['DJF','MAM','JJA','SON']:\n",
    "        fpm = fp+'Input_to_DARF_{mmm}_{vv}.mat'.format(mmm=mmm,vv=version)\n",
    "        print 'in %s months, getting mat file: %s' % (mmm,fpm)\n",
    "        input_mmm = sio.loadmat(fpm,mat_dtype=True)['data_input_darf']\n",
    "        if mmm=='DJF':\n",
    "            geo['month'] = 1\n",
    "            doy = 17\n",
    "        elif mmm=='MAM':\n",
    "            geo['month'] = 4\n",
    "            doy = 137\n",
    "        elif mmm=='JJA':\n",
    "            geo['month'] = 7\n",
    "            doy = 225\n",
    "        elif mmm=='SON':\n",
    "            geo['month'] = 10\n",
    "            doy = 321\n",
    "            \n",
    "        try:\n",
    "            file_list = file(fp_out+'AAC_list_file_{m}_{v}{lbl}.sh'.format(m=mmm,v=version,lbl=std_label),'w')\n",
    "        except Exception,e:\n",
    "            print 'Problem with accessing file, return Exception: ',e\n",
    "            return\n",
    "        print 'Starting list file'\n",
    "        fp_out2 = fp_out+mmm+std_label+'/'\n",
    "        if not os.path.exists(fp_out2):\n",
    "            os.mkdir(fp_out2)\n",
    "        if change_fp_output:\n",
    "            fp_output = fp_out2.replace('input','output')\n",
    "            if not os.path.exists(fp_output):\n",
    "                os.mkdir(fp_output)\n",
    "        fp_base_file = fp_out2+'base.inp'\n",
    "        make_base = True\n",
    "\n",
    "        fpa = fp_alb+'MCD43GF_geo_shortwave_%03i_2007.hdf' % doy\n",
    "        print 'Getting albedo files: '+fpa\n",
    "        try:\n",
    "            alb_geo,alb_geo_dict = lm.load_hdf_sd(fpa)\n",
    "            print 'done loading albedo files'\n",
    "            alb_geo_sub = np.nanmean(np.nanmean(alb_geo['MCD43GF_CMG'].reshape([48,21600/48,75,43200/75]),3),1)\n",
    "        except:\n",
    "            alb_geo = lm.load_hdf_raster1(fpa)\n",
    "            print 'done loading albedo files using raster 1'\n",
    "            alb_geo_sub = np.nanmean(np.nanmean(alb_geo.reshape([48,21600/48,75,43200/75]),3),1)        \n",
    "        alb_geo_lat = np.linspace(90,-90,num=48)\n",
    "        alb_geo_lon = np.linspace(-180,180,num=75)\n",
    "        \n",
    "        print 'Running through the files'\n",
    "        for ilat,lat in enumerate(input_mmm['MODIS_lat'][0,0]):\n",
    "            if start_lat:\n",
    "                if not ilat>=start_lat:\n",
    "                    continue\n",
    "            for ilon,lon in enumerate(input_mmm['MODIS_lon'][0,0]):\n",
    "                if start_lon:\n",
    "                    if not ilon>=start_lon:\n",
    "                        continue\n",
    "                geo['lat'],geo['lon'] = lat,lon\n",
    "                # set the aerosol values\n",
    "                aero['wvl_arr'] = input_mmm['MOC_wavelengths'][0,0][0,:]*1000.0\n",
    "                aero['ext'] = np.abs(input_mmm['MOC_ext_mean'][0,0][ilat,ilon,:]) # is in AOD units, not ext, but since it is for 1 km, does not matter\n",
    "                print 'ext:',stdfac_dict['ext'],aero['ext'][9],stdfac_dict['ext']*np.abs(input_mmm['MOC_ext_std'][0,0][ilat,ilon,9])/1000.0\n",
    "                aero['ext'] = aero['ext']+stdfac_dict['ext']*np.abs(input_mmm['MOC_ext_std'][0,0][ilat,ilon,:])/1000.0 #convert  per Mm to per km\n",
    "                aero['ext'][aero['ext']<0.0] = 0.0\n",
    "                if aero_clear:\n",
    "                    aero['ext'] = aero['ext']*0.0\n",
    "                if np.isnan(aero['ext']).all():\n",
    "                    #print 'skipping lat:%i, lon:%i' % (ilat,ilon)\n",
    "                    continue\n",
    "                aero['ssa'] = input_mmm['MOC_ssa_mean'][0,0][ilat,ilon,:]\n",
    "                aero['ssa'] = aero['ssa']+stdfac_dict['ssa']*input_mmm['MOC_ssa_std'][0,0][ilat,ilon,:]\n",
    "                aero['asy'] = input_mmm['MOC_asym_mean'][0,0][ilat,ilon,:]\n",
    "                aero['asy'] = aero['asy']+stdfac_dict['asym']*input_mmm['MOC_asym_std'][0,0][ilat,ilon,:]\n",
    "                \n",
    "                #sanitize inputs after adding subtracting standard deviations\n",
    "                try: aero['ssa'][aero['ssa']<0.0] = 0.0\n",
    "                except: pass\n",
    "                try: aero['ssa'][aero['ssa']>1.0] = 1.0\n",
    "                except: pass\n",
    "                try: aero['asy'][aero['asy']<0.0] = 0.0\n",
    "                except: pass\n",
    "                try: aero['asy'][aero['asy']>1.0] = 1.0\n",
    "                except: pass\n",
    "                \n",
    "                if aero['wvl_arr'].max()<100000.0:\n",
    "                    aero['wvl_arr'] = np.append(aero['wvl_arr'],100000.0)\n",
    "                    aero['ext'] = np.append(aero['ext'],aero['ext'][-1])\n",
    "                    aero['ssa'] = np.append(aero['ssa'],aero['ssa'][-1])\n",
    "                    aero['asy'] = np.append(aero['asy'],aero['asy'][-1])\n",
    "                # set the cloud values\n",
    "                cloud['tau'] = input_mmm['MODIS_COD_mean'][0,0][ilat,ilon]\n",
    "                cloud['tau'] = cloud['tau']+stdfac_dict['COD']*input_mmm['MODIS_COD_std'][0,0][ilat,ilon]\n",
    "                cloud['ref'] = input_mmm['MODIS_effrad_mean'][0,0][ilat,ilon]\n",
    "                cloud['ref'] = cloud['ref']+stdfac_dict['ref']*input_mmm['MODIS_Effrad_std'][0,0][ilat,ilon]\n",
    "                try: cloud['tau'][cloud['tau']<0.0] = 0.0\n",
    "                except: pass\n",
    "                try: cloud['ref'][cloud['ref']<2.0] = 2.0\n",
    "                except: pass\n",
    "                \n",
    "                # set the albedo\n",
    "                alb = alb_geo_sub[np.argmin(abs(alb_geo_lat-lat)),np.argmin(abs(alb_geo_lon-lon))]\n",
    "                if np.isnan(alb): \n",
    "                    albedo['sea_surface_albedo'] = True\n",
    "                else:\n",
    "                    albedo['albedo'] = alb\n",
    "                    \n",
    "                cloud['link_to_mom_file'] = False\n",
    "                aero['link_to_mom_file'] = False\n",
    "                cloud_file_name_sol = fp_out2+'AAC_input_lat%02i_lon%02i_%s_sol.inp_cloud' % (ilat,ilon,mmm)\n",
    "                cloud_file_name_thm = fp_out2+'AAC_input_lat%02i_lon%02i_%s_thm.inp_cloud' % (ilat,ilon,mmm)\n",
    "                aero['file_name'] = fp_out2+'AAC_input_lat%02i_lon%02i_%s_thm.inp_aero' % (ilat,ilon,mmm)\n",
    "\n",
    "                for HH in xrange(24):\n",
    "                    geo['hour'] = HH\n",
    "                    #build the solar input file\n",
    "                    source['source'] = 'solar'\n",
    "                    if wvl_file_sol:\n",
    "                        source['wvl_filename'] = wvl_file_sol\n",
    "                    else:\n",
    "                        source['wvl_range'] = [250,5600]\n",
    "                        source['wvl_filename'] = None\n",
    "                    cloud['moms_dict'] = pmom_solar\n",
    "                    cloud['file_name'] = cloud_file_name_sol\n",
    "                    file_out_sol = fp_out2+'AAC_input_lat%02i_lon%02i_%s_HH%02i_sol.inp' % (ilat,ilon,mmm,HH)\n",
    "                    if not list_only:\n",
    "                        RL.write_input_aac(file_out_sol,geo=geo,aero=aero,cloud=cloud,source=source,albedo=albedo,verbose=False,\n",
    "                                       make_base=make_base,fp_base_file=fp_base_file,set_quiet=True,solver='rodents')\n",
    "                    if make_base:\n",
    "                        make_base = False\n",
    "                    #build the thermal input file\n",
    "                    source['source'] = 'thermal'\n",
    "                    if wvl_file_thm:\n",
    "                        source['wvl_filename'] = wvl_file_thm\n",
    "                    else:\n",
    "                        source['wvl_range'] = [4000,50000-1]\n",
    "                        source['wvl_filename'] = None\n",
    "                    cloud['moms_dict'] = pmom_thermal\n",
    "                    cloud['file_name'] = cloud_file_name_thm\n",
    "                    file_out_thm = fp_out2+'AAC_input_lat%02i_lon%02i_%s_HH%02i_thm.inp' % (ilat,ilon,mmm,HH)\n",
    "                    \n",
    "                    if not list_only:\n",
    "                        RL.write_input_aac(file_out_thm,geo=geo,aero=aero,cloud=cloud,source=source,albedo=albedo,verbose=False,\n",
    "                                       make_base=False,fp_base_file=fp_base_file,set_quiet=True,solver='rodents')\n",
    "                    file_list.write(fp_uvspec+' < '+file_out_sol+' > '+fp_output\n",
    "                                    +'AAC_input_lat%02i_lon%02i_%s_HH%02i_sol.out\\n' % (ilat,ilon,mmm,HH))\n",
    "                    file_list.write(fp_uvspec+' < '+file_out_thm+' > '+fp_output\n",
    "                                    +'AAC_input_lat%02i_lon%02i_%s_HH%02i_thm.out\\n' % (ilat,ilon,mmm,HH))\n",
    "                    if not cloud['link_to_mom_file']:\n",
    "                        cloud['link_to_mom_file'] = True\n",
    "                    if not aero['link_to_mom_file']:\n",
    "                        aero['link_to_mom_file'] = True\n",
    "                    print mmm,ilat,ilon,HH\n",
    "        del alb_geo\n",
    "        del input_mmm\n",
    "        file_list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def read_libradtran(fp,zout=[0,3,100],num_rad=0):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    \n",
    "        Program to read the output of libradtran irradiance and radiance files\n",
    "        output irradiance for any number of wavelengths, and number of zouts\n",
    "        in addition to any number of radiance zenith directions, and only one azimuth direction\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "        fp: full path of file to read\n",
    "        zout: array of zout values\n",
    "        num_rad: to load radiance set to number of zenith angle directions (defaults to none)\n",
    "        \n",
    "    Outputs:\n",
    "    \n",
    "        out: dictionary with\n",
    "            wvl: wavelength array \n",
    "            zout: zout values\n",
    "            direct_down: irradiance down from direct beam\n",
    "            diffuse_down: irradiance down from diffuse soruces\n",
    "            diffuse_up: irradiance upwwelling\n",
    "            int_dir_dn: average intensity direct down\n",
    "            int_dif_dn: average intensity diffuse down\n",
    "            int_dif_up: average intensity diffuse up\n",
    "            umu: (if radiance set to more than one) returns the cosine of the zenith angle direction of the radiance values\n",
    "            phi: (if rad set) returns a singular azimuth angle of the radiance value\n",
    "            rad: radiance array at zouts, at a single phi, and at the wavelengths (uu in libradtran notation)\n",
    "            rad_avg : azimuthally averaged radiance values, not intensity corrected (u0u in libradtran notation)\n",
    "        \n",
    "    Dependencies:\n",
    "    \n",
    "        os\n",
    "        numpy\n",
    "        \n",
    "    Required files:\n",
    "    \n",
    "        file output of libradtran\n",
    "        \n",
    "    Example:\n",
    "    \n",
    "        ...\n",
    "        \n",
    "    Modification History:\n",
    "    \n",
    "        Written: Samuel LeBlanc, 2015-07-13, Santa Cruz, CA\n",
    "        Modified: Samuel LeBlanc, 2015-10-14, NASA Ames, Santa Cruz, CA\n",
    "                  - added handling of radiance values\n",
    "        \n",
    "    \"\"\"\n",
    "    #import os\n",
    "    import numpy as np\n",
    "    #if not os.path.isfile(fp):\n",
    "    #    raise IOError('File not found')\n",
    "    #    return\n",
    "    zout_len = len(zout)\n",
    "    if num_rad:\n",
    "        arr_len = 11\n",
    "        if num_rad>1:\n",
    "            arr_len += 3*(num_rad-1)\n",
    "    else:\n",
    "        arr_len = 7\n",
    "    dat = np.fromfile(fp,sep=' ')\n",
    "    if len(dat)==0 :\n",
    "        raise IOError('File {} empty'.format(fp))\n",
    "    try:\n",
    "        dat = dat.reshape(len(dat)/arr_len/zout_len,zout_len,arr_len)\n",
    "    except ValueError:\n",
    "        arr_len = 5\n",
    "        dat = dat.reshape(len(dat)/arr_len/zout_len,zout_len,arr_len)\n",
    "    try:\n",
    "        output = {'wvl':dat[:,0,0].squeeze(),\n",
    "                  'zout':zout,\n",
    "                  'direct_down':dat[:,:,1].squeeze(),\n",
    "                  'diffuse_down':dat[:,:,2].squeeze(),\n",
    "                  'diffuse_up':dat[:,:,3].squeeze(),\n",
    "                  'int_dir_dn':dat[:,:,4].squeeze(),\n",
    "                  'int_dif_dn':dat[:,:,5].squeeze(),\n",
    "                  'int_dif_up':dat[:,:,6].squeeze()}\n",
    "    except:\n",
    "        output = {'wvl':dat[:,0,0].squeeze(),\n",
    "                  'zout':zout,\n",
    "                  'direct_down':dat[:,:,1].squeeze(),\n",
    "                  'diffuse_down':dat[:,:,2].squeeze(),\n",
    "                  'diffuse_up':dat[:,:,3].squeeze()}\n",
    "        try:\n",
    "             output['int_tot'] = dat[:,:,4].squeeze()\n",
    "        except:\n",
    "            output['int_tot'] = np.NaN\n",
    "    if num_rad:\n",
    "        output['rad'] = dat[:,:,10].squeeze()\n",
    "        output['rad_avg'] = dat[:,:,9].squeeze()\n",
    "        output['phi'] = dat[0,0,7]\n",
    "        output['umu'] = np.array([dat[0,0,8]])\n",
    "        if num_rad>1:\n",
    "            output['rad'] = output['rad'][...,np.newaxis]\n",
    "            output['rad_avg'] = output['rad_avg'][...,np.newaxis]\n",
    "        for i in range(num_rad-1):\n",
    "            output['umu'] = np.append(output['umu'],dat[0,0,11+i*3])\n",
    "            output['rad'][:,:,:,i+1] = dat[:,:,13+i*3]\n",
    "            output['rad_avg'][:,:,:,i+1] = dat[:,:,12+i*3]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def read_aac(fp_out,fp_mat,mmm=None,read_sol=True,read_thm=True):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    \n",
    "        Simple program to read all the output of the libradtran runs for AAC\n",
    "        Program to read the output of libradtran irradiance files\n",
    "        Very simple output of 3 zout, one wavelength\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "        fp_out: full path of the directory with the files to read\n",
    "        fp_mat: full path of mat file with lat and lon to use\n",
    "        mmm: string with the season defined (can be DJF,MAM,JJA, or SON)\n",
    "        read_sol: set to True (default) to read the sol files\n",
    "        read_thm: set to True (default) to read the thm files\n",
    "        \n",
    "    Outputs:\n",
    "    \n",
    "        out: dictionary with the saved output \n",
    "        \n",
    "    Dependencies:\n",
    "    \n",
    "        Run_libradtran (this file)\n",
    "        os\n",
    "        numpy\n",
    "        scipy\n",
    "        \n",
    "    Required files:\n",
    "    \n",
    "        files of libradtran output\n",
    "        meloë's .mat files\n",
    "        \n",
    "    Example:\n",
    "    \n",
    "        >>> import Run_libradtran as RL\n",
    "        >>> fp_out = '/nobackup/sleblan2/AAC_DARF/output/v2/DJF/'\n",
    "        >>> fp_mat = '/u/sleblan2/meloe_AAC/Input_to_DARF_DJF.mat'\n",
    "        >>> mmm = 'DJF'\n",
    "        >>> DJF = RL.read_aac(fp_out,fp_mat,mmm=mmm)\n",
    "        \n",
    "        DJF 0 0\n",
    "        File not found skip: lat00_lon00_DJF_HH00 \n",
    "        .\n",
    "        .\n",
    "        .\n",
    "        \n",
    "        >>> DJF.keys()\n",
    "        ['UTC', \n",
    "         'LW_irr_up_utc', \n",
    "         'lon', \n",
    "         'SW_irr_dn_avg', \n",
    "         'SW_irr_up_utc',\n",
    "         'LW_irr_dn_avg', \n",
    "         'zout', \n",
    "         'LW_irr_up_avg', \n",
    "         'lat', \n",
    "         'SW_irr_up_avg', \n",
    "         'SW_irr_dn_utc', \n",
    "         'LW_irr_dn_utc']\n",
    " \n",
    "    Modification History:\n",
    "    \n",
    "        Written: Samuel LeBlanc, 2015-07-13, Santa Cruz, CA\n",
    "        Modified: Samuel LeBlanc, 2015-07-15, Santa Cruz, CA\n",
    "                    - added read_sol and read_thm keywords\n",
    "                    - added example\n",
    "        \n",
    "    \"\"\"\n",
    "    import os\n",
    "    import scipy.io as sio\n",
    "    import Run_libradtran as RL\n",
    "    import numpy as np\n",
    "    \n",
    "    if not mmm:\n",
    "        raise NameError('no season string defined')\n",
    "        return\n",
    "    \n",
    "    input_mmm = sio.loadmat(fp_mat,mat_dtype=True)['data_input_darf']\n",
    "    output = {'lat':input_mmm['MODIS_lat'][0,0],\n",
    "              'lon':input_mmm['MODIS_lon'][0,0],\n",
    "              'UTC':range(24),\n",
    "              'zout':[0,3,100]}\n",
    "    nlat,nlon,nz = len(output['lat']),len(output['lon']),len(output['zout'])\n",
    "    output['SW_irr_dn_utc'] = np.zeros((nz,nlat,nlon,24))\n",
    "    output['SW_irr_up_utc'] = np.zeros((nz,nlat,nlon,24))\n",
    "    output['LW_irr_dn_utc'] = np.zeros((nz,nlat,nlon,24))\n",
    "    output['LW_irr_up_utc'] = np.zeros((nz,nlat,nlon,24))\n",
    "    output['SW_irr_dn_avg'] = np.zeros((nz,nlat,nlon))\n",
    "    output['SW_irr_up_avg'] = np.zeros((nz,nlat,nlon))\n",
    "    output['LW_irr_dn_avg'] = np.zeros((nz,nlat,nlon))\n",
    "    output['LW_irr_up_avg'] = np.zeros((nz,nlat,nlon))    \n",
    "    for ilat in xrange(nlat):\n",
    "        for ilon in xrange(nlon):        \n",
    "            for iutc in output['UTC']:\n",
    "                file_out_sol = fp_out+'AAC_input_lat%02i_lon%02i_%s_HH%02i_sol.out' % (ilat,ilon,mmm,iutc)\n",
    "                file_out_thm = fp_out+'AAC_input_lat%02i_lon%02i_%s_HH%02i_thm.out' % (ilat,ilon,mmm,iutc)\n",
    "                try:\n",
    "                    if read_sol:\n",
    "                        sol = RL.read_libradtran(file_out_sol,zout=output['zout'])\n",
    "                    if read_thm:\n",
    "                        thm = RL.read_libradtran(file_out_thm,zout=output['zout'])\n",
    "                except IOError:\n",
    "                    #print 'File not found skip: lat%02i_lon%02i_%s_HH%02i' %(ilat,ilon,mmm,iutc)\n",
    "                    if iutc==0:\n",
    "                        print file_out_sol\n",
    "                    continue\n",
    "                except ValueError:\n",
    "                    #print 'Problem with file: lat%02i_lon%02i_%s_HH%02i' %(ilat,ilon,mmm,iutc)\n",
    "                    output['SW_irr_dn_utc'][:,ilat,ilon,iutc] = np.nan\n",
    "                    output['SW_irr_up_utc'][:,ilat,ilon,iutc] = np.nan\n",
    "                    output['LW_irr_dn_utc'][:,ilat,ilon,iutc] = np.nan\n",
    "                    output['LW_irr_up_utc'][:,ilat,ilon,iutc] = np.nan\n",
    "                    continue\n",
    "                if read_sol:\n",
    "                    output['SW_irr_dn_utc'][:,ilat,ilon,iutc] = sol['direct_down']+sol['diffuse_down']\n",
    "                    output['SW_irr_up_utc'][:,ilat,ilon,iutc] = sol['diffuse_up']\n",
    "                if read_thm:\n",
    "                    output['LW_irr_dn_utc'][:,ilat,ilon,iutc] = thm['direct_down']+thm['diffuse_down']\n",
    "                    output['LW_irr_up_utc'][:,ilat,ilon,iutc] = thm['diffuse_up']\n",
    "            print mmm,ilat,ilon\n",
    "            output['SW_irr_dn_avg'][:,ilat,ilon] = np.mean(output['SW_irr_dn_utc'][:,ilat,ilon,:],axis=1)\n",
    "            output['SW_irr_up_avg'][:,ilat,ilon] = np.mean(output['SW_irr_up_utc'][:,ilat,ilon,:],axis=1)\n",
    "            output['LW_irr_dn_avg'][:,ilat,ilon] = np.mean(output['LW_irr_dn_utc'][:,ilat,ilon,:],axis=1)\n",
    "            output['LW_irr_up_avg'][:,ilat,ilon] = np.mean(output['LW_irr_up_utc'][:,ilat,ilon,:],axis=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_wvl(dat1,dat2):\n",
    "    \"\"\"\n",
    "    Program to combine the output of read_libradtran along the wavelength dimension\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    dat = dat1\n",
    "    try: \n",
    "        if not (dat1['phi']==dat2['phi']):\n",
    "            print '*** Possible problem, the two arrays do not match in phi'\n",
    "    except: \n",
    "        pass\n",
    "    if not (dat1['zout']==dat2['zout']):\n",
    "        print '*** Possible problem, the two arrays do not match in zout'\n",
    "    try:\n",
    "        if not (dat1['umu']==dat2['umu']):\n",
    "            print '*** Possible problem, the two arrays do not match in umu'\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        dat['rad_avg'] = np.vstack((dat1['rad_avg'],dat2['rad_avg']))\n",
    "    except:\n",
    "        pass\n",
    "    dat['direct_down'] = np.vstack((dat1['direct_down'],dat2['direct_down']))\n",
    "    dat['diffuse_up'] = np.vstack((dat1['diffuse_up'],dat2['diffuse_up']))\n",
    "    dat['diffuse_down'] = np.vstack((dat1['diffuse_down'],dat2['diffuse_down']))\n",
    "    dat['int_dif_up'] = np.vstack((dat1['int_dif_up'],dat2['int_dif_up']))\n",
    "    dat['int_dir_dn'] = np.vstack((dat1['int_dir_dn'],dat2['int_dir_dn']))\n",
    "    dat['int_dif_dn'] = np.vstack((dat1['int_dif_dn'],dat2['int_dif_dn']))\n",
    "    try:\n",
    "        dat['rad'] = np.vstack((dat1['rad'],dat2['rad']))\n",
    "    except:\n",
    "        pass\n",
    "    dat['wvl'] = np.hstack((dat1['wvl'],dat2['wvl']))\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_lut(fp_out,zout=None,tau=[None],ref=[None],sza=[None],\n",
    "             phase=['wc','ic'],fmt='lut_sza{sza:02d}_tau{tau:06.2f}_ref{ref:04.1f}_{phase}_w{iwvl:1d}.dat',\n",
    "             split_wvl=True,numrad=1):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    \n",
    "        Simple program to read all the output of the libradtran runs for LUT creation\n",
    "        Program to read the output of libradtran irradiance and radiance files\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "        fp_out: full path of the directory with the files to read\n",
    "        zout: array of altitude out values (km)\n",
    "        tau: array of tau values\n",
    "        ref: array of ref values\n",
    "        sza: array of solar zenith angles to read (if not set, will not run through the solar zenith angles)\n",
    "        phase: array of string values linked to phase\n",
    "        fmt: format line used to create the files (with new >2.7 format string type, including '{}')\n",
    "             should include full file name with extension, \n",
    "             and named format characters for 'tau', 'ref', 'sza','phase','iwvl' \n",
    "             If file name does not require any of these, program doe snot freeze by omission \n",
    "        split_wvl: (defaults to True) if set then files are split per wavelength \n",
    "                   loads two seperate file per combination of tau, ref, sza, and phase\n",
    "        numrad: (number of radiance values to read, defaults to 1)\n",
    "        \n",
    "    Outputs:\n",
    "    \n",
    "        out: dictionary with the saved output \n",
    "        \n",
    "    Dependencies:\n",
    "    \n",
    "        Run_libradtran (this file)\n",
    "        os\n",
    "        numpy\n",
    "        \n",
    "    Required files:\n",
    "    \n",
    "        files of libradtran output\n",
    "        \n",
    "    Example:\n",
    "    \n",
    "        ...\n",
    "        \n",
    "    Modification History:\n",
    "    \n",
    "        Written: Samuel LeBlanc, 2015-10-14, NASA Ames, Santa Cruz, CA\n",
    "        Modified: Samuel LeBlanc, 2017-02-17, Santa Cruz, CA\n",
    "                  Added error checking for testing last file and ice as well as first file\n",
    "        \n",
    "    \"\"\"\n",
    "    import Run_libradtran as RL\n",
    "    import os \n",
    "    import numpy as np\n",
    "    \n",
    "    #test of single load of file\n",
    "    try:\n",
    "        dat1 = RL.read_libradtran(os.path.join(fp_out,fmt.format(ref=ref[0],tau=tau[0],sza=sza[0],phase=phase[0],iwvl=0)),\n",
    "                                  zout=zout,num_rad=numrad)\n",
    "    except:\n",
    "        print 'trying backup first run on file:'+fp_out\n",
    "        dat1 = RL.read_libradtran(os.path.join(fp_out,fmt.format(ref=ref[-1],tau=tau[-1],sza=sza[-1],phase=phase[-1],iwvl=0)),\n",
    "                                  zout=zout,num_rad=numrad)\n",
    "    if split_wvl:\n",
    "        try:\n",
    "            dat2 = RL.read_libradtran(os.path.join(fp_out,fmt.format(ref=ref[0],tau=tau[0],sza=sza[0],phase=phase[0],iwvl=1)),\n",
    "                                      zout=zout,num_rad=numrad)\n",
    "        except:\n",
    "            dat2 = RL.read_libradtran(os.path.join(fp_out,fmt.format(ref=ref[-1],tau=tau[-1],sza=sza[-1],phase=phase[-1],iwvl=1)),\n",
    "                                      zout=zout,num_rad=numrad)\n",
    "        dat = RL.combine_wvl(dat1,dat2)\n",
    "    else:\n",
    "        dat = dat1\n",
    "    output = {'rad':np.zeros((len(phase),len(dat['wvl']),\n",
    "                              len(zout),len(ref),len(tau),len(sza))),\n",
    "              'wvl':dat['wvl'],\n",
    "              'zout':zout,\n",
    "              'irr_dn':np.zeros((len(phase),len(dat['wvl']),\n",
    "                                 len(zout),len(ref),len(tau),len(sza))),\n",
    "              'irr_up':np.zeros((len(phase),len(dat['wvl']),\n",
    "                                 len(zout),len(ref),len(tau),len(sza))),\n",
    "              'irr_dn_diff':np.zeros((len(phase),len(dat['wvl']),\n",
    "                                      len(zout),len(ref),len(tau),len(sza))),\n",
    "              'tau':tau,\n",
    "              'ref':ref,\n",
    "              'sza':sza,\n",
    "              'phase':phase}\n",
    "    for iz,s in enumerate(sza):\n",
    "        for it,t in enumerate(tau):\n",
    "            for ir,r in enumerate(ref):\n",
    "                for ip,p in enumerate(phase):\n",
    "                    try:\n",
    "                        dat1 = RL.read_libradtran(os.path.join(fp_out,fmt.format(ref=r,tau=t,sza=s,phase=p,iwvl=0)),\n",
    "                                                  zout=zout,num_rad=numrad)\n",
    "                        if split_wvl:\n",
    "                            dat2 = RL.read_libradtran(os.path.join(fp_out,fmt.format(ref=r,tau=t,sza=s,phase=p,iwvl=1)),\n",
    "                                                      zout=zout,num_rad=numrad)            \n",
    "                            dat1 = RL.combine_wvl(dat1,dat2)\n",
    "                    except IOError:\n",
    "                        continue\n",
    "                    try:\n",
    "                        output['rad'][ip,:,:,ir,it,iz] = dat1['rad']\n",
    "                    except:\n",
    "                        pass\n",
    "                    output['irr_up'][ip,:,:,ir,it,iz] = dat1['diffuse_up']\n",
    "                    output['irr_dn'][ip,:,:,ir,it,iz] = dat1['direct_down']+dat1['diffuse_down']\n",
    "                    output['irr_dn_diff'][ip,:,:,ir,it,iz] = dat1['diffuse_down']\n",
    "                    print s,t,r\n",
    "    return output               \n",
    "#'lut_sza%02i_tau%06.2f_ref%04.1f'\n",
    "#'lut_sza%02i_ref%02.1f_tau%03.1f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_version_details(filename,vv,geo={},aero={},cloud={},source={},albedo={},\n",
    "                          tau=[None],ref=[None],sza=[None],cloud_pmom_file=None,\n",
    "                          fmt='lut_sza{sza:02.0f}_tau{tau:06.2f}_ref{ref:04.1f}_{phase}_w{iwvl:1d}.dat',use_json=True):\n",
    "    'Program to write an ascii file to print out the version and set up info'\n",
    "    if use_json:\n",
    "        from load_utils import save_to_json\n",
    "        lut = {'LUT_input_version':vv,'sza':sza,'tau':tau,'ref':ref,'format':fmt}\n",
    "        d = {'lut_details':lut,'geo':geo,'aero':aero,'source':source,'albedo':albedo}\n",
    "        if cloud_pmom_file:\n",
    "            from copy import deepcopy\n",
    "            d['cloud'] = deepcopy(cloud)\n",
    "            d['cloud']['pmom'] = None\n",
    "            try:\n",
    "                d['cloud']['moms_dict'] = None\n",
    "            except:\n",
    "                pass\n",
    "            d['cloud']['pmom_file'] = cloud_pmom_file\n",
    "        else:\n",
    "            d['cloud'] = cloud\n",
    "        save_to_json(filename,d)\n",
    "    else:\n",
    "        from Run_libradtran import writeDict\n",
    "        f = open(filename,'w')\n",
    "        f.write('UVSpec input file version: {} \\n'.format(vv))\n",
    "        f.write('sza = {} \\n'.format(sza))\n",
    "        f.write('tau = {} \\n'.format(tau))\n",
    "        f.write('ref = {} \\n'.format(ref))\n",
    "        f.close()\n",
    "        writeDict(geo,'geo',filename)\n",
    "        writeDict(aero,'aero',filename)\n",
    "        writeDict(cloud,'cloud',filename)\n",
    "        writeDict(source,'source',filename)\n",
    "        writeDict(albedo,'albedo',filename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeDict(dict_in, dict_name, filename):\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(\"{}\\n\".format(dict_name))\n",
    "        for i,v in dict_in.items():            \n",
    "            f.write(\"  {}: {}\\n\".format(i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def read_all_aac():\n",
    "    \"\"\"\n",
    "    Simple program to run the read_aac for the files and paths saved\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def run_from_ipython():\n",
    "    try:\n",
    "        __IPYTHON__\n",
    "        return True\n",
    "    except NameError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_24h_aac(d):\n",
    "    'function to read out the 24hour files (sol and thm) from a list of files'\n",
    "    import numpy as np\n",
    "    import Run_libradtran as RL\n",
    "    d.sort()\n",
    "    \n",
    "    zout=[0,3,100]\n",
    "    nz = len(zout)\n",
    "    output = {}\n",
    "    #output = {'zout':zout,'ext':d['aero']['ext'],'asy':d['aero']['asy'],'ssa':d['aero']['ssa']}\n",
    "    output['SW_irr_dn_utc'] = np.zeros((nz,24))\n",
    "    output['SW_irr_up_utc'] = np.zeros((nz,24))\n",
    "    output['LW_irr_dn_utc'] = np.zeros((nz,24))\n",
    "    output['LW_irr_up_utc'] = np.zeros((nz,24))  \n",
    "    output['HH'] = np.zeros((24,1))\n",
    "    output['file_sol'] = []\n",
    "    output['file_thm'] = []\n",
    "    \n",
    "    for HH in xrange(24):\n",
    "        output['HH'][HH] = HH\n",
    "        h = 'HH{:02.0f}'.format(HH)\n",
    "        for fin in d:\n",
    "            if h in fin:\n",
    "                if 'sol' in fin:\n",
    "                    file_out_sol = fin\n",
    "                if 'thm' in fin:\n",
    "                    file_out_thm = fin\n",
    "        \n",
    "        output['file_sol'].append(file_out_sol)           \n",
    "        output['file_thm'].append(file_out_thm)\n",
    "                    \n",
    "        try:\n",
    "            sol = RL.read_libradtran(file_out_sol,zout=zout)\n",
    "        except IOError:\n",
    "            print 'File {} not found skip'.format(file_out_sol) \n",
    "            if HH==0:\n",
    "                print file_out_sol\n",
    "            continue\n",
    "        except ValueError:\n",
    "            print 'Problem with file: {}'.format(file_out_sol)\n",
    "            output['SW_irr_dn_utc'][:,HH] = np.nan\n",
    "            output['SW_irr_up_utc'][:,HH] = np.nan\n",
    "                    \n",
    "        try:\n",
    "            thm = RL.read_libradtran(file_out_thm,zout=zout)\n",
    "        except IOError:\n",
    "            print 'File {} not found skip'.format(file_out_thm) \n",
    "            if HH==0:\n",
    "                print file_out_thm\n",
    "            continue\n",
    "        except ValueError:\n",
    "            print 'Problem with file: {}'.format(file_out_thm)\n",
    "            output['LW_irr_dn_utc'][:,HH] = np.nan\n",
    "            output['LW_irr_up_utc'][:,HH] = np.nan\n",
    "            \n",
    "            \n",
    "        output['SW_irr_dn_utc'][:,HH] = sol['direct_down']+sol['diffuse_down']\n",
    "        output['SW_irr_up_utc'][:,HH] = sol['diffuse_up']\n",
    "        output['LW_irr_dn_utc'][:,HH] = thm['direct_down']+thm['diffuse_down']\n",
    "        output['LW_irr_up_utc'][:,HH] = thm['diffuse_up']\n",
    "\n",
    "    output['SW_irr_dn_avg'] = np.mean(output['SW_irr_dn_utc'],axis=1)\n",
    "    output['SW_irr_up_avg'] = np.mean(output['SW_irr_up_utc'],axis=1)\n",
    "    output['LW_irr_dn_avg'] = np.mean(output['LW_irr_dn_utc'],axis=1)\n",
    "    output['LW_irr_up_avg'] = np.mean(output['LW_irr_up_utc'],axis=1)\n",
    "    return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    import numpy as np\n",
    "    ext = np.array([[0.5,0.4,0.3],[0,0,0]])\n",
    "    ssa = ext*1.9\n",
    "    asy = ext*1.7\n",
    "    ext.shape\n",
    "\n",
    "    z_arr = np.array([3,4])\n",
    "    wvl_arr = np.array([350.,500.,650.])\n",
    "\n",
    "    write_aerosol_file_explicit('C:\\Users\\sleblan2\\libradtran/aero.inp',z_arr,ext,ssa,asy,wvl_arr,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..Cloud water content is: 0.066667\n",
      "..printing to file: C:\\Users\\sleblan2\\libradtran\\cloud.inp\n",
      "..File finished, closed\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    write_cloud_file('C:\\Users\\sleblan2\\libradtran\\cloud.inp',10,10,2,3,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..printing to albedo wavelength defined file: C:\\Users\\sleblan2\\libradtran/alb.inp\n",
      "..File finished, closed\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    write_albedo_file('C:\\Users\\sleblan2\\libradtran/alb.inp',[500.0,600.0],[0.5,0.6],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening input file C:\\Users\\sleblan2\\libradtran/test_input.inp\n",
      "setting the dicts to defaults\n",
      "..write out general default values\n",
      "..write out source dict values\n",
      "..write out the albedo values\n",
      "..write out the geo values\n",
      "..write out the cloud properties\n",
      "..Liquid water cloud\n",
      "..Cloud water content is: 0.066667\n",
      "..printing to file: C:\\Users\\sleblan2\\libradtran/test_input.inp_cloud\n",
      "..File finished, closed\n",
      "Finished printing: Closing file\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    write_input_aac('C:\\Users\\sleblan2\\libradtran/test_input.inp',geo={'zout':[0,3,100],'wvl_range':[202,5600]},aero={},cloud={'tau':10,'ref':10,'phase':'wc','ztop':3,'zbot':2},source={},\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "run_control": {
     "breakpoint": true,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Run_libradtran' from 'Run_libradtran.py'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    import Run_libradtran\n",
    "    reload(Run_libradtran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    mie = make_pmom_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    geo = {'zout':[0,3,100],\n",
    "           'lat':-14.0,\n",
    "           'lon':-85.0,\n",
    "           'year':2007,'month':2,'day':10,'hour':10,'minute':0,'second':0}\n",
    "    aero = {'ext':[  4.85364736e-02,   4.66139195e-02,   4.47312609e-02,\n",
    "         4.30849589e-02,   4.19923201e-02,   4.03355801e-02,\n",
    "         3.74764159e-02,   3.45595009e-02,   3.19684762e-02,\n",
    "         2.94772306e-02,   2.74202103e-02,   2.57334360e-02,\n",
    "         2.39507641e-02,   2.08731768e-02,   1.67933569e-02,\n",
    "         1.29016393e-02,   9.04034361e-03,   6.65431703e-03,\n",
    "         4.35758656e-03,   3.47793084e-03,   2.59552084e-03,\n",
    "         1.92045503e-03,   1.48977972e-03,   1.14460091e-03,\n",
    "         7.92407241e-04,   5.10274383e-04,   3.17954425e-04,\n",
    "         1.69683997e-04,   8.10304392e-05,   3.35441191e-05],\n",
    "            'ssa':[ 0.94027621,  0.94451989,  0.94726128,  0.94923121,  0.95027106,\n",
    "        0.95172633,  0.95389696,  0.95572622,  0.9572892 ,  0.95868109,\n",
    "        0.9598034 ,  0.9607617 ,  0.96177931,  0.96326677,  0.95907986,\n",
    "        0.94878827,  0.92993408,  0.90942679,  0.87588452,  0.85667554,\n",
    "        0.83186815,  0.80753487,  0.78811889,  0.76859549,  0.741118  ,\n",
    "        0.70538566,  0.66048003,  0.58568778,  0.46758827,  0.27607095],\n",
    "            'asy':[ 0.7852096 ,  0.78103743,  0.77684837,  0.77285771,  0.77073574,\n",
    "        0.767068  ,  0.76026127,  0.75438874,  0.74906518,  0.74499582,\n",
    "        0.74245588,  0.7404872 ,  0.73816073,  0.73253394,  0.72113882,\n",
    "        0.70217822,  0.66814234,  0.63567558,  0.58822783,  0.56218055,\n",
    "        0.52791341,  0.49239392,  0.4624792 ,  0.43165396,  0.38933818,\n",
    "        0.34021788,  0.28974332,  0.22683931,  0.1585286 ,  0.08400939],\n",
    "            'z_arr':[3.0,4.0],\n",
    "            'wvl_arr':np.array([  0.20005,   0.2343 ,   0.2648 ,   0.2921 ,   0.3105 ,   0.34   ,\n",
    "          0.3975 ,   0.4675 ,   0.54625,   0.6423 ,   0.742  ,   0.8415 ,\n",
    "          0.9655 ,   1.226  ,   1.6574 ,   2.2024 ,   3.0044 ,   3.7544 ,\n",
    "          4.9    ,   5.57   ,   6.51   ,   7.57   ,   8.545  ,   9.645  ,\n",
    "         11.35   ,  13.7    ,  16.7    ,  21.75   ,  30.35   ,  50.     ])*1000.0}\n",
    "    cloud = {'tau':7.6,'ref':12.47,'ztop':3.0,'zbot':2.0,\n",
    "             'phase':'wc','write_moments_file':True,'moms_dict':mie}\n",
    "    source = {'wvl_range':[202,5600],\n",
    "              'source':'solar',\n",
    "              'integrate_values':True}\n",
    "    albedo = {'create_albedo_file':False,\n",
    "              'albedo':0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening input file C:\\Users\\sleblan2\\libradtran/test_input_aac.inp\n",
      "..setting the dicts to defaults\n",
      "..write out general default values\n",
      "..write out source dict values\n",
      "wvl_range starting too low, setting to 250 nm\n",
      "..write out the albedo values\n",
      "..write out the geo values\n",
      "..write out the aerosol parameters\n",
      "..printing to file: C:\\Users\\sleblan2\\libradtran/test_input_aac.inp_aero\n",
      "..printing 2 lines onto profile file\n",
      "..printing to explicit aerosol wavelength defined file: C:\\Users\\sleblan2\\libradtran/test_input_aac.inp_aero_z001\n",
      "..File finished write_aerosol_file_explicit_wvl, closed\n",
      "..File finished write_aerosol_file_explicit, closed\n",
      "..write out the cloud properties\n",
      "..Liquid water cloud\n",
      "..printing to file: C:\\Users\\sleblan2\\libradtran/test_input_aac.inp_cloud\n",
      "..printing to cloud moments properties wavelength defined file: C:\\Users\\sleblan2\\libradtran/test_input_aac.inp_cloud_zbot\n",
      "..File write_cloud_file_moments_wvl finished, closed\n",
      "..File finished write_cloud_file_moments, closed\n",
      "Finished printing main input file: Closing file\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    write_input_aac('C:\\Users\\sleblan2\\libradtran/test_input_aac.inp',geo=geo,aero=aero,cloud=cloud,source=source,albedo=albedo,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "run_control": {
     "breakpoint": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    fp = 'C:\\Users\\sleblan2/Research/libradtran/testing_new/AAC_input_lat06_lon19_DJF_HH17_sol.out'\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    d = pd.read_csv(fp,delim_whitespace=True,engine='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>550.000</th>\n",
       "      <th>2.894112e-09</th>\n",
       "      <th>2.512678e+02</th>\n",
       "      <th>1.635327e+01</th>\n",
       "      <th>3.582418e-10</th>\n",
       "      <th>3.458860e+01</th>\n",
       "      <th>4.776243e+00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550</td>\n",
       "      <td>697.1321</td>\n",
       "      <td>97.545040</td>\n",
       "      <td>498.0487</td>\n",
       "      <td>86.29308</td>\n",
       "      <td>23.674470</td>\n",
       "      <td>84.61614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550</td>\n",
       "      <td>909.6457</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>487.5659</td>\n",
       "      <td>112.59860</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>79.58508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   550.000  2.894112e-09  2.512678e+02  1.635327e+01  3.582418e-10  \\\n",
       "0      550      697.1321     97.545040      498.0487      86.29308   \n",
       "1      550      909.6457      0.000033      487.5659     112.59860   \n",
       "\n",
       "   3.458860e+01  4.776243e+00  \n",
       "0     23.674470      84.61614  \n",
       "1      0.000014      79.58508  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    dat = np.array(d)\n",
    "\n",
    "    dat\n",
    "\n",
    "    #if run_from_ipython():\n",
    "    #    %timeit rr = np.fromfile(fp,sep=' ').reshape((3,7))\n",
    "    #    %timeit dd = np.array(pd.read_csv(fp,delim_whitespace=True,engine='c'))\n",
    "    #    %timeit gg = np.loadtxt(fp)\n",
    "    #    %timeit gh = np.genfromtxt(fp)\n",
    "\n",
    "    Run_libradtran.read_libradtran(fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "560px",
    "left": "1545.94px",
    "right": "20px",
    "top": "110px",
    "width": "193px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
