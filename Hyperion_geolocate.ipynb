{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info\n",
    "Purpose:\n",
    "\n",
    "    Read in L1 hyperion files. Geolocate with .csv file, output new file\n",
    "\n",
    "Input:\n",
    "\n",
    "    arguments\n",
    "\n",
    "Output:\n",
    "\n",
    "    Figure and save files\n",
    "\n",
    "Keywords:\n",
    "\n",
    "    none\n",
    "\n",
    "Dependencies:\n",
    "\n",
    "    - load_utils.py\n",
    "    - matplotlib\n",
    "    - numpy\n",
    "    - write_utils\n",
    "    - path_utils\n",
    "    - hdf5storage\n",
    "    - scipy\n",
    "\n",
    "Needed Files:\n",
    "  - file.rc : for consistent creation of look of matplotlib figures\n",
    "  - ...\n",
    "\n",
    "Modification History:\n",
    "\n",
    "    Written: Samuel LeBlanc, Santa Cruz, CA, 2021-08-03\n",
    "    Modified:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:18:44.834100Z",
     "start_time": "2021-08-03T22:18:44.830843Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:18:45.338213Z",
     "start_time": "2021-08-03T22:18:45.334493Z"
    }
   },
   "outputs": [],
   "source": [
    "long_description = \"\"\"    Pull in Hyperion L1R file and hyperion_metadata.csv to calculate the geolocation\n",
    "    The output is a new netcdf file.\n",
    "        if selected creates new file with just the geolocation data, if not saves again the radiance data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:20:24.239531Z",
     "start_time": "2021-08-03T22:20:24.225899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-q', '--quiet'], dest='quiet', nargs=0, const=True, default=False, type=None, choices=None, help='if set, quiet the comments', metavar=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=long_description)\n",
    "parser.add_argument('-f','--file_name',nargs='?',\n",
    "                    help='Input filename',\n",
    "                    default='EO1H0080122015195110K4.L1R')\n",
    "parser.add_argument('-r','--root_dir',nargs='?',\n",
    "                    help='full file path of the root directory to read from',\n",
    "                    default='/data/sam/SBG/data/')\n",
    "parser.add_argument('-m','--hyperionmeta_dir',nargs='?',\n",
    "                    help='full file path of the directory which has the hyperion metadata file',\n",
    "                    default='/data/sam/SBG/data/')\n",
    "parser.add_argument('-o','--out_dir',nargs='?',\n",
    "                    help='full file path of the output directory',\n",
    "                    default='/data/sam/SBG/data/')\n",
    "parser.add_argument('-g','--only_geo',help='if set, will only save the geolocation information to new file',\n",
    "                    action='store_true')\n",
    "parser.add_argument('-q','--quiet',help='if set, quiet the comments',\n",
    "                    action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:20:25.525704Z",
     "start_time": "2021-08-03T22:20:25.521574Z"
    }
   },
   "outputs": [],
   "source": [
    "in_ = vars(parser.parse_known_args()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T22:20:26.046540Z",
     "start_time": "2021-08-03T22:20:26.040568Z"
    }
   },
   "outputs": [],
   "source": [
    "fp = in_.get('root_dir','/data/sam/SBG/data/')\n",
    "fph = in_.get('hyperionmeta_dir','/data/sam/SBG/data/')\n",
    "fp_out = in_.get('out_dir','/data/sam/SBG/data/')\n",
    "only_geo = in_.get('only_geo',False)\n",
    "fname = in_.get('file_name','EO1H0080122015195110K4.L1R')\n",
    "verbose = not in_.get('quiet',False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T18:36:12.363097Z",
     "start_time": "2021-08-03T18:36:12.084919Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import pyproj as pp\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T21:52:53.931361Z",
     "start_time": "2021-08-03T21:52:53.927831Z"
    }
   },
   "outputs": [],
   "source": [
    "vv = '1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T21:53:52.935212Z",
     "start_time": "2021-08-03T21:53:52.927865Z"
    }
   },
   "outputs": [],
   "source": [
    "da = xr.open_dataset(fp+fname)\n",
    "if verbose: print('loaded file: '+fp+fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T19:36:17.435668Z",
     "start_time": "2021-08-03T19:36:17.431409Z"
    }
   },
   "outputs": [],
   "source": [
    "ny,nx = da.dims['Along Track'],da.dims['Cross Track']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T17:58:54.432066Z",
     "start_time": "2021-08-03T17:58:53.397665Z"
    }
   },
   "outputs": [],
   "source": [
    "g = pd.read_csv(fp+'Hyperion_attributes.csv')\n",
    "if verbose: print('loaded metadata file: '+fph+'Hyperion_attributes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T18:07:45.390469Z",
     "start_time": "2021-08-03T18:07:45.347696Z"
    }
   },
   "outputs": [],
   "source": [
    "i = g[g['Entity_ID'].str.contains(fname.split('.')[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate the corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T19:34:43.803381Z",
     "start_time": "2021-08-03T19:34:43.796998Z"
    }
   },
   "outputs": [],
   "source": [
    "geoid = pp.Geod(ellps=\"WGS84\")\n",
    "x_trackpoints_top = geoid.npts(i['NW_Corne_3'],i['NW_Corne_2'],i['NE_Corne_3'],i['NE_Corne_2'],nx) #lon0,lat0,lon1,lat1\n",
    "x_trackpoints_bottom = geoid.npts(i['SW_Corne_3'],i['SW_Corne_2'],i['SE_Corne_3'],i['SE_Corne_2'],nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T19:34:45.479033Z",
     "start_time": "2021-08-03T19:34:44.284204Z"
    }
   },
   "outputs": [],
   "source": [
    "if verbose: print('.. interpolating corners for lat & lon')\n",
    "lat = np.zeros((ny,nx))\n",
    "lon = np.zeros((ny,nx))\n",
    "for j,xt in enumerate(x_trackpoints_top):\n",
    "    tmp = np.array(geoid.npts(xt[0],xt[1],x_trackpoints_bottom[j][0],x_trackpoints_bottom[j][1],ny))\n",
    "    lat[:,j] = tmp[:,1]\n",
    "    lon[:,j] = tmp[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T19:53:06.244247Z",
     "start_time": "2021-08-03T19:53:06.239447Z"
    }
   },
   "outputs": [],
   "source": [
    "attributes = {'Geolocation_CreatedBy':'Samuel LeBlanc',\n",
    "              'Geolocation_version':vv,\n",
    "              'Geolocation_CreationDate':str(datetime.now()),\n",
    "              'Geolocation_method':'Great circle interplation between corners from file: Hyperion_attributes.csv, cross-track first, then along track, using pyproj, WSG84',\n",
    "              'FieldInfo':'see: https://lta.cr.usgs.gov/DD/EO1.html'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T19:53:06.679357Z",
     "start_time": "2021-08-03T19:53:06.670541Z"
    }
   },
   "outputs": [],
   "source": [
    "da['Latitude'] = xr.DataArray(lat,dims=['Along Track','Cross Track'],attrs=attributes)\n",
    "da['Longitude'] = xr.DataArray(lon,dims=['Along Track','Cross Track'],attrs=attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the time of each along track line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T21:13:58.363199Z",
     "start_time": "2021-08-03T21:13:58.356017Z"
    }
   },
   "outputs": [],
   "source": [
    "start = pd.to_datetime(i['Scene_Star'],format='%Y:%j:%H:%M:%S.%f').values[0]\n",
    "stop = pd.to_datetime(i['Scene_Stop'],format='%Y:%j:%H:%M:%S.%f').values[0]\n",
    "dt = np.linspace(start.astype(int),stop.astype(int),ny)\n",
    "time = [datetime.utcfromtimestamp(dti*1e-9) for dti in dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T21:28:15.157741Z",
     "start_time": "2021-08-03T21:28:15.153223Z"
    }
   },
   "outputs": [],
   "source": [
    "time_attrs = {'Geolocation_CreatedBy':'Samuel LeBlanc',\n",
    "              'Geolocation_version':vv,\n",
    "              'Geolocation_CreationDate':str(datetime.now()),\n",
    "              'time_method':'from Scene_start and Scene_stop from file Hyperion_attributes.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T21:28:15.584837Z",
     "start_time": "2021-08-03T21:28:15.567842Z"
    }
   },
   "outputs": [],
   "source": [
    "da['time'] = xr.DataArray(time,dims=['Along Track'],attrs=time_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the view angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T20:36:41.860239Z",
     "start_time": "2021-08-03T20:36:41.856508Z"
    }
   },
   "outputs": [],
   "source": [
    "distance_sat_to_earth = 705000.0 #m average, could be better by using the two line element orbit descriptor\n",
    "#vza = arctan(tan(look_angle)+dist_from_center/distance_sat_to_earth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T20:36:28.172311Z",
     "start_time": "2021-08-03T20:36:25.169494Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the distance from the center point\n",
    "if verbose: print('.. calculating view angles')\n",
    "ix = [int(nx/2)] #find the corsstrack center point\n",
    "vza = np.zeros((ny,nx)) \n",
    "vaa = np.zeros((ny,nx)) #view azimuth angle\n",
    "for iy in range(ny):\n",
    "    faa_tmp,baa_tmp,d_tmp = geoid.inv(lon[iy,ix*nx],lat[iy,ix*nx],lon[iy,:],lat[iy,:]) #forward az, back azi, dist in m    \n",
    "    vza[iy,:] = np.rad2deg(np.arctan(np.tan(np.deg2rad(float(i['Look_Angle'])))+d_tmp/distance_sat_to_earth))\n",
    "    vaa[iy,:] = 90.0-faa_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T20:38:32.527497Z",
     "start_time": "2021-08-03T20:38:32.522693Z"
    }
   },
   "outputs": [],
   "source": [
    "view_angles_attrs = {'Geolocation_CreatedBy':'Samuel LeBlanc',\n",
    "                     'Geolocation_version':vv,\n",
    "                     'Geolocation_CreationDate':str(datetime.now()),\n",
    "                     'ViewAngle_method':'using pyproj to calculate differences in look angle from center of crosstrack to each pixel. View azimuth angle calculated from normal of along track',\n",
    "                     'Additional_info':'see https://www.usgs.gov/centers/eros/look-angles-and-coverage-area'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T20:39:23.924065Z",
     "start_time": "2021-08-03T20:39:23.915297Z"
    }
   },
   "outputs": [],
   "source": [
    "da['ViewZenithAngle'] = xr.DataArray(vza,dims=['Along Track','Cross Track'],attrs=view_angles_attrs)\n",
    "da['ViewAzimuthAngle'] = xr.DataArray(vaa,dims=['Along Track','Cross Track'],attrs=view_angles_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the sun angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sza_azi(lat,lon,datetimet,alt=None,return_sunearthfactor=False,return_sunf_and_dec=False):\n",
    "    \"\"\"\n",
    "    Program wrapper for pyephem.Sun to get the solar zenith angle and the solar azimuth angle\n",
    "    can use inputs of list or numpy arrays\n",
    "    require input of lat,lon,datetimet\n",
    "    optional input of altitutde (in meters)\n",
    "    optional output of sun earth distance factor if return_sunearthfactor is set to True\n",
    "    optional output of sun earth distance factor and sun declination if return_sunf_and_dec is set to True\n",
    "    \"\"\"\n",
    "    import ephem\n",
    "    from numpy import pi,isscalar\n",
    "    sun = ephem.Sun()\n",
    "    obs = ephem.Observer()\n",
    "    if isscalar(lat):\n",
    "        if isscalar(datetimet):\n",
    "            lat = [lat]\n",
    "            lon = [lon]\n",
    "            datetime = [datetimet]\n",
    "        else:\n",
    "            lati = [lat for i in range(len(datetimet))]\n",
    "            loni = [lon for i in range(len(datetimet))]\n",
    "            lat,lon = lati,loni\n",
    "    n = len(lat)\n",
    "    sza = []\n",
    "    azi = []\n",
    "    sunf = []\n",
    "    dec = []\n",
    "    for i in range(n):\n",
    "        obs.lat,obs.lon,obs.date = lat[i]/180.0*pi,lon[i]/180.0*pi,datetimet[i]\n",
    "        if alt:\n",
    "            obs.elevation = alt\n",
    "        sun.compute(obs)\n",
    "        sza.append(90.0-sun.alt*180/pi)\n",
    "        azi.append(sun.az*180/pi)\n",
    "        sunf.append(1.0/(sun.earth_distance**2))\n",
    "        dec.append(sun.dec*180.0/pi)\n",
    "    if return_sunf_and_dec:\n",
    "        return sza,azi,sunf,dec\n",
    "    elif return_sunearthfactor:\n",
    "        return sza,azi,sunf\n",
    "    else:\n",
    "        return sza,azi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T21:34:20.103402Z",
     "start_time": "2021-08-03T21:33:50.774689Z"
    }
   },
   "outputs": [],
   "source": [
    "if verbose: print('.. calculating sun angles')\n",
    "sza = np.zeros((ny,nx))\n",
    "azi = np.zeros((ny,nx))\n",
    "for j in range(nx):\n",
    "    sza_tmp, azi_tmp = get_sza_azi(lat[:,j],lon[:,j],time)\n",
    "    sza[:,j] = np.array(sza_tmp)\n",
    "    azi[:,j] = np.array(azi_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T21:37:15.950484Z",
     "start_time": "2021-08-03T21:37:15.945705Z"
    }
   },
   "outputs": [],
   "source": [
    "sun_attrs = {'Geolocation_CreatedBy':'Samuel LeBlanc',\n",
    "             'Geolocation_version':vv,\n",
    "             'Geolocation_CreationDate':str(datetime.now()),\n",
    "             'SolarAngle_method':'using pyephem to calculate solar zenith and azimuth angle from interpolated lat-lon and time positions'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T21:37:24.765863Z",
     "start_time": "2021-08-03T21:37:24.755147Z"
    }
   },
   "outputs": [],
   "source": [
    "da['SolarZenithAngle'] = xr.DataArray(sza,dims=['Along Track','Cross Track'],attrs=sun_attrs)\n",
    "da['SolarAzimuthAngle'] = xr.DataArray(azi,dims=['Along Track','Cross Track'],attrs=sun_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T21:38:31.441094Z",
     "start_time": "2021-08-03T21:38:31.019314Z"
    }
   },
   "outputs": [],
   "source": [
    "if only_geo:\n",
    "    du = da.drop(['Image','Spectral Center Wavelengths','Spectral Bandwidths','Gain Coefficients','Flag Mask'])\n",
    "    new_path = fp_out+fname.split('.')[0]+'_'+fname.split('.')[1]+'_geo_only.nc'\n",
    "    print('Saving to : '+new_path)\n",
    "    du.to_netcdf(new_path)\n",
    "else:\n",
    "    new_path = fp_out+fname.split('.')[0]+'_'+fname.split('.')[1]+'_geo.nc'\n",
    "    print('Saving to : '+new_path)\n",
    "    da.to_netcdf(new_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
